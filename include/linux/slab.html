<!DOCTYPE html>
<html><head><title>joekychen/linux » include › linux › slab.h

</title>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta name="generator" content="Docco">
<link rel="stylesheet" media="all" href="../../stylesheets/docco.min.css" />


</head>
<body>
<div id="container">
<div id="background"></div>
<table cellpadding="0" cellspacing="0">
<thead><tr><th class="docs"><a id="home" href="../../index.html"></a><h1>slab.h</h1></th><th class="code"></th></tr></thead>
<tbody>


<tr id="section-1"><td class="docs"><div class="pilwrap"><a class="pilcrow" href="#section-1">&#182;</a></div></td><td class="code"><div class="highlight"><pre><span class="cm">/*</span>
<span class="cm"> * Written by Mark Hemment, 1996 (markhe@nextd.demon.co.uk).</span>
<span class="cm"> *</span>
<span class="cm"> * (C) SGI 2006, Christoph Lameter</span>
<span class="cm"> * 	Cleaned up and restructured to ease the addition of alternative</span>
<span class="cm"> * 	implementations of SLAB allocators.</span>
<span class="cm"> */</span>

<span class="cp">#ifndef _LINUX_SLAB_H</span>
<span class="cp">#define	_LINUX_SLAB_H</span>

<span class="cp">#include &lt;linux/gfp.h&gt;</span>
<span class="cp">#include &lt;linux/types.h&gt;</span>

<span class="cm">/*</span>
<span class="cm"> * Flags to pass to kmem_cache_create().</span>
<span class="cm"> * The ones marked DEBUG are only valid if CONFIG_SLAB_DEBUG is set.</span>
<span class="cm"> */</span>
<span class="cp">#define SLAB_DEBUG_FREE		0x00000100UL	</span><span class="cm">/* DEBUG: Perform (expensive) checks on free */</span><span class="cp"></span>
<span class="cp">#define SLAB_RED_ZONE		0x00000400UL	</span><span class="cm">/* DEBUG: Red zone objs in a cache */</span><span class="cp"></span>
<span class="cp">#define SLAB_POISON		0x00000800UL	</span><span class="cm">/* DEBUG: Poison objects */</span><span class="cp"></span>
<span class="cp">#define SLAB_HWCACHE_ALIGN	0x00002000UL	</span><span class="cm">/* Align objs on cache lines */</span><span class="cp"></span>
<span class="cp">#define SLAB_CACHE_DMA		0x00004000UL	</span><span class="cm">/* Use GFP_DMA memory */</span><span class="cp"></span>
<span class="cp">#define SLAB_STORE_USER		0x00010000UL	</span><span class="cm">/* DEBUG: Store the last owner for bug hunting */</span><span class="cp"></span>
<span class="cp">#define SLAB_PANIC		0x00040000UL	</span><span class="cm">/* Panic if kmem_cache_create() fails */</span><span class="cp"></span>
<span class="cm">/*</span>
<span class="cm"> * SLAB_DESTROY_BY_RCU - **WARNING** READ THIS!</span>
<span class="cm"> *</span>
<span class="cm"> * This delays freeing the SLAB page by a grace period, it does _NOT_</span>
<span class="cm"> * delay object freeing. This means that if you do kmem_cache_free()</span>
<span class="cm"> * that memory location is free to be reused at any time. Thus it may</span>
<span class="cm"> * be possible to see another object there in the same RCU grace period.</span>
<span class="cm"> *</span>
<span class="cm"> * This feature only ensures the memory location backing the object</span>
<span class="cm"> * stays valid, the trick to using this is relying on an independent</span>
<span class="cm"> * object validation pass. Something like:</span>
<span class="cm"> *</span>
<span class="cm"> *  rcu_read_lock()</span>
<span class="cm"> * again:</span>
<span class="cm"> *  obj = lockless_lookup(key);</span>
<span class="cm"> *  if (obj) {</span>
<span class="cm"> *    if (!try_get_ref(obj)) // might fail for free objects</span>
<span class="cm"> *      goto again;</span>
<span class="cm"> *</span>
<span class="cm"> *    if (obj-&gt;key != key) { // not the object we expected</span>
<span class="cm"> *      put_ref(obj);</span>
<span class="cm"> *      goto again;</span>
<span class="cm"> *    }</span>
<span class="cm"> *  }</span>
<span class="cm"> *  rcu_read_unlock();</span>
<span class="cm"> *</span>
<span class="cm"> * See also the comment on struct slab_rcu in mm/slab.c.</span>
<span class="cm"> */</span>
<span class="cp">#define SLAB_DESTROY_BY_RCU	0x00080000UL	</span><span class="cm">/* Defer freeing slabs to RCU */</span><span class="cp"></span>
<span class="cp">#define SLAB_MEM_SPREAD		0x00100000UL	</span><span class="cm">/* Spread some memory over cpuset */</span><span class="cp"></span>
<span class="cp">#define SLAB_TRACE		0x00200000UL	</span><span class="cm">/* Trace allocations and frees */</span><span class="cp"></span>

<span class="cm">/* Flag to prevent checks on free */</span>
<span class="cp">#ifdef CONFIG_DEBUG_OBJECTS</span>
<span class="cp"># define SLAB_DEBUG_OBJECTS	0x00400000UL</span>
<span class="cp">#else</span>
<span class="cp"># define SLAB_DEBUG_OBJECTS	0x00000000UL</span>
<span class="cp">#endif</span>

<span class="cp">#define SLAB_NOLEAKTRACE	0x00800000UL	</span><span class="cm">/* Avoid kmemleak tracing */</span><span class="cp"></span>

<span class="cm">/* Don&#39;t track use of uninitialized memory */</span>
<span class="cp">#ifdef CONFIG_KMEMCHECK</span>
<span class="cp"># define SLAB_NOTRACK		0x01000000UL</span>
<span class="cp">#else</span>
<span class="cp"># define SLAB_NOTRACK		0x00000000UL</span>
<span class="cp">#endif</span>
<span class="cp">#ifdef CONFIG_FAILSLAB</span>
<span class="cp"># define SLAB_FAILSLAB		0x02000000UL	</span><span class="cm">/* Fault injection mark */</span><span class="cp"></span>
<span class="cp">#else</span>
<span class="cp"># define SLAB_FAILSLAB		0x00000000UL</span>
<span class="cp">#endif</span>

<span class="cm">/* The following flags affect the page allocator grouping pages by mobility */</span>
<span class="cp">#define SLAB_RECLAIM_ACCOUNT	0x00020000UL		</span><span class="cm">/* Objects are reclaimable */</span><span class="cp"></span>
<span class="cp">#define SLAB_TEMPORARY		SLAB_RECLAIM_ACCOUNT	</span><span class="cm">/* Objects are short-lived */</span><span class="cp"></span>
<span class="cm">/*</span>
<span class="cm"> * ZERO_SIZE_PTR will be returned for zero sized kmalloc requests.</span>
<span class="cm"> *</span>
<span class="cm"> * Dereferencing ZERO_SIZE_PTR will lead to a distinct access fault.</span>
<span class="cm"> *</span>
<span class="cm"> * ZERO_SIZE_PTR can be passed to kfree though in the same way that NULL can.</span>
<span class="cm"> * Both make kfree a no-op.</span>
<span class="cm"> */</span>
<span class="cp">#define ZERO_SIZE_PTR ((void *)16)</span>

<span class="cp">#define ZERO_OR_NULL_PTR(x) ((unsigned long)(x) &lt;= \</span>
<span class="cp">				(unsigned long)ZERO_SIZE_PTR)</span>

<span class="cm">/*</span>
<span class="cm"> * struct kmem_cache related prototypes</span>
<span class="cm"> */</span>
<span class="kt">void</span> <span class="n">__init</span> <span class="n">kmem_cache_init</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span>
<span class="kt">int</span> <span class="n">slab_is_available</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span>

<span class="k">struct</span> <span class="n">kmem_cache</span> <span class="o">*</span><span class="n">kmem_cache_create</span><span class="p">(</span><span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="p">,</span> <span class="kt">size_t</span><span class="p">,</span> <span class="kt">size_t</span><span class="p">,</span>
			<span class="kt">unsigned</span> <span class="kt">long</span><span class="p">,</span>
			<span class="kt">void</span> <span class="p">(</span><span class="o">*</span><span class="p">)(</span><span class="kt">void</span> <span class="o">*</span><span class="p">));</span>
<span class="kt">void</span> <span class="n">kmem_cache_destroy</span><span class="p">(</span><span class="k">struct</span> <span class="n">kmem_cache</span> <span class="o">*</span><span class="p">);</span>
<span class="kt">int</span> <span class="n">kmem_cache_shrink</span><span class="p">(</span><span class="k">struct</span> <span class="n">kmem_cache</span> <span class="o">*</span><span class="p">);</span>
<span class="kt">void</span> <span class="n">kmem_cache_free</span><span class="p">(</span><span class="k">struct</span> <span class="n">kmem_cache</span> <span class="o">*</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="p">);</span>
<span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">kmem_cache_size</span><span class="p">(</span><span class="k">struct</span> <span class="n">kmem_cache</span> <span class="o">*</span><span class="p">);</span>

<span class="cm">/*</span>
<span class="cm"> * Please use this macro to create slab caches. Simply specify the</span>
<span class="cm"> * name of the structure and maybe some flags that are listed above.</span>
<span class="cm"> *</span>
<span class="cm"> * The alignment of the struct determines object alignment. If you</span>
<span class="cm"> * f.e. add ____cacheline_aligned_in_smp to the struct declaration</span>
<span class="cm"> * then the objects will be properly aligned in SMP configurations.</span>
<span class="cm"> */</span>
<span class="cp">#define KMEM_CACHE(__struct, __flags) kmem_cache_create(#__struct,\</span>
<span class="cp">		sizeof(struct __struct), __alignof__(struct __struct),\</span>
<span class="cp">		(__flags), NULL)</span>

<span class="cm">/*</span>
<span class="cm"> * The largest kmalloc size supported by the slab allocators is</span>
<span class="cm"> * 32 megabyte (2^25) or the maximum allocatable page order if that is</span>
<span class="cm"> * less than 32 MB.</span>
<span class="cm"> *</span>
<span class="cm"> * WARNING: Its not easy to increase this value since the allocators have</span>
<span class="cm"> * to do various tricks to work around compiler limitations in order to</span>
<span class="cm"> * ensure proper constant folding.</span>
<span class="cm"> */</span>
<span class="cp">#define KMALLOC_SHIFT_HIGH	((MAX_ORDER + PAGE_SHIFT - 1) &lt;= 25 ? \</span>
<span class="cp">				(MAX_ORDER + PAGE_SHIFT - 1) : 25)</span>

<span class="cp">#define KMALLOC_MAX_SIZE	(1UL &lt;&lt; KMALLOC_SHIFT_HIGH)</span>
<span class="cp">#define KMALLOC_MAX_ORDER	(KMALLOC_SHIFT_HIGH - PAGE_SHIFT)</span>

<span class="cm">/*</span>
<span class="cm"> * Some archs want to perform DMA into kmalloc caches and need a guaranteed</span>
<span class="cm"> * alignment larger than the alignment of a 64-bit integer.</span>
<span class="cm"> * Setting ARCH_KMALLOC_MINALIGN in arch headers allows that.</span>
<span class="cm"> */</span>
<span class="cp">#ifdef ARCH_DMA_MINALIGN</span>
<span class="cp">#define ARCH_KMALLOC_MINALIGN ARCH_DMA_MINALIGN</span>
<span class="cp">#else</span>
<span class="cp">#define ARCH_KMALLOC_MINALIGN __alignof__(unsigned long long)</span>
<span class="cp">#endif</span>

<span class="cm">/*</span>
<span class="cm"> * Setting ARCH_SLAB_MINALIGN in arch headers allows a different alignment.</span>
<span class="cm"> * Intended for arches that get misalignment faults even for 64 bit integer</span>
<span class="cm"> * aligned buffers.</span>
<span class="cm"> */</span>
<span class="cp">#ifndef ARCH_SLAB_MINALIGN</span>
<span class="cp">#define ARCH_SLAB_MINALIGN __alignof__(unsigned long long)</span>
<span class="cp">#endif</span>

<span class="cm">/*</span>
<span class="cm"> * Common kmalloc functions provided by all allocators</span>
<span class="cm"> */</span>
<span class="kt">void</span> <span class="o">*</span> <span class="n">__must_check</span> <span class="n">__krealloc</span><span class="p">(</span><span class="k">const</span> <span class="kt">void</span> <span class="o">*</span><span class="p">,</span> <span class="kt">size_t</span><span class="p">,</span> <span class="n">gfp_t</span><span class="p">);</span>
<span class="kt">void</span> <span class="o">*</span> <span class="n">__must_check</span> <span class="n">krealloc</span><span class="p">(</span><span class="k">const</span> <span class="kt">void</span> <span class="o">*</span><span class="p">,</span> <span class="kt">size_t</span><span class="p">,</span> <span class="n">gfp_t</span><span class="p">);</span>
<span class="kt">void</span> <span class="n">kfree</span><span class="p">(</span><span class="k">const</span> <span class="kt">void</span> <span class="o">*</span><span class="p">);</span>
<span class="kt">void</span> <span class="n">kzfree</span><span class="p">(</span><span class="k">const</span> <span class="kt">void</span> <span class="o">*</span><span class="p">);</span>
<span class="kt">size_t</span> <span class="n">ksize</span><span class="p">(</span><span class="k">const</span> <span class="kt">void</span> <span class="o">*</span><span class="p">);</span>

<span class="cm">/*</span>
<span class="cm"> * Allocator specific definitions. These are mainly used to establish optimized</span>
<span class="cm"> * ways to convert kmalloc() calls to kmem_cache_alloc() invocations by</span>
<span class="cm"> * selecting the appropriate general cache at compile time.</span>
<span class="cm"> *</span>
<span class="cm"> * Allocators must define at least:</span>
<span class="cm"> *</span>
<span class="cm"> *	kmem_cache_alloc()</span>
<span class="cm"> *	__kmalloc()</span>
<span class="cm"> *	kmalloc()</span>
<span class="cm"> *</span>
<span class="cm"> * Those wishing to support NUMA must also define:</span>
<span class="cm"> *</span>
<span class="cm"> *	kmem_cache_alloc_node()</span>
<span class="cm"> *	kmalloc_node()</span>
<span class="cm"> *</span>
<span class="cm"> * See each allocator definition file for additional comments and</span>
<span class="cm"> * implementation notes.</span>
<span class="cm"> */</span>
<span class="cp">#ifdef CONFIG_SLUB</span>
<span class="cp">#include &lt;linux/slub_def.h&gt;</span>
<span class="cp">#elif defined(CONFIG_SLOB)</span>
<span class="cp">#include &lt;linux/slob_def.h&gt;</span>
<span class="cp">#else</span>
<span class="cp">#include &lt;linux/slab_def.h&gt;</span>
<span class="cp">#endif</span>

<span class="cm">/**</span>
<span class="cm"> * kmalloc_array - allocate memory for an array.</span>
<span class="cm"> * @n: number of elements.</span>
<span class="cm"> * @size: element size.</span>
<span class="cm"> * @flags: the type of memory to allocate.</span>
<span class="cm"> *</span>
<span class="cm"> * The @flags argument may be one of:</span>
<span class="cm"> *</span>
<span class="cm"> * %GFP_USER - Allocate memory on behalf of user.  May sleep.</span>
<span class="cm"> *</span>
<span class="cm"> * %GFP_KERNEL - Allocate normal kernel ram.  May sleep.</span>
<span class="cm"> *</span>
<span class="cm"> * %GFP_ATOMIC - Allocation will not sleep.  May use emergency pools.</span>
<span class="cm"> *   For example, use this inside interrupt handlers.</span>
<span class="cm"> *</span>
<span class="cm"> * %GFP_HIGHUSER - Allocate pages from high memory.</span>
<span class="cm"> *</span>
<span class="cm"> * %GFP_NOIO - Do not do any I/O at all while trying to get memory.</span>
<span class="cm"> *</span>
<span class="cm"> * %GFP_NOFS - Do not make any fs calls while trying to get memory.</span>
<span class="cm"> *</span>
<span class="cm"> * %GFP_NOWAIT - Allocation will not sleep.</span>
<span class="cm"> *</span>
<span class="cm"> * %GFP_THISNODE - Allocate node-local memory only.</span>
<span class="cm"> *</span>
<span class="cm"> * %GFP_DMA - Allocation suitable for DMA.</span>
<span class="cm"> *   Should only be used for kmalloc() caches. Otherwise, use a</span>
<span class="cm"> *   slab created with SLAB_DMA.</span>
<span class="cm"> *</span>
<span class="cm"> * Also it is possible to set different flags by OR&#39;ing</span>
<span class="cm"> * in one or more of the following additional @flags:</span>
<span class="cm"> *</span>
<span class="cm"> * %__GFP_COLD - Request cache-cold pages instead of</span>
<span class="cm"> *   trying to return cache-warm pages.</span>
<span class="cm"> *</span>
<span class="cm"> * %__GFP_HIGH - This allocation has high priority and may use emergency pools.</span>
<span class="cm"> *</span>
<span class="cm"> * %__GFP_NOFAIL - Indicate that this allocation is in no way allowed to fail</span>
<span class="cm"> *   (think twice before using).</span>
<span class="cm"> *</span>
<span class="cm"> * %__GFP_NORETRY - If memory is not immediately available,</span>
<span class="cm"> *   then give up at once.</span>
<span class="cm"> *</span>
<span class="cm"> * %__GFP_NOWARN - If allocation fails, don&#39;t issue any warnings.</span>
<span class="cm"> *</span>
<span class="cm"> * %__GFP_REPEAT - If allocation fails initially, try once more before failing.</span>
<span class="cm"> *</span>
<span class="cm"> * There are other flags available as well, but these are not intended</span>
<span class="cm"> * for general use, and so are not documented here. For a full list of</span>
<span class="cm"> * potential flags, always refer to linux/gfp.h.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="o">*</span><span class="nf">kmalloc_array</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">n</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span> <span class="n">gfp_t</span> <span class="n">flags</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">size</span> <span class="o">!=</span> <span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">n</span> <span class="o">&gt;</span> <span class="n">SIZE_MAX</span> <span class="o">/</span> <span class="n">size</span><span class="p">)</span>
		<span class="k">return</span> <span class="nb">NULL</span><span class="p">;</span>
	<span class="k">return</span> <span class="n">__kmalloc</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">size</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>
<span class="p">}</span>

<span class="cm">/**</span>
<span class="cm"> * kcalloc - allocate memory for an array. The memory is set to zero.</span>
<span class="cm"> * @n: number of elements.</span>
<span class="cm"> * @size: element size.</span>
<span class="cm"> * @flags: the type of memory to allocate (see kmalloc).</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="o">*</span><span class="nf">kcalloc</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">n</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span> <span class="n">gfp_t</span> <span class="n">flags</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="n">kmalloc_array</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">flags</span> <span class="o">|</span> <span class="n">__GFP_ZERO</span><span class="p">);</span>
<span class="p">}</span>

<span class="cp">#if !defined(CONFIG_NUMA) &amp;&amp; !defined(CONFIG_SLOB)</span>
<span class="cm">/**</span>
<span class="cm"> * kmalloc_node - allocate memory from a specific node</span>
<span class="cm"> * @size: how many bytes of memory are required.</span>
<span class="cm"> * @flags: the type of memory to allocate (see kcalloc).</span>
<span class="cm"> * @node: node to allocate from.</span>
<span class="cm"> *</span>
<span class="cm"> * kmalloc() for non-local nodes, used to allocate from a specific node</span>
<span class="cm"> * if available. Equivalent to kmalloc() in the non-NUMA single-node</span>
<span class="cm"> * case.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="o">*</span><span class="nf">kmalloc_node</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span> <span class="n">gfp_t</span> <span class="n">flags</span><span class="p">,</span> <span class="kt">int</span> <span class="n">node</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="n">kmalloc</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="o">*</span><span class="nf">__kmalloc_node</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span> <span class="n">gfp_t</span> <span class="n">flags</span><span class="p">,</span> <span class="kt">int</span> <span class="n">node</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="n">__kmalloc</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="o">*</span><span class="n">kmem_cache_alloc</span><span class="p">(</span><span class="k">struct</span> <span class="n">kmem_cache</span> <span class="o">*</span><span class="p">,</span> <span class="n">gfp_t</span><span class="p">);</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="o">*</span><span class="nf">kmem_cache_alloc_node</span><span class="p">(</span><span class="k">struct</span> <span class="n">kmem_cache</span> <span class="o">*</span><span class="n">cachep</span><span class="p">,</span>
					<span class="n">gfp_t</span> <span class="n">flags</span><span class="p">,</span> <span class="kt">int</span> <span class="n">node</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="n">kmem_cache_alloc</span><span class="p">(</span><span class="n">cachep</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>
<span class="p">}</span>
<span class="cp">#endif </span><span class="cm">/* !CONFIG_NUMA &amp;&amp; !CONFIG_SLOB */</span><span class="cp"></span>

<span class="cm">/*</span>
<span class="cm"> * kmalloc_track_caller is a special version of kmalloc that records the</span>
<span class="cm"> * calling function of the routine calling it for slab leak tracking instead</span>
<span class="cm"> * of just the calling function (confusing, eh?).</span>
<span class="cm"> * It&#39;s useful when the call to kmalloc comes from a widely-used standard</span>
<span class="cm"> * allocator where we care about the real place the memory allocation</span>
<span class="cm"> * request comes from.</span>
<span class="cm"> */</span>
<span class="cp">#if defined(CONFIG_DEBUG_SLAB) || defined(CONFIG_SLUB) || \</span>
<span class="cp">	(defined(CONFIG_SLAB) &amp;&amp; defined(CONFIG_TRACING))</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="o">*</span><span class="n">__kmalloc_track_caller</span><span class="p">(</span><span class="kt">size_t</span><span class="p">,</span> <span class="n">gfp_t</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span><span class="p">);</span>
<span class="cp">#define kmalloc_track_caller(size, flags) \</span>
<span class="cp">	__kmalloc_track_caller(size, flags, _RET_IP_)</span>
<span class="cp">#else</span>
<span class="cp">#define kmalloc_track_caller(size, flags) \</span>
<span class="cp">	__kmalloc(size, flags)</span>
<span class="cp">#endif </span><span class="cm">/* DEBUG_SLAB */</span><span class="cp"></span>

<span class="cp">#ifdef CONFIG_NUMA</span>
<span class="cm">/*</span>
<span class="cm"> * kmalloc_node_track_caller is a special version of kmalloc_node that</span>
<span class="cm"> * records the calling function of the routine calling it for slab leak</span>
<span class="cm"> * tracking instead of just the calling function (confusing, eh?).</span>
<span class="cm"> * It&#39;s useful when the call to kmalloc_node comes from a widely-used</span>
<span class="cm"> * standard allocator where we care about the real place the memory</span>
<span class="cm"> * allocation request comes from.</span>
<span class="cm"> */</span>
<span class="cp">#if defined(CONFIG_DEBUG_SLAB) || defined(CONFIG_SLUB) || \</span>
<span class="cp">	(defined(CONFIG_SLAB) &amp;&amp; defined(CONFIG_TRACING))</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="o">*</span><span class="n">__kmalloc_node_track_caller</span><span class="p">(</span><span class="kt">size_t</span><span class="p">,</span> <span class="n">gfp_t</span><span class="p">,</span> <span class="kt">int</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span><span class="p">);</span>
<span class="cp">#define kmalloc_node_track_caller(size, flags, node) \</span>
<span class="cp">	__kmalloc_node_track_caller(size, flags, node, \</span>
<span class="cp">			_RET_IP_)</span>
<span class="cp">#else</span>
<span class="cp">#define kmalloc_node_track_caller(size, flags, node) \</span>
<span class="cp">	__kmalloc_node(size, flags, node)</span>
<span class="cp">#endif</span>

<span class="cp">#else </span><span class="cm">/* CONFIG_NUMA */</span><span class="cp"></span>

<span class="cp">#define kmalloc_node_track_caller(size, flags, node) \</span>
<span class="cp">	kmalloc_track_caller(size, flags)</span>

<span class="cp">#endif </span><span class="cm">/* CONFIG_NUMA */</span><span class="cp"></span>

<span class="cm">/*</span>
<span class="cm"> * Shortcuts</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="o">*</span><span class="nf">kmem_cache_zalloc</span><span class="p">(</span><span class="k">struct</span> <span class="n">kmem_cache</span> <span class="o">*</span><span class="n">k</span><span class="p">,</span> <span class="n">gfp_t</span> <span class="n">flags</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="n">kmem_cache_alloc</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">flags</span> <span class="o">|</span> <span class="n">__GFP_ZERO</span><span class="p">);</span>
<span class="p">}</span>

<span class="cm">/**</span>
<span class="cm"> * kzalloc - allocate memory. The memory is set to zero.</span>
<span class="cm"> * @size: how many bytes of memory are required.</span>
<span class="cm"> * @flags: the type of memory to allocate (see kmalloc).</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="o">*</span><span class="nf">kzalloc</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span> <span class="n">gfp_t</span> <span class="n">flags</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="n">kmalloc</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">flags</span> <span class="o">|</span> <span class="n">__GFP_ZERO</span><span class="p">);</span>
<span class="p">}</span>

<span class="cm">/**</span>
<span class="cm"> * kzalloc_node - allocate zeroed memory from a particular memory node.</span>
<span class="cm"> * @size: how many bytes of memory are required.</span>
<span class="cm"> * @flags: the type of memory to allocate (see kmalloc).</span>
<span class="cm"> * @node: memory node from which to allocate</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="o">*</span><span class="nf">kzalloc_node</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span> <span class="n">gfp_t</span> <span class="n">flags</span><span class="p">,</span> <span class="kt">int</span> <span class="n">node</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="n">kmalloc_node</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">flags</span> <span class="o">|</span> <span class="n">__GFP_ZERO</span><span class="p">,</span> <span class="n">node</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="n">__init</span> <span class="n">kmem_cache_init_late</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span>

<span class="cp">#endif	</span><span class="cm">/* _LINUX_SLAB_H */</span><span class="cp"></span>

</pre></div></td></tr>

</tbody>
</table>
</div>

</body>
<script>docas={repo:"joekychen/linux",depth:2}</script>
<script>document.write('<script src=' + ('__proto__' in {} ? 'http://cdnjs.cloudflare.com/ajax/libs/zepto/1.0rc1/zepto.min.js' : 'https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js')+'><\\/script>')</script>
<script src="http://baoshan.github.com/moment/min/moment.min.js"></script>
<script src="../../javascript/docco.min.js"></script>
</html>
