<!DOCTYPE html>
<html><head><title>joekychen/linux » include › linux › percpu.h

</title>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta name="generator" content="Docco">
<link rel="stylesheet" media="all" href="../../stylesheets/docco.min.css" />


</head>
<body>
<div id="container">
<div id="background"></div>
<table cellpadding="0" cellspacing="0">
<thead><tr><th class="docs"><a id="home" href="../../index.html"></a><h1>percpu.h</h1></th><th class="code"></th></tr></thead>
<tbody>


<tr id="section-1"><td class="docs"><div class="pilwrap"><a class="pilcrow" href="#section-1">&#182;</a></div></td><td class="code"><div class="highlight"><pre><span class="cp">#ifndef __LINUX_PERCPU_H</span>
<span class="cp">#define __LINUX_PERCPU_H</span>

<span class="cp">#include &lt;linux/preempt.h&gt;</span>
<span class="cp">#include &lt;linux/smp.h&gt;</span>
<span class="cp">#include &lt;linux/cpumask.h&gt;</span>
<span class="cp">#include &lt;linux/pfn.h&gt;</span>
<span class="cp">#include &lt;linux/init.h&gt;</span>

<span class="cp">#include &lt;asm/percpu.h&gt;</span>

<span class="cm">/* enough to cover all DEFINE_PER_CPUs in modules */</span>
<span class="cp">#ifdef CONFIG_MODULES</span>
<span class="cp">#define PERCPU_MODULE_RESERVE		(8 &lt;&lt; 10)</span>
<span class="cp">#else</span>
<span class="cp">#define PERCPU_MODULE_RESERVE		0</span>
<span class="cp">#endif</span>

<span class="cp">#ifndef PERCPU_ENOUGH_ROOM</span>
<span class="cp">#define PERCPU_ENOUGH_ROOM						\</span>
<span class="cp">	(ALIGN(__per_cpu_end - __per_cpu_start, SMP_CACHE_BYTES) +	\</span>
<span class="cp">	 PERCPU_MODULE_RESERVE)</span>
<span class="cp">#endif</span>

<span class="cm">/*</span>
<span class="cm"> * Must be an lvalue. Since @var must be a simple identifier,</span>
<span class="cm"> * we force a syntax error here if it isn&#39;t.</span>
<span class="cm"> */</span>
<span class="cp">#define get_cpu_var(var) (*({				\</span>
<span class="cp">	preempt_disable();				\</span>
<span class="cp">	&amp;__get_cpu_var(var); }))</span>

<span class="cm">/*</span>
<span class="cm"> * The weird &amp; is necessary because sparse considers (void)(var) to be</span>
<span class="cm"> * a direct dereference of percpu variable (var).</span>
<span class="cm"> */</span>
<span class="cp">#define put_cpu_var(var) do {				\</span>
<span class="cp">	(void)&amp;(var);					\</span>
<span class="cp">	preempt_enable();				\</span>
<span class="cp">} while (0)</span>

<span class="cp">#define get_cpu_ptr(var) ({				\</span>
<span class="cp">	preempt_disable();				\</span>
<span class="cp">	this_cpu_ptr(var); })</span>

<span class="cp">#define put_cpu_ptr(var) do {				\</span>
<span class="cp">	(void)(var);					\</span>
<span class="cp">	preempt_enable();				\</span>
<span class="cp">} while (0)</span>

<span class="cm">/* minimum unit size, also is the maximum supported allocation size */</span>
<span class="cp">#define PCPU_MIN_UNIT_SIZE		PFN_ALIGN(32 &lt;&lt; 10)</span>

<span class="cm">/*</span>
<span class="cm"> * Percpu allocator can serve percpu allocations before slab is</span>
<span class="cm"> * initialized which allows slab to depend on the percpu allocator.</span>
<span class="cm"> * The following two parameters decide how much resource to</span>
<span class="cm"> * preallocate for this.  Keep PERCPU_DYNAMIC_RESERVE equal to or</span>
<span class="cm"> * larger than PERCPU_DYNAMIC_EARLY_SIZE.</span>
<span class="cm"> */</span>
<span class="cp">#define PERCPU_DYNAMIC_EARLY_SLOTS	128</span>
<span class="cp">#define PERCPU_DYNAMIC_EARLY_SIZE	(12 &lt;&lt; 10)</span>

<span class="cm">/*</span>
<span class="cm"> * PERCPU_DYNAMIC_RESERVE indicates the amount of free area to piggy</span>
<span class="cm"> * back on the first chunk for dynamic percpu allocation if arch is</span>
<span class="cm"> * manually allocating and mapping it for faster access (as a part of</span>
<span class="cm"> * large page mapping for example).</span>
<span class="cm"> *</span>
<span class="cm"> * The following values give between one and two pages of free space</span>
<span class="cm"> * after typical minimal boot (2-way SMP, single disk and NIC) with</span>
<span class="cm"> * both defconfig and a distro config on x86_64 and 32.  More</span>
<span class="cm"> * intelligent way to determine this would be nice.</span>
<span class="cm"> */</span>
<span class="cp">#if BITS_PER_LONG &gt; 32</span>
<span class="cp">#define PERCPU_DYNAMIC_RESERVE		(20 &lt;&lt; 10)</span>
<span class="cp">#else</span>
<span class="cp">#define PERCPU_DYNAMIC_RESERVE		(12 &lt;&lt; 10)</span>
<span class="cp">#endif</span>

<span class="k">extern</span> <span class="kt">void</span> <span class="o">*</span><span class="n">pcpu_base_addr</span><span class="p">;</span>
<span class="k">extern</span> <span class="k">const</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="o">*</span><span class="n">pcpu_unit_offsets</span><span class="p">;</span>

<span class="k">struct</span> <span class="n">pcpu_group_info</span> <span class="p">{</span>
	<span class="kt">int</span>			<span class="n">nr_units</span><span class="p">;</span>	<span class="cm">/* aligned # of units */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span>		<span class="n">base_offset</span><span class="p">;</span>	<span class="cm">/* base address offset */</span>
	<span class="kt">unsigned</span> <span class="kt">int</span>		<span class="o">*</span><span class="n">cpu_map</span><span class="p">;</span>	<span class="cm">/* unit-&gt;cpu map, empty</span>
<span class="cm">						 * entries contain NR_CPUS */</span>
<span class="p">};</span>

<span class="k">struct</span> <span class="n">pcpu_alloc_info</span> <span class="p">{</span>
	<span class="kt">size_t</span>			<span class="n">static_size</span><span class="p">;</span>
	<span class="kt">size_t</span>			<span class="n">reserved_size</span><span class="p">;</span>
	<span class="kt">size_t</span>			<span class="n">dyn_size</span><span class="p">;</span>
	<span class="kt">size_t</span>			<span class="n">unit_size</span><span class="p">;</span>
	<span class="kt">size_t</span>			<span class="n">atom_size</span><span class="p">;</span>
	<span class="kt">size_t</span>			<span class="n">alloc_size</span><span class="p">;</span>
	<span class="kt">size_t</span>			<span class="n">__ai_size</span><span class="p">;</span>	<span class="cm">/* internal, don&#39;t use */</span>
	<span class="kt">int</span>			<span class="n">nr_groups</span><span class="p">;</span>	<span class="cm">/* 0 if grouping unnecessary */</span>
	<span class="k">struct</span> <span class="n">pcpu_group_info</span>	<span class="n">groups</span><span class="p">[];</span>
<span class="p">};</span>

<span class="k">enum</span> <span class="n">pcpu_fc</span> <span class="p">{</span>
	<span class="n">PCPU_FC_AUTO</span><span class="p">,</span>
	<span class="n">PCPU_FC_EMBED</span><span class="p">,</span>
	<span class="n">PCPU_FC_PAGE</span><span class="p">,</span>

	<span class="n">PCPU_FC_NR</span><span class="p">,</span>
<span class="p">};</span>
<span class="k">extern</span> <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">pcpu_fc_names</span><span class="p">[</span><span class="n">PCPU_FC_NR</span><span class="p">];</span>

<span class="k">extern</span> <span class="k">enum</span> <span class="n">pcpu_fc</span> <span class="n">pcpu_chosen_fc</span><span class="p">;</span>

<span class="k">typedef</span> <span class="kt">void</span> <span class="o">*</span> <span class="p">(</span><span class="o">*</span><span class="n">pcpu_fc_alloc_fn_t</span><span class="p">)(</span><span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">cpu</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span>
				     <span class="kt">size_t</span> <span class="n">align</span><span class="p">);</span>
<span class="k">typedef</span> <span class="kt">void</span> <span class="p">(</span><span class="o">*</span><span class="n">pcpu_fc_free_fn_t</span><span class="p">)(</span><span class="kt">void</span> <span class="o">*</span><span class="n">ptr</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">size</span><span class="p">);</span>
<span class="k">typedef</span> <span class="kt">void</span> <span class="p">(</span><span class="o">*</span><span class="n">pcpu_fc_populate_pte_fn_t</span><span class="p">)(</span><span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">addr</span><span class="p">);</span>
<span class="k">typedef</span> <span class="kt">int</span> <span class="p">(</span><span class="n">pcpu_fc_cpu_distance_fn_t</span><span class="p">)(</span><span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">from</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">to</span><span class="p">);</span>

<span class="k">extern</span> <span class="k">struct</span> <span class="n">pcpu_alloc_info</span> <span class="o">*</span> <span class="n">__init</span> <span class="n">pcpu_alloc_alloc_info</span><span class="p">(</span><span class="kt">int</span> <span class="n">nr_groups</span><span class="p">,</span>
							     <span class="kt">int</span> <span class="n">nr_units</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">__init</span> <span class="n">pcpu_free_alloc_info</span><span class="p">(</span><span class="k">struct</span> <span class="n">pcpu_alloc_info</span> <span class="o">*</span><span class="n">ai</span><span class="p">);</span>

<span class="k">extern</span> <span class="kt">int</span> <span class="n">__init</span> <span class="n">pcpu_setup_first_chunk</span><span class="p">(</span><span class="k">const</span> <span class="k">struct</span> <span class="n">pcpu_alloc_info</span> <span class="o">*</span><span class="n">ai</span><span class="p">,</span>
					 <span class="kt">void</span> <span class="o">*</span><span class="n">base_addr</span><span class="p">);</span>

<span class="cp">#ifdef CONFIG_NEED_PER_CPU_EMBED_FIRST_CHUNK</span>
<span class="k">extern</span> <span class="kt">int</span> <span class="n">__init</span> <span class="n">pcpu_embed_first_chunk</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">reserved_size</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">dyn_size</span><span class="p">,</span>
				<span class="kt">size_t</span> <span class="n">atom_size</span><span class="p">,</span>
				<span class="n">pcpu_fc_cpu_distance_fn_t</span> <span class="n">cpu_distance_fn</span><span class="p">,</span>
				<span class="n">pcpu_fc_alloc_fn_t</span> <span class="n">alloc_fn</span><span class="p">,</span>
				<span class="n">pcpu_fc_free_fn_t</span> <span class="n">free_fn</span><span class="p">);</span>
<span class="cp">#endif</span>

<span class="cp">#ifdef CONFIG_NEED_PER_CPU_PAGE_FIRST_CHUNK</span>
<span class="k">extern</span> <span class="kt">int</span> <span class="n">__init</span> <span class="n">pcpu_page_first_chunk</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">reserved_size</span><span class="p">,</span>
				<span class="n">pcpu_fc_alloc_fn_t</span> <span class="n">alloc_fn</span><span class="p">,</span>
				<span class="n">pcpu_fc_free_fn_t</span> <span class="n">free_fn</span><span class="p">,</span>
				<span class="n">pcpu_fc_populate_pte_fn_t</span> <span class="n">populate_pte_fn</span><span class="p">);</span>
<span class="cp">#endif</span>

<span class="cm">/*</span>
<span class="cm"> * Use this to get to a cpu&#39;s version of the per-cpu object</span>
<span class="cm"> * dynamically allocated. Non-atomic access to the current CPU&#39;s</span>
<span class="cm"> * version should probably be combined with get_cpu()/put_cpu().</span>
<span class="cm"> */</span>
<span class="cp">#ifdef CONFIG_SMP</span>
<span class="cp">#define per_cpu_ptr(ptr, cpu)	SHIFT_PERCPU_PTR((ptr), per_cpu_offset((cpu)))</span>
<span class="cp">#else</span>
<span class="cp">#define per_cpu_ptr(ptr, cpu)	({ (void)(cpu); VERIFY_PERCPU_PTR((ptr)); })</span>
<span class="cp">#endif</span>

<span class="k">extern</span> <span class="kt">void</span> <span class="n">__percpu</span> <span class="o">*</span><span class="n">__alloc_reserved_percpu</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">align</span><span class="p">);</span>
<span class="k">extern</span> <span class="n">bool</span> <span class="n">is_kernel_percpu_address</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">addr</span><span class="p">);</span>

<span class="cp">#if !defined(CONFIG_SMP) || !defined(CONFIG_HAVE_SETUP_PER_CPU_AREA)</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">__init</span> <span class="n">setup_per_cpu_areas</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span>
<span class="cp">#endif</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">__init</span> <span class="n">percpu_init_late</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span>

<span class="k">extern</span> <span class="kt">void</span> <span class="n">__percpu</span> <span class="o">*</span><span class="n">__alloc_percpu</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">align</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">free_percpu</span><span class="p">(</span><span class="kt">void</span> <span class="n">__percpu</span> <span class="o">*</span><span class="n">__pdata</span><span class="p">);</span>
<span class="k">extern</span> <span class="n">phys_addr_t</span> <span class="n">per_cpu_ptr_to_phys</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">addr</span><span class="p">);</span>

<span class="cp">#define alloc_percpu(type)	\</span>
<span class="cp">	(typeof(type) __percpu *)__alloc_percpu(sizeof(type), __alignof__(type))</span>

<span class="cm">/*</span>
<span class="cm"> * Branching function to split up a function into a set of functions that</span>
<span class="cm"> * are called for different scalar sizes of the objects handled.</span>
<span class="cm"> */</span>

<span class="k">extern</span> <span class="kt">void</span> <span class="n">__bad_size_call_parameter</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span>

<span class="cp">#define __pcpu_size_call_return(stem, variable)				\</span>
<span class="cp">({	typeof(variable) pscr_ret__;					\</span>
<span class="cp">	__verify_pcpu_ptr(&amp;(variable));					\</span>
<span class="cp">	switch(sizeof(variable)) {					\</span>
<span class="cp">	case 1: pscr_ret__ = stem##1(variable);break;			\</span>
<span class="cp">	case 2: pscr_ret__ = stem##2(variable);break;			\</span>
<span class="cp">	case 4: pscr_ret__ = stem##4(variable);break;			\</span>
<span class="cp">	case 8: pscr_ret__ = stem##8(variable);break;			\</span>
<span class="cp">	default:							\</span>
<span class="cp">		__bad_size_call_parameter();break;			\</span>
<span class="cp">	}								\</span>
<span class="cp">	pscr_ret__;							\</span>
<span class="cp">})</span>

<span class="cp">#define __pcpu_size_call_return2(stem, variable, ...)			\</span>
<span class="cp">({									\</span>
<span class="cp">	typeof(variable) pscr2_ret__;					\</span>
<span class="cp">	__verify_pcpu_ptr(&amp;(variable));					\</span>
<span class="cp">	switch(sizeof(variable)) {					\</span>
<span class="cp">	case 1: pscr2_ret__ = stem##1(variable, __VA_ARGS__); break;	\</span>
<span class="cp">	case 2: pscr2_ret__ = stem##2(variable, __VA_ARGS__); break;	\</span>
<span class="cp">	case 4: pscr2_ret__ = stem##4(variable, __VA_ARGS__); break;	\</span>
<span class="cp">	case 8: pscr2_ret__ = stem##8(variable, __VA_ARGS__); break;	\</span>
<span class="cp">	default:							\</span>
<span class="cp">		__bad_size_call_parameter(); break;			\</span>
<span class="cp">	}								\</span>
<span class="cp">	pscr2_ret__;							\</span>
<span class="cp">})</span>

<span class="cm">/*</span>
<span class="cm"> * Special handling for cmpxchg_double.  cmpxchg_double is passed two</span>
<span class="cm"> * percpu variables.  The first has to be aligned to a double word</span>
<span class="cm"> * boundary and the second has to follow directly thereafter.</span>
<span class="cm"> * We enforce this on all architectures even if they don&#39;t support</span>
<span class="cm"> * a double cmpxchg instruction, since it&#39;s a cheap requirement, and it</span>
<span class="cm"> * avoids breaking the requirement for architectures with the instruction.</span>
<span class="cm"> */</span>
<span class="cp">#define __pcpu_double_call_return_bool(stem, pcp1, pcp2, ...)		\</span>
<span class="cp">({									\</span>
<span class="cp">	bool pdcrb_ret__;						\</span>
<span class="cp">	__verify_pcpu_ptr(&amp;pcp1);					\</span>
<span class="cp">	BUILD_BUG_ON(sizeof(pcp1) != sizeof(pcp2));			\</span>
<span class="cp">	VM_BUG_ON((unsigned long)(&amp;pcp1) % (2 * sizeof(pcp1)));		\</span>
<span class="cp">	VM_BUG_ON((unsigned long)(&amp;pcp2) !=				\</span>
<span class="cp">		  (unsigned long)(&amp;pcp1) + sizeof(pcp1));		\</span>
<span class="cp">	switch(sizeof(pcp1)) {						\</span>
<span class="cp">	case 1: pdcrb_ret__ = stem##1(pcp1, pcp2, __VA_ARGS__); break;	\</span>
<span class="cp">	case 2: pdcrb_ret__ = stem##2(pcp1, pcp2, __VA_ARGS__); break;	\</span>
<span class="cp">	case 4: pdcrb_ret__ = stem##4(pcp1, pcp2, __VA_ARGS__); break;	\</span>
<span class="cp">	case 8: pdcrb_ret__ = stem##8(pcp1, pcp2, __VA_ARGS__); break;	\</span>
<span class="cp">	default:							\</span>
<span class="cp">		__bad_size_call_parameter(); break;			\</span>
<span class="cp">	}								\</span>
<span class="cp">	pdcrb_ret__;							\</span>
<span class="cp">})</span>

<span class="cp">#define __pcpu_size_call(stem, variable, ...)				\</span>
<span class="cp">do {									\</span>
<span class="cp">	__verify_pcpu_ptr(&amp;(variable));					\</span>
<span class="cp">	switch(sizeof(variable)) {					\</span>
<span class="cp">		case 1: stem##1(variable, __VA_ARGS__);break;		\</span>
<span class="cp">		case 2: stem##2(variable, __VA_ARGS__);break;		\</span>
<span class="cp">		case 4: stem##4(variable, __VA_ARGS__);break;		\</span>
<span class="cp">		case 8: stem##8(variable, __VA_ARGS__);break;		\</span>
<span class="cp">		default: 						\</span>
<span class="cp">			__bad_size_call_parameter();break;		\</span>
<span class="cp">	}								\</span>
<span class="cp">} while (0)</span>

<span class="cm">/*</span>
<span class="cm"> * Optimized manipulation for memory allocated through the per cpu</span>
<span class="cm"> * allocator or for addresses of per cpu variables.</span>
<span class="cm"> *</span>
<span class="cm"> * These operation guarantee exclusivity of access for other operations</span>
<span class="cm"> * on the *same* processor. The assumption is that per cpu data is only</span>
<span class="cm"> * accessed by a single processor instance (the current one).</span>
<span class="cm"> *</span>
<span class="cm"> * The first group is used for accesses that must be done in a</span>
<span class="cm"> * preemption safe way since we know that the context is not preempt</span>
<span class="cm"> * safe. Interrupts may occur. If the interrupt modifies the variable</span>
<span class="cm"> * too then RMW actions will not be reliable.</span>
<span class="cm"> *</span>
<span class="cm"> * The arch code can provide optimized functions in two ways:</span>
<span class="cm"> *</span>
<span class="cm"> * 1. Override the function completely. F.e. define this_cpu_add().</span>
<span class="cm"> *    The arch must then ensure that the various scalar format passed</span>
<span class="cm"> *    are handled correctly.</span>
<span class="cm"> *</span>
<span class="cm"> * 2. Provide functions for certain scalar sizes. F.e. provide</span>
<span class="cm"> *    this_cpu_add_2() to provide per cpu atomic operations for 2 byte</span>
<span class="cm"> *    sized RMW actions. If arch code does not provide operations for</span>
<span class="cm"> *    a scalar size then the fallback in the generic code will be</span>
<span class="cm"> *    used.</span>
<span class="cm"> */</span>

<span class="cp">#define _this_cpu_generic_read(pcp)					\</span>
<span class="cp">({	typeof(pcp) ret__;						\</span>
<span class="cp">	preempt_disable();						\</span>
<span class="cp">	ret__ = *this_cpu_ptr(&amp;(pcp));					\</span>
<span class="cp">	preempt_enable();						\</span>
<span class="cp">	ret__;								\</span>
<span class="cp">})</span>

<span class="cp">#ifndef this_cpu_read</span>
<span class="cp"># ifndef this_cpu_read_1</span>
<span class="cp">#  define this_cpu_read_1(pcp)	_this_cpu_generic_read(pcp)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_read_2</span>
<span class="cp">#  define this_cpu_read_2(pcp)	_this_cpu_generic_read(pcp)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_read_4</span>
<span class="cp">#  define this_cpu_read_4(pcp)	_this_cpu_generic_read(pcp)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_read_8</span>
<span class="cp">#  define this_cpu_read_8(pcp)	_this_cpu_generic_read(pcp)</span>
<span class="cp"># endif</span>
<span class="cp"># define this_cpu_read(pcp)	__pcpu_size_call_return(this_cpu_read_, (pcp))</span>
<span class="cp">#endif</span>

<span class="cp">#define _this_cpu_generic_to_op(pcp, val, op)				\</span>
<span class="cp">do {									\</span>
<span class="cp">	unsigned long flags;						\</span>
<span class="cp">	raw_local_irq_save(flags);					\</span>
<span class="cp">	*__this_cpu_ptr(&amp;(pcp)) op val;					\</span>
<span class="cp">	raw_local_irq_restore(flags);					\</span>
<span class="cp">} while (0)</span>

<span class="cp">#ifndef this_cpu_write</span>
<span class="cp"># ifndef this_cpu_write_1</span>
<span class="cp">#  define this_cpu_write_1(pcp, val)	_this_cpu_generic_to_op((pcp), (val), =)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_write_2</span>
<span class="cp">#  define this_cpu_write_2(pcp, val)	_this_cpu_generic_to_op((pcp), (val), =)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_write_4</span>
<span class="cp">#  define this_cpu_write_4(pcp, val)	_this_cpu_generic_to_op((pcp), (val), =)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_write_8</span>
<span class="cp">#  define this_cpu_write_8(pcp, val)	_this_cpu_generic_to_op((pcp), (val), =)</span>
<span class="cp"># endif</span>
<span class="cp"># define this_cpu_write(pcp, val)	__pcpu_size_call(this_cpu_write_, (pcp), (val))</span>
<span class="cp">#endif</span>

<span class="cp">#ifndef this_cpu_add</span>
<span class="cp"># ifndef this_cpu_add_1</span>
<span class="cp">#  define this_cpu_add_1(pcp, val)	_this_cpu_generic_to_op((pcp), (val), +=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_add_2</span>
<span class="cp">#  define this_cpu_add_2(pcp, val)	_this_cpu_generic_to_op((pcp), (val), +=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_add_4</span>
<span class="cp">#  define this_cpu_add_4(pcp, val)	_this_cpu_generic_to_op((pcp), (val), +=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_add_8</span>
<span class="cp">#  define this_cpu_add_8(pcp, val)	_this_cpu_generic_to_op((pcp), (val), +=)</span>
<span class="cp"># endif</span>
<span class="cp"># define this_cpu_add(pcp, val)		__pcpu_size_call(this_cpu_add_, (pcp), (val))</span>
<span class="cp">#endif</span>

<span class="cp">#ifndef this_cpu_sub</span>
<span class="cp"># define this_cpu_sub(pcp, val)		this_cpu_add((pcp), -(val))</span>
<span class="cp">#endif</span>

<span class="cp">#ifndef this_cpu_inc</span>
<span class="cp"># define this_cpu_inc(pcp)		this_cpu_add((pcp), 1)</span>
<span class="cp">#endif</span>

<span class="cp">#ifndef this_cpu_dec</span>
<span class="cp"># define this_cpu_dec(pcp)		this_cpu_sub((pcp), 1)</span>
<span class="cp">#endif</span>

<span class="cp">#ifndef this_cpu_and</span>
<span class="cp"># ifndef this_cpu_and_1</span>
<span class="cp">#  define this_cpu_and_1(pcp, val)	_this_cpu_generic_to_op((pcp), (val), &amp;=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_and_2</span>
<span class="cp">#  define this_cpu_and_2(pcp, val)	_this_cpu_generic_to_op((pcp), (val), &amp;=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_and_4</span>
<span class="cp">#  define this_cpu_and_4(pcp, val)	_this_cpu_generic_to_op((pcp), (val), &amp;=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_and_8</span>
<span class="cp">#  define this_cpu_and_8(pcp, val)	_this_cpu_generic_to_op((pcp), (val), &amp;=)</span>
<span class="cp"># endif</span>
<span class="cp"># define this_cpu_and(pcp, val)		__pcpu_size_call(this_cpu_and_, (pcp), (val))</span>
<span class="cp">#endif</span>

<span class="cp">#ifndef this_cpu_or</span>
<span class="cp"># ifndef this_cpu_or_1</span>
<span class="cp">#  define this_cpu_or_1(pcp, val)	_this_cpu_generic_to_op((pcp), (val), |=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_or_2</span>
<span class="cp">#  define this_cpu_or_2(pcp, val)	_this_cpu_generic_to_op((pcp), (val), |=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_or_4</span>
<span class="cp">#  define this_cpu_or_4(pcp, val)	_this_cpu_generic_to_op((pcp), (val), |=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_or_8</span>
<span class="cp">#  define this_cpu_or_8(pcp, val)	_this_cpu_generic_to_op((pcp), (val), |=)</span>
<span class="cp"># endif</span>
<span class="cp"># define this_cpu_or(pcp, val)		__pcpu_size_call(this_cpu_or_, (pcp), (val))</span>
<span class="cp">#endif</span>

<span class="cp">#ifndef this_cpu_xor</span>
<span class="cp"># ifndef this_cpu_xor_1</span>
<span class="cp">#  define this_cpu_xor_1(pcp, val)	_this_cpu_generic_to_op((pcp), (val), ^=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_xor_2</span>
<span class="cp">#  define this_cpu_xor_2(pcp, val)	_this_cpu_generic_to_op((pcp), (val), ^=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_xor_4</span>
<span class="cp">#  define this_cpu_xor_4(pcp, val)	_this_cpu_generic_to_op((pcp), (val), ^=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_xor_8</span>
<span class="cp">#  define this_cpu_xor_8(pcp, val)	_this_cpu_generic_to_op((pcp), (val), ^=)</span>
<span class="cp"># endif</span>
<span class="cp"># define this_cpu_xor(pcp, val)		__pcpu_size_call(this_cpu_or_, (pcp), (val))</span>
<span class="cp">#endif</span>

<span class="cp">#define _this_cpu_generic_add_return(pcp, val)				\</span>
<span class="cp">({									\</span>
<span class="cp">	typeof(pcp) ret__;						\</span>
<span class="cp">	unsigned long flags;						\</span>
<span class="cp">	raw_local_irq_save(flags);					\</span>
<span class="cp">	__this_cpu_add(pcp, val);					\</span>
<span class="cp">	ret__ = __this_cpu_read(pcp);					\</span>
<span class="cp">	raw_local_irq_restore(flags);					\</span>
<span class="cp">	ret__;								\</span>
<span class="cp">})</span>

<span class="cp">#ifndef this_cpu_add_return</span>
<span class="cp"># ifndef this_cpu_add_return_1</span>
<span class="cp">#  define this_cpu_add_return_1(pcp, val)	_this_cpu_generic_add_return(pcp, val)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_add_return_2</span>
<span class="cp">#  define this_cpu_add_return_2(pcp, val)	_this_cpu_generic_add_return(pcp, val)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_add_return_4</span>
<span class="cp">#  define this_cpu_add_return_4(pcp, val)	_this_cpu_generic_add_return(pcp, val)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_add_return_8</span>
<span class="cp">#  define this_cpu_add_return_8(pcp, val)	_this_cpu_generic_add_return(pcp, val)</span>
<span class="cp"># endif</span>
<span class="cp"># define this_cpu_add_return(pcp, val)	__pcpu_size_call_return2(this_cpu_add_return_, pcp, val)</span>
<span class="cp">#endif</span>

<span class="cp">#define this_cpu_sub_return(pcp, val)	this_cpu_add_return(pcp, -(val))</span>
<span class="cp">#define this_cpu_inc_return(pcp)	this_cpu_add_return(pcp, 1)</span>
<span class="cp">#define this_cpu_dec_return(pcp)	this_cpu_add_return(pcp, -1)</span>

<span class="cp">#define _this_cpu_generic_xchg(pcp, nval)				\</span>
<span class="cp">({	typeof(pcp) ret__;						\</span>
<span class="cp">	unsigned long flags;						\</span>
<span class="cp">	raw_local_irq_save(flags);					\</span>
<span class="cp">	ret__ = __this_cpu_read(pcp);					\</span>
<span class="cp">	__this_cpu_write(pcp, nval);					\</span>
<span class="cp">	raw_local_irq_restore(flags);					\</span>
<span class="cp">	ret__;								\</span>
<span class="cp">})</span>

<span class="cp">#ifndef this_cpu_xchg</span>
<span class="cp"># ifndef this_cpu_xchg_1</span>
<span class="cp">#  define this_cpu_xchg_1(pcp, nval)	_this_cpu_generic_xchg(pcp, nval)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_xchg_2</span>
<span class="cp">#  define this_cpu_xchg_2(pcp, nval)	_this_cpu_generic_xchg(pcp, nval)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_xchg_4</span>
<span class="cp">#  define this_cpu_xchg_4(pcp, nval)	_this_cpu_generic_xchg(pcp, nval)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_xchg_8</span>
<span class="cp">#  define this_cpu_xchg_8(pcp, nval)	_this_cpu_generic_xchg(pcp, nval)</span>
<span class="cp"># endif</span>
<span class="cp"># define this_cpu_xchg(pcp, nval)	\</span>
<span class="cp">	__pcpu_size_call_return2(this_cpu_xchg_, (pcp), nval)</span>
<span class="cp">#endif</span>

<span class="cp">#define _this_cpu_generic_cmpxchg(pcp, oval, nval)			\</span>
<span class="cp">({									\</span>
<span class="cp">	typeof(pcp) ret__;						\</span>
<span class="cp">	unsigned long flags;						\</span>
<span class="cp">	raw_local_irq_save(flags);					\</span>
<span class="cp">	ret__ = __this_cpu_read(pcp);					\</span>
<span class="cp">	if (ret__ == (oval))						\</span>
<span class="cp">		__this_cpu_write(pcp, nval);				\</span>
<span class="cp">	raw_local_irq_restore(flags);					\</span>
<span class="cp">	ret__;								\</span>
<span class="cp">})</span>

<span class="cp">#ifndef this_cpu_cmpxchg</span>
<span class="cp"># ifndef this_cpu_cmpxchg_1</span>
<span class="cp">#  define this_cpu_cmpxchg_1(pcp, oval, nval)	_this_cpu_generic_cmpxchg(pcp, oval, nval)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_cmpxchg_2</span>
<span class="cp">#  define this_cpu_cmpxchg_2(pcp, oval, nval)	_this_cpu_generic_cmpxchg(pcp, oval, nval)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_cmpxchg_4</span>
<span class="cp">#  define this_cpu_cmpxchg_4(pcp, oval, nval)	_this_cpu_generic_cmpxchg(pcp, oval, nval)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_cmpxchg_8</span>
<span class="cp">#  define this_cpu_cmpxchg_8(pcp, oval, nval)	_this_cpu_generic_cmpxchg(pcp, oval, nval)</span>
<span class="cp"># endif</span>
<span class="cp"># define this_cpu_cmpxchg(pcp, oval, nval)	\</span>
<span class="cp">	__pcpu_size_call_return2(this_cpu_cmpxchg_, pcp, oval, nval)</span>
<span class="cp">#endif</span>

<span class="cm">/*</span>
<span class="cm"> * cmpxchg_double replaces two adjacent scalars at once.  The first</span>
<span class="cm"> * two parameters are per cpu variables which have to be of the same</span>
<span class="cm"> * size.  A truth value is returned to indicate success or failure</span>
<span class="cm"> * (since a double register result is difficult to handle).  There is</span>
<span class="cm"> * very limited hardware support for these operations, so only certain</span>
<span class="cm"> * sizes may work.</span>
<span class="cm"> */</span>
<span class="cp">#define _this_cpu_generic_cmpxchg_double(pcp1, pcp2, oval1, oval2, nval1, nval2)	\</span>
<span class="cp">({									\</span>
<span class="cp">	int ret__;							\</span>
<span class="cp">	unsigned long flags;						\</span>
<span class="cp">	raw_local_irq_save(flags);					\</span>
<span class="cp">	ret__ = __this_cpu_generic_cmpxchg_double(pcp1, pcp2,		\</span>
<span class="cp">			oval1, oval2, nval1, nval2);			\</span>
<span class="cp">	raw_local_irq_restore(flags);					\</span>
<span class="cp">	ret__;								\</span>
<span class="cp">})</span>

<span class="cp">#ifndef this_cpu_cmpxchg_double</span>
<span class="cp"># ifndef this_cpu_cmpxchg_double_1</span>
<span class="cp">#  define this_cpu_cmpxchg_double_1(pcp1, pcp2, oval1, oval2, nval1, nval2)	\</span>
<span class="cp">	_this_cpu_generic_cmpxchg_double(pcp1, pcp2, oval1, oval2, nval1, nval2)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_cmpxchg_double_2</span>
<span class="cp">#  define this_cpu_cmpxchg_double_2(pcp1, pcp2, oval1, oval2, nval1, nval2)	\</span>
<span class="cp">	_this_cpu_generic_cmpxchg_double(pcp1, pcp2, oval1, oval2, nval1, nval2)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_cmpxchg_double_4</span>
<span class="cp">#  define this_cpu_cmpxchg_double_4(pcp1, pcp2, oval1, oval2, nval1, nval2)	\</span>
<span class="cp">	_this_cpu_generic_cmpxchg_double(pcp1, pcp2, oval1, oval2, nval1, nval2)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef this_cpu_cmpxchg_double_8</span>
<span class="cp">#  define this_cpu_cmpxchg_double_8(pcp1, pcp2, oval1, oval2, nval1, nval2)	\</span>
<span class="cp">	_this_cpu_generic_cmpxchg_double(pcp1, pcp2, oval1, oval2, nval1, nval2)</span>
<span class="cp"># endif</span>
<span class="cp"># define this_cpu_cmpxchg_double(pcp1, pcp2, oval1, oval2, nval1, nval2)	\</span>
<span class="cp">	__pcpu_double_call_return_bool(this_cpu_cmpxchg_double_, (pcp1), (pcp2), (oval1), (oval2), (nval1), (nval2))</span>
<span class="cp">#endif</span>

<span class="cm">/*</span>
<span class="cm"> * Generic percpu operations for context that are safe from preemption/interrupts.</span>
<span class="cm"> * Either we do not care about races or the caller has the</span>
<span class="cm"> * responsibility of handling preemption/interrupt issues. Arch code can still</span>
<span class="cm"> * override these instructions since the arch per cpu code may be more</span>
<span class="cm"> * efficient and may actually get race freeness for free (that is the</span>
<span class="cm"> * case for x86 for example).</span>
<span class="cm"> *</span>
<span class="cm"> * If there is no other protection through preempt disable and/or</span>
<span class="cm"> * disabling interupts then one of these RMW operations can show unexpected</span>
<span class="cm"> * behavior because the execution thread was rescheduled on another processor</span>
<span class="cm"> * or an interrupt occurred and the same percpu variable was modified from</span>
<span class="cm"> * the interrupt context.</span>
<span class="cm"> */</span>
<span class="cp">#ifndef __this_cpu_read</span>
<span class="cp"># ifndef __this_cpu_read_1</span>
<span class="cp">#  define __this_cpu_read_1(pcp)	(*__this_cpu_ptr(&amp;(pcp)))</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_read_2</span>
<span class="cp">#  define __this_cpu_read_2(pcp)	(*__this_cpu_ptr(&amp;(pcp)))</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_read_4</span>
<span class="cp">#  define __this_cpu_read_4(pcp)	(*__this_cpu_ptr(&amp;(pcp)))</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_read_8</span>
<span class="cp">#  define __this_cpu_read_8(pcp)	(*__this_cpu_ptr(&amp;(pcp)))</span>
<span class="cp"># endif</span>
<span class="cp"># define __this_cpu_read(pcp)	__pcpu_size_call_return(__this_cpu_read_, (pcp))</span>
<span class="cp">#endif</span>

<span class="cp">#define __this_cpu_generic_to_op(pcp, val, op)				\</span>
<span class="cp">do {									\</span>
<span class="cp">	*__this_cpu_ptr(&amp;(pcp)) op val;					\</span>
<span class="cp">} while (0)</span>

<span class="cp">#ifndef __this_cpu_write</span>
<span class="cp"># ifndef __this_cpu_write_1</span>
<span class="cp">#  define __this_cpu_write_1(pcp, val)	__this_cpu_generic_to_op((pcp), (val), =)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_write_2</span>
<span class="cp">#  define __this_cpu_write_2(pcp, val)	__this_cpu_generic_to_op((pcp), (val), =)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_write_4</span>
<span class="cp">#  define __this_cpu_write_4(pcp, val)	__this_cpu_generic_to_op((pcp), (val), =)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_write_8</span>
<span class="cp">#  define __this_cpu_write_8(pcp, val)	__this_cpu_generic_to_op((pcp), (val), =)</span>
<span class="cp"># endif</span>
<span class="cp"># define __this_cpu_write(pcp, val)	__pcpu_size_call(__this_cpu_write_, (pcp), (val))</span>
<span class="cp">#endif</span>

<span class="cp">#ifndef __this_cpu_add</span>
<span class="cp"># ifndef __this_cpu_add_1</span>
<span class="cp">#  define __this_cpu_add_1(pcp, val)	__this_cpu_generic_to_op((pcp), (val), +=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_add_2</span>
<span class="cp">#  define __this_cpu_add_2(pcp, val)	__this_cpu_generic_to_op((pcp), (val), +=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_add_4</span>
<span class="cp">#  define __this_cpu_add_4(pcp, val)	__this_cpu_generic_to_op((pcp), (val), +=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_add_8</span>
<span class="cp">#  define __this_cpu_add_8(pcp, val)	__this_cpu_generic_to_op((pcp), (val), +=)</span>
<span class="cp"># endif</span>
<span class="cp"># define __this_cpu_add(pcp, val)	__pcpu_size_call(__this_cpu_add_, (pcp), (val))</span>
<span class="cp">#endif</span>

<span class="cp">#ifndef __this_cpu_sub</span>
<span class="cp"># define __this_cpu_sub(pcp, val)	__this_cpu_add((pcp), -(val))</span>
<span class="cp">#endif</span>

<span class="cp">#ifndef __this_cpu_inc</span>
<span class="cp"># define __this_cpu_inc(pcp)		__this_cpu_add((pcp), 1)</span>
<span class="cp">#endif</span>

<span class="cp">#ifndef __this_cpu_dec</span>
<span class="cp"># define __this_cpu_dec(pcp)		__this_cpu_sub((pcp), 1)</span>
<span class="cp">#endif</span>

<span class="cp">#ifndef __this_cpu_and</span>
<span class="cp"># ifndef __this_cpu_and_1</span>
<span class="cp">#  define __this_cpu_and_1(pcp, val)	__this_cpu_generic_to_op((pcp), (val), &amp;=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_and_2</span>
<span class="cp">#  define __this_cpu_and_2(pcp, val)	__this_cpu_generic_to_op((pcp), (val), &amp;=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_and_4</span>
<span class="cp">#  define __this_cpu_and_4(pcp, val)	__this_cpu_generic_to_op((pcp), (val), &amp;=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_and_8</span>
<span class="cp">#  define __this_cpu_and_8(pcp, val)	__this_cpu_generic_to_op((pcp), (val), &amp;=)</span>
<span class="cp"># endif</span>
<span class="cp"># define __this_cpu_and(pcp, val)	__pcpu_size_call(__this_cpu_and_, (pcp), (val))</span>
<span class="cp">#endif</span>

<span class="cp">#ifndef __this_cpu_or</span>
<span class="cp"># ifndef __this_cpu_or_1</span>
<span class="cp">#  define __this_cpu_or_1(pcp, val)	__this_cpu_generic_to_op((pcp), (val), |=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_or_2</span>
<span class="cp">#  define __this_cpu_or_2(pcp, val)	__this_cpu_generic_to_op((pcp), (val), |=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_or_4</span>
<span class="cp">#  define __this_cpu_or_4(pcp, val)	__this_cpu_generic_to_op((pcp), (val), |=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_or_8</span>
<span class="cp">#  define __this_cpu_or_8(pcp, val)	__this_cpu_generic_to_op((pcp), (val), |=)</span>
<span class="cp"># endif</span>
<span class="cp"># define __this_cpu_or(pcp, val)	__pcpu_size_call(__this_cpu_or_, (pcp), (val))</span>
<span class="cp">#endif</span>

<span class="cp">#ifndef __this_cpu_xor</span>
<span class="cp"># ifndef __this_cpu_xor_1</span>
<span class="cp">#  define __this_cpu_xor_1(pcp, val)	__this_cpu_generic_to_op((pcp), (val), ^=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_xor_2</span>
<span class="cp">#  define __this_cpu_xor_2(pcp, val)	__this_cpu_generic_to_op((pcp), (val), ^=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_xor_4</span>
<span class="cp">#  define __this_cpu_xor_4(pcp, val)	__this_cpu_generic_to_op((pcp), (val), ^=)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_xor_8</span>
<span class="cp">#  define __this_cpu_xor_8(pcp, val)	__this_cpu_generic_to_op((pcp), (val), ^=)</span>
<span class="cp"># endif</span>
<span class="cp"># define __this_cpu_xor(pcp, val)	__pcpu_size_call(__this_cpu_xor_, (pcp), (val))</span>
<span class="cp">#endif</span>

<span class="cp">#define __this_cpu_generic_add_return(pcp, val)				\</span>
<span class="cp">({									\</span>
<span class="cp">	__this_cpu_add(pcp, val);					\</span>
<span class="cp">	__this_cpu_read(pcp);						\</span>
<span class="cp">})</span>

<span class="cp">#ifndef __this_cpu_add_return</span>
<span class="cp"># ifndef __this_cpu_add_return_1</span>
<span class="cp">#  define __this_cpu_add_return_1(pcp, val)	__this_cpu_generic_add_return(pcp, val)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_add_return_2</span>
<span class="cp">#  define __this_cpu_add_return_2(pcp, val)	__this_cpu_generic_add_return(pcp, val)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_add_return_4</span>
<span class="cp">#  define __this_cpu_add_return_4(pcp, val)	__this_cpu_generic_add_return(pcp, val)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_add_return_8</span>
<span class="cp">#  define __this_cpu_add_return_8(pcp, val)	__this_cpu_generic_add_return(pcp, val)</span>
<span class="cp"># endif</span>
<span class="cp"># define __this_cpu_add_return(pcp, val)	\</span>
<span class="cp">	__pcpu_size_call_return2(__this_cpu_add_return_, pcp, val)</span>
<span class="cp">#endif</span>

<span class="cp">#define __this_cpu_sub_return(pcp, val)	__this_cpu_add_return(pcp, -(val))</span>
<span class="cp">#define __this_cpu_inc_return(pcp)	__this_cpu_add_return(pcp, 1)</span>
<span class="cp">#define __this_cpu_dec_return(pcp)	__this_cpu_add_return(pcp, -1)</span>

<span class="cp">#define __this_cpu_generic_xchg(pcp, nval)				\</span>
<span class="cp">({	typeof(pcp) ret__;						\</span>
<span class="cp">	ret__ = __this_cpu_read(pcp);					\</span>
<span class="cp">	__this_cpu_write(pcp, nval);					\</span>
<span class="cp">	ret__;								\</span>
<span class="cp">})</span>

<span class="cp">#ifndef __this_cpu_xchg</span>
<span class="cp"># ifndef __this_cpu_xchg_1</span>
<span class="cp">#  define __this_cpu_xchg_1(pcp, nval)	__this_cpu_generic_xchg(pcp, nval)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_xchg_2</span>
<span class="cp">#  define __this_cpu_xchg_2(pcp, nval)	__this_cpu_generic_xchg(pcp, nval)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_xchg_4</span>
<span class="cp">#  define __this_cpu_xchg_4(pcp, nval)	__this_cpu_generic_xchg(pcp, nval)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_xchg_8</span>
<span class="cp">#  define __this_cpu_xchg_8(pcp, nval)	__this_cpu_generic_xchg(pcp, nval)</span>
<span class="cp"># endif</span>
<span class="cp"># define __this_cpu_xchg(pcp, nval)	\</span>
<span class="cp">	__pcpu_size_call_return2(__this_cpu_xchg_, (pcp), nval)</span>
<span class="cp">#endif</span>

<span class="cp">#define __this_cpu_generic_cmpxchg(pcp, oval, nval)			\</span>
<span class="cp">({									\</span>
<span class="cp">	typeof(pcp) ret__;						\</span>
<span class="cp">	ret__ = __this_cpu_read(pcp);					\</span>
<span class="cp">	if (ret__ == (oval))						\</span>
<span class="cp">		__this_cpu_write(pcp, nval);				\</span>
<span class="cp">	ret__;								\</span>
<span class="cp">})</span>

<span class="cp">#ifndef __this_cpu_cmpxchg</span>
<span class="cp"># ifndef __this_cpu_cmpxchg_1</span>
<span class="cp">#  define __this_cpu_cmpxchg_1(pcp, oval, nval)	__this_cpu_generic_cmpxchg(pcp, oval, nval)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_cmpxchg_2</span>
<span class="cp">#  define __this_cpu_cmpxchg_2(pcp, oval, nval)	__this_cpu_generic_cmpxchg(pcp, oval, nval)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_cmpxchg_4</span>
<span class="cp">#  define __this_cpu_cmpxchg_4(pcp, oval, nval)	__this_cpu_generic_cmpxchg(pcp, oval, nval)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_cmpxchg_8</span>
<span class="cp">#  define __this_cpu_cmpxchg_8(pcp, oval, nval)	__this_cpu_generic_cmpxchg(pcp, oval, nval)</span>
<span class="cp"># endif</span>
<span class="cp"># define __this_cpu_cmpxchg(pcp, oval, nval)	\</span>
<span class="cp">	__pcpu_size_call_return2(__this_cpu_cmpxchg_, pcp, oval, nval)</span>
<span class="cp">#endif</span>

<span class="cp">#define __this_cpu_generic_cmpxchg_double(pcp1, pcp2, oval1, oval2, nval1, nval2)	\</span>
<span class="cp">({									\</span>
<span class="cp">	int __ret = 0;							\</span>
<span class="cp">	if (__this_cpu_read(pcp1) == (oval1) &amp;&amp;				\</span>
<span class="cp">			 __this_cpu_read(pcp2)  == (oval2)) {		\</span>
<span class="cp">		__this_cpu_write(pcp1, (nval1));			\</span>
<span class="cp">		__this_cpu_write(pcp2, (nval2));			\</span>
<span class="cp">		__ret = 1;						\</span>
<span class="cp">	}								\</span>
<span class="cp">	(__ret);							\</span>
<span class="cp">})</span>

<span class="cp">#ifndef __this_cpu_cmpxchg_double</span>
<span class="cp"># ifndef __this_cpu_cmpxchg_double_1</span>
<span class="cp">#  define __this_cpu_cmpxchg_double_1(pcp1, pcp2, oval1, oval2, nval1, nval2)	\</span>
<span class="cp">	__this_cpu_generic_cmpxchg_double(pcp1, pcp2, oval1, oval2, nval1, nval2)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_cmpxchg_double_2</span>
<span class="cp">#  define __this_cpu_cmpxchg_double_2(pcp1, pcp2, oval1, oval2, nval1, nval2)	\</span>
<span class="cp">	__this_cpu_generic_cmpxchg_double(pcp1, pcp2, oval1, oval2, nval1, nval2)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_cmpxchg_double_4</span>
<span class="cp">#  define __this_cpu_cmpxchg_double_4(pcp1, pcp2, oval1, oval2, nval1, nval2)	\</span>
<span class="cp">	__this_cpu_generic_cmpxchg_double(pcp1, pcp2, oval1, oval2, nval1, nval2)</span>
<span class="cp"># endif</span>
<span class="cp"># ifndef __this_cpu_cmpxchg_double_8</span>
<span class="cp">#  define __this_cpu_cmpxchg_double_8(pcp1, pcp2, oval1, oval2, nval1, nval2)	\</span>
<span class="cp">	__this_cpu_generic_cmpxchg_double(pcp1, pcp2, oval1, oval2, nval1, nval2)</span>
<span class="cp"># endif</span>
<span class="cp"># define __this_cpu_cmpxchg_double(pcp1, pcp2, oval1, oval2, nval1, nval2)	\</span>
<span class="cp">	__pcpu_double_call_return_bool(__this_cpu_cmpxchg_double_, (pcp1), (pcp2), (oval1), (oval2), (nval1), (nval2))</span>
<span class="cp">#endif</span>

<span class="cp">#endif </span><span class="cm">/* __LINUX_PERCPU_H */</span><span class="cp"></span>

</pre></div></td></tr>

</tbody>
</table>
</div>

</body>
<script>docas={repo:"joekychen/linux",depth:2}</script>
<script>document.write('<script src=' + ('__proto__' in {} ? 'http://cdnjs.cloudflare.com/ajax/libs/zepto/1.0rc1/zepto.min.js' : 'https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js')+'><\\/script>')</script>
<script src="http://baoshan.github.com/moment/min/moment.min.js"></script>
<script src="../../javascript/docco.min.js"></script>
</html>
