<!DOCTYPE html>
<html><head><title>joekychen/linux » include › linux › perf_event.h

</title>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta name="generator" content="Docco">
<link rel="stylesheet" media="all" href="../../stylesheets/docco.min.css" />


</head>
<body>
<div id="container">
<div id="background"></div>
<table cellpadding="0" cellspacing="0">
<thead><tr><th class="docs"><a id="home" href="../../index.html"></a><h1>perf_event.h</h1></th><th class="code"></th></tr></thead>
<tbody>


<tr id="section-1"><td class="docs"><div class="pilwrap"><a class="pilcrow" href="#section-1">&#182;</a></div></td><td class="code"><div class="highlight"><pre><span class="cm">/*</span>
<span class="cm"> * Performance events:</span>
<span class="cm"> *</span>
<span class="cm"> *    Copyright (C) 2008-2009, Thomas Gleixner &lt;tglx@linutronix.de&gt;</span>
<span class="cm"> *    Copyright (C) 2008-2011, Red Hat, Inc., Ingo Molnar</span>
<span class="cm"> *    Copyright (C) 2008-2011, Red Hat, Inc., Peter Zijlstra</span>
<span class="cm"> *</span>
<span class="cm"> * Data type definitions, declarations, prototypes.</span>
<span class="cm"> *</span>
<span class="cm"> *    Started by: Thomas Gleixner and Ingo Molnar</span>
<span class="cm"> *</span>
<span class="cm"> * For licencing details see kernel-base/COPYING</span>
<span class="cm"> */</span>
<span class="cp">#ifndef _LINUX_PERF_EVENT_H</span>
<span class="cp">#define _LINUX_PERF_EVENT_H</span>

<span class="cp">#include &lt;linux/types.h&gt;</span>
<span class="cp">#include &lt;linux/ioctl.h&gt;</span>
<span class="cp">#include &lt;asm/byteorder.h&gt;</span>

<span class="cm">/*</span>
<span class="cm"> * User-space ABI bits:</span>
<span class="cm"> */</span>

<span class="cm">/*</span>
<span class="cm"> * attr.type</span>
<span class="cm"> */</span>
<span class="k">enum</span> <span class="n">perf_type_id</span> <span class="p">{</span>
	<span class="n">PERF_TYPE_HARDWARE</span>			<span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
	<span class="n">PERF_TYPE_SOFTWARE</span>			<span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
	<span class="n">PERF_TYPE_TRACEPOINT</span>			<span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
	<span class="n">PERF_TYPE_HW_CACHE</span>			<span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
	<span class="n">PERF_TYPE_RAW</span>				<span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
	<span class="n">PERF_TYPE_BREAKPOINT</span>			<span class="o">=</span> <span class="mi">5</span><span class="p">,</span>

	<span class="n">PERF_TYPE_MAX</span><span class="p">,</span>				<span class="cm">/* non-ABI */</span>
<span class="p">};</span>

<span class="cm">/*</span>
<span class="cm"> * Generalized performance event event_id types, used by the</span>
<span class="cm"> * attr.event_id parameter of the sys_perf_event_open()</span>
<span class="cm"> * syscall:</span>
<span class="cm"> */</span>
<span class="k">enum</span> <span class="n">perf_hw_id</span> <span class="p">{</span>
	<span class="cm">/*</span>
<span class="cm">	 * Common hardware events, generalized by the kernel:</span>
<span class="cm">	 */</span>
	<span class="n">PERF_COUNT_HW_CPU_CYCLES</span>		<span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
	<span class="n">PERF_COUNT_HW_INSTRUCTIONS</span>		<span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
	<span class="n">PERF_COUNT_HW_CACHE_REFERENCES</span>		<span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
	<span class="n">PERF_COUNT_HW_CACHE_MISSES</span>		<span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
	<span class="n">PERF_COUNT_HW_BRANCH_INSTRUCTIONS</span>	<span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
	<span class="n">PERF_COUNT_HW_BRANCH_MISSES</span>		<span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
	<span class="n">PERF_COUNT_HW_BUS_CYCLES</span>		<span class="o">=</span> <span class="mi">6</span><span class="p">,</span>
	<span class="n">PERF_COUNT_HW_STALLED_CYCLES_FRONTEND</span>	<span class="o">=</span> <span class="mi">7</span><span class="p">,</span>
	<span class="n">PERF_COUNT_HW_STALLED_CYCLES_BACKEND</span>	<span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
	<span class="n">PERF_COUNT_HW_REF_CPU_CYCLES</span>		<span class="o">=</span> <span class="mi">9</span><span class="p">,</span>

	<span class="n">PERF_COUNT_HW_MAX</span><span class="p">,</span>			<span class="cm">/* non-ABI */</span>
<span class="p">};</span>

<span class="cm">/*</span>
<span class="cm"> * Generalized hardware cache events:</span>
<span class="cm"> *</span>
<span class="cm"> *       { L1-D, L1-I, LLC, ITLB, DTLB, BPU, NODE } x</span>
<span class="cm"> *       { read, write, prefetch } x</span>
<span class="cm"> *       { accesses, misses }</span>
<span class="cm"> */</span>
<span class="k">enum</span> <span class="n">perf_hw_cache_id</span> <span class="p">{</span>
	<span class="n">PERF_COUNT_HW_CACHE_L1D</span>			<span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
	<span class="n">PERF_COUNT_HW_CACHE_L1I</span>			<span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
	<span class="n">PERF_COUNT_HW_CACHE_LL</span>			<span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
	<span class="n">PERF_COUNT_HW_CACHE_DTLB</span>		<span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
	<span class="n">PERF_COUNT_HW_CACHE_ITLB</span>		<span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
	<span class="n">PERF_COUNT_HW_CACHE_BPU</span>			<span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
	<span class="n">PERF_COUNT_HW_CACHE_NODE</span>		<span class="o">=</span> <span class="mi">6</span><span class="p">,</span>

	<span class="n">PERF_COUNT_HW_CACHE_MAX</span><span class="p">,</span>		<span class="cm">/* non-ABI */</span>
<span class="p">};</span>

<span class="k">enum</span> <span class="n">perf_hw_cache_op_id</span> <span class="p">{</span>
	<span class="n">PERF_COUNT_HW_CACHE_OP_READ</span>		<span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
	<span class="n">PERF_COUNT_HW_CACHE_OP_WRITE</span>		<span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
	<span class="n">PERF_COUNT_HW_CACHE_OP_PREFETCH</span>		<span class="o">=</span> <span class="mi">2</span><span class="p">,</span>

	<span class="n">PERF_COUNT_HW_CACHE_OP_MAX</span><span class="p">,</span>		<span class="cm">/* non-ABI */</span>
<span class="p">};</span>

<span class="k">enum</span> <span class="n">perf_hw_cache_op_result_id</span> <span class="p">{</span>
	<span class="n">PERF_COUNT_HW_CACHE_RESULT_ACCESS</span>	<span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
	<span class="n">PERF_COUNT_HW_CACHE_RESULT_MISS</span>		<span class="o">=</span> <span class="mi">1</span><span class="p">,</span>

	<span class="n">PERF_COUNT_HW_CACHE_RESULT_MAX</span><span class="p">,</span>		<span class="cm">/* non-ABI */</span>
<span class="p">};</span>

<span class="cm">/*</span>
<span class="cm"> * Special &quot;software&quot; events provided by the kernel, even if the hardware</span>
<span class="cm"> * does not support performance events. These events measure various</span>
<span class="cm"> * physical and sw events of the kernel (and allow the profiling of them as</span>
<span class="cm"> * well):</span>
<span class="cm"> */</span>
<span class="k">enum</span> <span class="n">perf_sw_ids</span> <span class="p">{</span>
	<span class="n">PERF_COUNT_SW_CPU_CLOCK</span>			<span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
	<span class="n">PERF_COUNT_SW_TASK_CLOCK</span>		<span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
	<span class="n">PERF_COUNT_SW_PAGE_FAULTS</span>		<span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
	<span class="n">PERF_COUNT_SW_CONTEXT_SWITCHES</span>		<span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
	<span class="n">PERF_COUNT_SW_CPU_MIGRATIONS</span>		<span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
	<span class="n">PERF_COUNT_SW_PAGE_FAULTS_MIN</span>		<span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
	<span class="n">PERF_COUNT_SW_PAGE_FAULTS_MAJ</span>		<span class="o">=</span> <span class="mi">6</span><span class="p">,</span>
	<span class="n">PERF_COUNT_SW_ALIGNMENT_FAULTS</span>		<span class="o">=</span> <span class="mi">7</span><span class="p">,</span>
	<span class="n">PERF_COUNT_SW_EMULATION_FAULTS</span>		<span class="o">=</span> <span class="mi">8</span><span class="p">,</span>

	<span class="n">PERF_COUNT_SW_MAX</span><span class="p">,</span>			<span class="cm">/* non-ABI */</span>
<span class="p">};</span>

<span class="cm">/*</span>
<span class="cm"> * Bits that can be set in attr.sample_type to request information</span>
<span class="cm"> * in the overflow packets.</span>
<span class="cm"> */</span>
<span class="k">enum</span> <span class="n">perf_event_sample_format</span> <span class="p">{</span>
	<span class="n">PERF_SAMPLE_IP</span>				<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">0</span><span class="p">,</span>
	<span class="n">PERF_SAMPLE_TID</span>				<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">1</span><span class="p">,</span>
	<span class="n">PERF_SAMPLE_TIME</span>			<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">2</span><span class="p">,</span>
	<span class="n">PERF_SAMPLE_ADDR</span>			<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">3</span><span class="p">,</span>
	<span class="n">PERF_SAMPLE_READ</span>			<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">4</span><span class="p">,</span>
	<span class="n">PERF_SAMPLE_CALLCHAIN</span>			<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">5</span><span class="p">,</span>
	<span class="n">PERF_SAMPLE_ID</span>				<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">6</span><span class="p">,</span>
	<span class="n">PERF_SAMPLE_CPU</span>				<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">7</span><span class="p">,</span>
	<span class="n">PERF_SAMPLE_PERIOD</span>			<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">8</span><span class="p">,</span>
	<span class="n">PERF_SAMPLE_STREAM_ID</span>			<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">9</span><span class="p">,</span>
	<span class="n">PERF_SAMPLE_RAW</span>				<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">10</span><span class="p">,</span>
	<span class="n">PERF_SAMPLE_BRANCH_STACK</span>		<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">11</span><span class="p">,</span>

	<span class="n">PERF_SAMPLE_MAX</span> <span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">12</span><span class="p">,</span>		<span class="cm">/* non-ABI */</span>
<span class="p">};</span>

<span class="cm">/*</span>
<span class="cm"> * values to program into branch_sample_type when PERF_SAMPLE_BRANCH is set</span>
<span class="cm"> *</span>
<span class="cm"> * If the user does not pass priv level information via branch_sample_type,</span>
<span class="cm"> * the kernel uses the event&#39;s priv level. Branch and event priv levels do</span>
<span class="cm"> * not have to match. Branch priv level is checked for permissions.</span>
<span class="cm"> *</span>
<span class="cm"> * The branch types can be combined, however BRANCH_ANY covers all types</span>
<span class="cm"> * of branches and therefore it supersedes all the other types.</span>
<span class="cm"> */</span>
<span class="k">enum</span> <span class="n">perf_branch_sample_type</span> <span class="p">{</span>
	<span class="n">PERF_SAMPLE_BRANCH_USER</span>		<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">0</span><span class="p">,</span> <span class="cm">/* user branches */</span>
	<span class="n">PERF_SAMPLE_BRANCH_KERNEL</span>	<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">1</span><span class="p">,</span> <span class="cm">/* kernel branches */</span>
	<span class="n">PERF_SAMPLE_BRANCH_HV</span>		<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">2</span><span class="p">,</span> <span class="cm">/* hypervisor branches */</span>

	<span class="n">PERF_SAMPLE_BRANCH_ANY</span>		<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">3</span><span class="p">,</span> <span class="cm">/* any branch types */</span>
	<span class="n">PERF_SAMPLE_BRANCH_ANY_CALL</span>	<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">4</span><span class="p">,</span> <span class="cm">/* any call branch */</span>
	<span class="n">PERF_SAMPLE_BRANCH_ANY_RETURN</span>	<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">5</span><span class="p">,</span> <span class="cm">/* any return branch */</span>
	<span class="n">PERF_SAMPLE_BRANCH_IND_CALL</span>	<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">6</span><span class="p">,</span> <span class="cm">/* indirect calls */</span>

	<span class="n">PERF_SAMPLE_BRANCH_MAX</span>		<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">7</span><span class="p">,</span> <span class="cm">/* non-ABI */</span>
<span class="p">};</span>

<span class="cp">#define PERF_SAMPLE_BRANCH_PLM_ALL \</span>
<span class="cp">	(PERF_SAMPLE_BRANCH_USER|\</span>
<span class="cp">	 PERF_SAMPLE_BRANCH_KERNEL|\</span>
<span class="cp">	 PERF_SAMPLE_BRANCH_HV)</span>

<span class="cm">/*</span>
<span class="cm"> * The format of the data returned by read() on a perf event fd,</span>
<span class="cm"> * as specified by attr.read_format:</span>
<span class="cm"> *</span>
<span class="cm"> * struct read_format {</span>
<span class="cm"> *	{ u64		value;</span>
<span class="cm"> *	  { u64		time_enabled; } &amp;&amp; PERF_FORMAT_TOTAL_TIME_ENABLED</span>
<span class="cm"> *	  { u64		time_running; } &amp;&amp; PERF_FORMAT_TOTAL_TIME_RUNNING</span>
<span class="cm"> *	  { u64		id;           } &amp;&amp; PERF_FORMAT_ID</span>
<span class="cm"> *	} &amp;&amp; !PERF_FORMAT_GROUP</span>
<span class="cm"> *</span>
<span class="cm"> *	{ u64		nr;</span>
<span class="cm"> *	  { u64		time_enabled; } &amp;&amp; PERF_FORMAT_TOTAL_TIME_ENABLED</span>
<span class="cm"> *	  { u64		time_running; } &amp;&amp; PERF_FORMAT_TOTAL_TIME_RUNNING</span>
<span class="cm"> *	  { u64		value;</span>
<span class="cm"> *	    { u64	id;           } &amp;&amp; PERF_FORMAT_ID</span>
<span class="cm"> *	  }		cntr[nr];</span>
<span class="cm"> *	} &amp;&amp; PERF_FORMAT_GROUP</span>
<span class="cm"> * };</span>
<span class="cm"> */</span>
<span class="k">enum</span> <span class="n">perf_event_read_format</span> <span class="p">{</span>
	<span class="n">PERF_FORMAT_TOTAL_TIME_ENABLED</span>		<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">0</span><span class="p">,</span>
	<span class="n">PERF_FORMAT_TOTAL_TIME_RUNNING</span>		<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">1</span><span class="p">,</span>
	<span class="n">PERF_FORMAT_ID</span>				<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">2</span><span class="p">,</span>
	<span class="n">PERF_FORMAT_GROUP</span>			<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">3</span><span class="p">,</span>

	<span class="n">PERF_FORMAT_MAX</span> <span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">4</span><span class="p">,</span>		<span class="cm">/* non-ABI */</span>
<span class="p">};</span>

<span class="cp">#define PERF_ATTR_SIZE_VER0	64	</span><span class="cm">/* sizeof first published struct */</span><span class="cp"></span>
<span class="cp">#define PERF_ATTR_SIZE_VER1	72	</span><span class="cm">/* add: config2 */</span><span class="cp"></span>
<span class="cp">#define PERF_ATTR_SIZE_VER2	80	</span><span class="cm">/* add: branch_sample_type */</span><span class="cp"></span>

<span class="cm">/*</span>
<span class="cm"> * Hardware event_id to monitor via a performance monitoring event:</span>
<span class="cm"> */</span>
<span class="k">struct</span> <span class="n">perf_event_attr</span> <span class="p">{</span>

	<span class="cm">/*</span>
<span class="cm">	 * Major type: hardware/software/tracepoint/etc.</span>
<span class="cm">	 */</span>
	<span class="n">__u32</span>			<span class="n">type</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * Size of the attr structure, for fwd/bwd compat.</span>
<span class="cm">	 */</span>
	<span class="n">__u32</span>			<span class="n">size</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * Type specific configuration information.</span>
<span class="cm">	 */</span>
	<span class="n">__u64</span>			<span class="n">config</span><span class="p">;</span>

	<span class="k">union</span> <span class="p">{</span>
		<span class="n">__u64</span>		<span class="n">sample_period</span><span class="p">;</span>
		<span class="n">__u64</span>		<span class="n">sample_freq</span><span class="p">;</span>
	<span class="p">};</span>

	<span class="n">__u64</span>			<span class="n">sample_type</span><span class="p">;</span>
	<span class="n">__u64</span>			<span class="n">read_format</span><span class="p">;</span>

	<span class="n">__u64</span>			<span class="n">disabled</span>       <span class="o">:</span>  <span class="mi">1</span><span class="p">,</span> <span class="cm">/* off by default        */</span>
				<span class="n">inherit</span>	       <span class="o">:</span>  <span class="mi">1</span><span class="p">,</span> <span class="cm">/* children inherit it   */</span>
				<span class="n">pinned</span>	       <span class="o">:</span>  <span class="mi">1</span><span class="p">,</span> <span class="cm">/* must always be on PMU */</span>
				<span class="n">exclusive</span>      <span class="o">:</span>  <span class="mi">1</span><span class="p">,</span> <span class="cm">/* only group on PMU     */</span>
				<span class="n">exclude_user</span>   <span class="o">:</span>  <span class="mi">1</span><span class="p">,</span> <span class="cm">/* don&#39;t count user      */</span>
				<span class="n">exclude_kernel</span> <span class="o">:</span>  <span class="mi">1</span><span class="p">,</span> <span class="cm">/* ditto kernel          */</span>
				<span class="n">exclude_hv</span>     <span class="o">:</span>  <span class="mi">1</span><span class="p">,</span> <span class="cm">/* ditto hypervisor      */</span>
				<span class="n">exclude_idle</span>   <span class="o">:</span>  <span class="mi">1</span><span class="p">,</span> <span class="cm">/* don&#39;t count when idle */</span>
				<span class="n">mmap</span>           <span class="o">:</span>  <span class="mi">1</span><span class="p">,</span> <span class="cm">/* include mmap data     */</span>
				<span class="n">comm</span>	       <span class="o">:</span>  <span class="mi">1</span><span class="p">,</span> <span class="cm">/* include comm data     */</span>
				<span class="n">freq</span>           <span class="o">:</span>  <span class="mi">1</span><span class="p">,</span> <span class="cm">/* use freq, not period  */</span>
				<span class="n">inherit_stat</span>   <span class="o">:</span>  <span class="mi">1</span><span class="p">,</span> <span class="cm">/* per task counts       */</span>
				<span class="n">enable_on_exec</span> <span class="o">:</span>  <span class="mi">1</span><span class="p">,</span> <span class="cm">/* next exec enables     */</span>
				<span class="n">task</span>           <span class="o">:</span>  <span class="mi">1</span><span class="p">,</span> <span class="cm">/* trace fork/exit       */</span>
				<span class="n">watermark</span>      <span class="o">:</span>  <span class="mi">1</span><span class="p">,</span> <span class="cm">/* wakeup_watermark      */</span>
				<span class="cm">/*</span>
<span class="cm">				 * precise_ip:</span>
<span class="cm">				 *</span>
<span class="cm">				 *  0 - SAMPLE_IP can have arbitrary skid</span>
<span class="cm">				 *  1 - SAMPLE_IP must have constant skid</span>
<span class="cm">				 *  2 - SAMPLE_IP requested to have 0 skid</span>
<span class="cm">				 *  3 - SAMPLE_IP must have 0 skid</span>
<span class="cm">				 *</span>
<span class="cm">				 *  See also PERF_RECORD_MISC_EXACT_IP</span>
<span class="cm">				 */</span>
				<span class="n">precise_ip</span>     <span class="o">:</span>  <span class="mi">2</span><span class="p">,</span> <span class="cm">/* skid constraint       */</span>
				<span class="n">mmap_data</span>      <span class="o">:</span>  <span class="mi">1</span><span class="p">,</span> <span class="cm">/* non-exec mmap data    */</span>
				<span class="n">sample_id_all</span>  <span class="o">:</span>  <span class="mi">1</span><span class="p">,</span> <span class="cm">/* sample_type all events */</span>

				<span class="n">exclude_host</span>   <span class="o">:</span>  <span class="mi">1</span><span class="p">,</span> <span class="cm">/* don&#39;t count in host   */</span>
				<span class="n">exclude_guest</span>  <span class="o">:</span>  <span class="mi">1</span><span class="p">,</span> <span class="cm">/* don&#39;t count in guest  */</span>

				<span class="n">__reserved_1</span>   <span class="o">:</span> <span class="mi">43</span><span class="p">;</span>

	<span class="k">union</span> <span class="p">{</span>
		<span class="n">__u32</span>		<span class="n">wakeup_events</span><span class="p">;</span>	  <span class="cm">/* wakeup every n events */</span>
		<span class="n">__u32</span>		<span class="n">wakeup_watermark</span><span class="p">;</span> <span class="cm">/* bytes before wakeup   */</span>
	<span class="p">};</span>

	<span class="n">__u32</span>			<span class="n">bp_type</span><span class="p">;</span>
	<span class="k">union</span> <span class="p">{</span>
		<span class="n">__u64</span>		<span class="n">bp_addr</span><span class="p">;</span>
		<span class="n">__u64</span>		<span class="n">config1</span><span class="p">;</span> <span class="cm">/* extension of config */</span>
	<span class="p">};</span>
	<span class="k">union</span> <span class="p">{</span>
		<span class="n">__u64</span>		<span class="n">bp_len</span><span class="p">;</span>
		<span class="n">__u64</span>		<span class="n">config2</span><span class="p">;</span> <span class="cm">/* extension of config1 */</span>
	<span class="p">};</span>
	<span class="n">__u64</span>	<span class="n">branch_sample_type</span><span class="p">;</span> <span class="cm">/* enum branch_sample_type */</span>
<span class="p">};</span>

<span class="cm">/*</span>
<span class="cm"> * Ioctls that can be done on a perf event fd:</span>
<span class="cm"> */</span>
<span class="cp">#define PERF_EVENT_IOC_ENABLE		_IO (&#39;$&#39;, 0)</span>
<span class="cp">#define PERF_EVENT_IOC_DISABLE		_IO (&#39;$&#39;, 1)</span>
<span class="cp">#define PERF_EVENT_IOC_REFRESH		_IO (&#39;$&#39;, 2)</span>
<span class="cp">#define PERF_EVENT_IOC_RESET		_IO (&#39;$&#39;, 3)</span>
<span class="cp">#define PERF_EVENT_IOC_PERIOD		_IOW(&#39;$&#39;, 4, __u64)</span>
<span class="cp">#define PERF_EVENT_IOC_SET_OUTPUT	_IO (&#39;$&#39;, 5)</span>
<span class="cp">#define PERF_EVENT_IOC_SET_FILTER	_IOW(&#39;$&#39;, 6, char *)</span>

<span class="k">enum</span> <span class="n">perf_event_ioc_flags</span> <span class="p">{</span>
	<span class="n">PERF_IOC_FLAG_GROUP</span>		<span class="o">=</span> <span class="mi">1U</span> <span class="o">&lt;&lt;</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">};</span>

<span class="cm">/*</span>
<span class="cm"> * Structure of the page that can be mapped via mmap</span>
<span class="cm"> */</span>
<span class="k">struct</span> <span class="n">perf_event_mmap_page</span> <span class="p">{</span>
	<span class="n">__u32</span>	<span class="n">version</span><span class="p">;</span>		<span class="cm">/* version number of this structure */</span>
	<span class="n">__u32</span>	<span class="n">compat_version</span><span class="p">;</span>		<span class="cm">/* lowest version this is compat with */</span>

	<span class="cm">/*</span>
<span class="cm">	 * Bits needed to read the hw events in user-space.</span>
<span class="cm">	 *</span>
<span class="cm">	 *   u32 seq, time_mult, time_shift, idx, width;</span>
<span class="cm">	 *   u64 count, enabled, running;</span>
<span class="cm">	 *   u64 cyc, time_offset;</span>
<span class="cm">	 *   s64 pmc = 0;</span>
<span class="cm">	 *</span>
<span class="cm">	 *   do {</span>
<span class="cm">	 *     seq = pc-&gt;lock;</span>
<span class="cm">	 *     barrier()</span>
<span class="cm">	 *</span>
<span class="cm">	 *     enabled = pc-&gt;time_enabled;</span>
<span class="cm">	 *     running = pc-&gt;time_running;</span>
<span class="cm">	 *</span>
<span class="cm">	 *     if (pc-&gt;cap_usr_time &amp;&amp; enabled != running) {</span>
<span class="cm">	 *       cyc = rdtsc();</span>
<span class="cm">	 *       time_offset = pc-&gt;time_offset;</span>
<span class="cm">	 *       time_mult   = pc-&gt;time_mult;</span>
<span class="cm">	 *       time_shift  = pc-&gt;time_shift;</span>
<span class="cm">	 *     }</span>
<span class="cm">	 *</span>
<span class="cm">	 *     idx = pc-&gt;index;</span>
<span class="cm">	 *     count = pc-&gt;offset;</span>
<span class="cm">	 *     if (pc-&gt;cap_usr_rdpmc &amp;&amp; idx) {</span>
<span class="cm">	 *       width = pc-&gt;pmc_width;</span>
<span class="cm">	 *       pmc = rdpmc(idx - 1);</span>
<span class="cm">	 *     }</span>
<span class="cm">	 *</span>
<span class="cm">	 *     barrier();</span>
<span class="cm">	 *   } while (pc-&gt;lock != seq);</span>
<span class="cm">	 *</span>
<span class="cm">	 * NOTE: for obvious reason this only works on self-monitoring</span>
<span class="cm">	 *       processes.</span>
<span class="cm">	 */</span>
	<span class="n">__u32</span>	<span class="n">lock</span><span class="p">;</span>			<span class="cm">/* seqlock for synchronization */</span>
	<span class="n">__u32</span>	<span class="n">index</span><span class="p">;</span>			<span class="cm">/* hardware event identifier */</span>
	<span class="n">__s64</span>	<span class="n">offset</span><span class="p">;</span>			<span class="cm">/* add to hardware event value */</span>
	<span class="n">__u64</span>	<span class="n">time_enabled</span><span class="p">;</span>		<span class="cm">/* time event active */</span>
	<span class="n">__u64</span>	<span class="n">time_running</span><span class="p">;</span>		<span class="cm">/* time event on cpu */</span>
	<span class="k">union</span> <span class="p">{</span>
		<span class="n">__u64</span>	<span class="n">capabilities</span><span class="p">;</span>
		<span class="n">__u64</span>	<span class="n">cap_usr_time</span>  <span class="o">:</span> <span class="mi">1</span><span class="p">,</span>
			<span class="n">cap_usr_rdpmc</span> <span class="o">:</span> <span class="mi">1</span><span class="p">,</span>
			<span class="n">cap_____res</span>   <span class="o">:</span> <span class="mi">62</span><span class="p">;</span>
	<span class="p">};</span>

	<span class="cm">/*</span>
<span class="cm">	 * If cap_usr_rdpmc this field provides the bit-width of the value</span>
<span class="cm">	 * read using the rdpmc() or equivalent instruction. This can be used</span>
<span class="cm">	 * to sign extend the result like:</span>
<span class="cm">	 *</span>
<span class="cm">	 *   pmc &lt;&lt;= 64 - width;</span>
<span class="cm">	 *   pmc &gt;&gt;= 64 - width; // signed shift right</span>
<span class="cm">	 *   count += pmc;</span>
<span class="cm">	 */</span>
	<span class="n">__u16</span>	<span class="n">pmc_width</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * If cap_usr_time the below fields can be used to compute the time</span>
<span class="cm">	 * delta since time_enabled (in ns) using rdtsc or similar.</span>
<span class="cm">	 *</span>
<span class="cm">	 *   u64 quot, rem;</span>
<span class="cm">	 *   u64 delta;</span>
<span class="cm">	 *</span>
<span class="cm">	 *   quot = (cyc &gt;&gt; time_shift);</span>
<span class="cm">	 *   rem = cyc &amp; ((1 &lt;&lt; time_shift) - 1);</span>
<span class="cm">	 *   delta = time_offset + quot * time_mult +</span>
<span class="cm">	 *              ((rem * time_mult) &gt;&gt; time_shift);</span>
<span class="cm">	 *</span>
<span class="cm">	 * Where time_offset,time_mult,time_shift and cyc are read in the</span>
<span class="cm">	 * seqcount loop described above. This delta can then be added to</span>
<span class="cm">	 * enabled and possible running (if idx), improving the scaling:</span>
<span class="cm">	 *</span>
<span class="cm">	 *   enabled += delta;</span>
<span class="cm">	 *   if (idx)</span>
<span class="cm">	 *     running += delta;</span>
<span class="cm">	 *</span>
<span class="cm">	 *   quot = count / running;</span>
<span class="cm">	 *   rem  = count % running;</span>
<span class="cm">	 *   count = quot * enabled + (rem * enabled) / running;</span>
<span class="cm">	 */</span>
	<span class="n">__u16</span>	<span class="n">time_shift</span><span class="p">;</span>
	<span class="n">__u32</span>	<span class="n">time_mult</span><span class="p">;</span>
	<span class="n">__u64</span>	<span class="n">time_offset</span><span class="p">;</span>

		<span class="cm">/*</span>
<span class="cm">		 * Hole for extension of the self monitor capabilities</span>
<span class="cm">		 */</span>

	<span class="n">__u64</span>	<span class="n">__reserved</span><span class="p">[</span><span class="mi">120</span><span class="p">];</span>	<span class="cm">/* align to 1k */</span>

	<span class="cm">/*</span>
<span class="cm">	 * Control data for the mmap() data buffer.</span>
<span class="cm">	 *</span>
<span class="cm">	 * User-space reading the @data_head value should issue an rmb(), on</span>
<span class="cm">	 * SMP capable platforms, after reading this value -- see</span>
<span class="cm">	 * perf_event_wakeup().</span>
<span class="cm">	 *</span>
<span class="cm">	 * When the mapping is PROT_WRITE the @data_tail value should be</span>
<span class="cm">	 * written by userspace to reflect the last read data. In this case</span>
<span class="cm">	 * the kernel will not over-write unread data.</span>
<span class="cm">	 */</span>
	<span class="n">__u64</span>   <span class="n">data_head</span><span class="p">;</span>		<span class="cm">/* head in the data section */</span>
	<span class="n">__u64</span>	<span class="n">data_tail</span><span class="p">;</span>		<span class="cm">/* user-space written tail */</span>
<span class="p">};</span>

<span class="cp">#define PERF_RECORD_MISC_CPUMODE_MASK		(7 &lt;&lt; 0)</span>
<span class="cp">#define PERF_RECORD_MISC_CPUMODE_UNKNOWN	(0 &lt;&lt; 0)</span>
<span class="cp">#define PERF_RECORD_MISC_KERNEL			(1 &lt;&lt; 0)</span>
<span class="cp">#define PERF_RECORD_MISC_USER			(2 &lt;&lt; 0)</span>
<span class="cp">#define PERF_RECORD_MISC_HYPERVISOR		(3 &lt;&lt; 0)</span>
<span class="cp">#define PERF_RECORD_MISC_GUEST_KERNEL		(4 &lt;&lt; 0)</span>
<span class="cp">#define PERF_RECORD_MISC_GUEST_USER		(5 &lt;&lt; 0)</span>

<span class="cm">/*</span>
<span class="cm"> * Indicates that the content of PERF_SAMPLE_IP points to</span>
<span class="cm"> * the actual instruction that triggered the event. See also</span>
<span class="cm"> * perf_event_attr::precise_ip.</span>
<span class="cm"> */</span>
<span class="cp">#define PERF_RECORD_MISC_EXACT_IP		(1 &lt;&lt; 14)</span>
<span class="cm">/*</span>
<span class="cm"> * Reserve the last bit to indicate some extended misc field</span>
<span class="cm"> */</span>
<span class="cp">#define PERF_RECORD_MISC_EXT_RESERVED		(1 &lt;&lt; 15)</span>

<span class="k">struct</span> <span class="n">perf_event_header</span> <span class="p">{</span>
	<span class="n">__u32</span>	<span class="n">type</span><span class="p">;</span>
	<span class="n">__u16</span>	<span class="n">misc</span><span class="p">;</span>
	<span class="n">__u16</span>	<span class="n">size</span><span class="p">;</span>
<span class="p">};</span>

<span class="k">enum</span> <span class="n">perf_event_type</span> <span class="p">{</span>

	<span class="cm">/*</span>
<span class="cm">	 * If perf_event_attr.sample_id_all is set then all event types will</span>
<span class="cm">	 * have the sample_type selected fields related to where/when</span>
<span class="cm">	 * (identity) an event took place (TID, TIME, ID, CPU, STREAM_ID)</span>
<span class="cm">	 * described in PERF_RECORD_SAMPLE below, it will be stashed just after</span>
<span class="cm">	 * the perf_event_header and the fields already present for the existing</span>
<span class="cm">	 * fields, i.e. at the end of the payload. That way a newer perf.data</span>
<span class="cm">	 * file will be supported by older perf tools, with these new optional</span>
<span class="cm">	 * fields being ignored.</span>
<span class="cm">	 *</span>
<span class="cm">	 * The MMAP events record the PROT_EXEC mappings so that we can</span>
<span class="cm">	 * correlate userspace IPs to code. They have the following structure:</span>
<span class="cm">	 *</span>
<span class="cm">	 * struct {</span>
<span class="cm">	 *	struct perf_event_header	header;</span>
<span class="cm">	 *</span>
<span class="cm">	 *	u32				pid, tid;</span>
<span class="cm">	 *	u64				addr;</span>
<span class="cm">	 *	u64				len;</span>
<span class="cm">	 *	u64				pgoff;</span>
<span class="cm">	 *	char				filename[];</span>
<span class="cm">	 * };</span>
<span class="cm">	 */</span>
	<span class="n">PERF_RECORD_MMAP</span>			<span class="o">=</span> <span class="mi">1</span><span class="p">,</span>

	<span class="cm">/*</span>
<span class="cm">	 * struct {</span>
<span class="cm">	 *	struct perf_event_header	header;</span>
<span class="cm">	 *	u64				id;</span>
<span class="cm">	 *	u64				lost;</span>
<span class="cm">	 * };</span>
<span class="cm">	 */</span>
	<span class="n">PERF_RECORD_LOST</span>			<span class="o">=</span> <span class="mi">2</span><span class="p">,</span>

	<span class="cm">/*</span>
<span class="cm">	 * struct {</span>
<span class="cm">	 *	struct perf_event_header	header;</span>
<span class="cm">	 *</span>
<span class="cm">	 *	u32				pid, tid;</span>
<span class="cm">	 *	char				comm[];</span>
<span class="cm">	 * };</span>
<span class="cm">	 */</span>
	<span class="n">PERF_RECORD_COMM</span>			<span class="o">=</span> <span class="mi">3</span><span class="p">,</span>

	<span class="cm">/*</span>
<span class="cm">	 * struct {</span>
<span class="cm">	 *	struct perf_event_header	header;</span>
<span class="cm">	 *	u32				pid, ppid;</span>
<span class="cm">	 *	u32				tid, ptid;</span>
<span class="cm">	 *	u64				time;</span>
<span class="cm">	 * };</span>
<span class="cm">	 */</span>
	<span class="n">PERF_RECORD_EXIT</span>			<span class="o">=</span> <span class="mi">4</span><span class="p">,</span>

	<span class="cm">/*</span>
<span class="cm">	 * struct {</span>
<span class="cm">	 *	struct perf_event_header	header;</span>
<span class="cm">	 *	u64				time;</span>
<span class="cm">	 *	u64				id;</span>
<span class="cm">	 *	u64				stream_id;</span>
<span class="cm">	 * };</span>
<span class="cm">	 */</span>
	<span class="n">PERF_RECORD_THROTTLE</span>			<span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
	<span class="n">PERF_RECORD_UNTHROTTLE</span>			<span class="o">=</span> <span class="mi">6</span><span class="p">,</span>

	<span class="cm">/*</span>
<span class="cm">	 * struct {</span>
<span class="cm">	 *	struct perf_event_header	header;</span>
<span class="cm">	 *	u32				pid, ppid;</span>
<span class="cm">	 *	u32				tid, ptid;</span>
<span class="cm">	 *	u64				time;</span>
<span class="cm">	 * };</span>
<span class="cm">	 */</span>
	<span class="n">PERF_RECORD_FORK</span>			<span class="o">=</span> <span class="mi">7</span><span class="p">,</span>

	<span class="cm">/*</span>
<span class="cm">	 * struct {</span>
<span class="cm">	 *	struct perf_event_header	header;</span>
<span class="cm">	 *	u32				pid, tid;</span>
<span class="cm">	 *</span>
<span class="cm">	 *	struct read_format		values;</span>
<span class="cm">	 * };</span>
<span class="cm">	 */</span>
	<span class="n">PERF_RECORD_READ</span>			<span class="o">=</span> <span class="mi">8</span><span class="p">,</span>

	<span class="cm">/*</span>
<span class="cm">	 * struct {</span>
<span class="cm">	 *	struct perf_event_header	header;</span>
<span class="cm">	 *</span>
<span class="cm">	 *	{ u64			ip;	  } &amp;&amp; PERF_SAMPLE_IP</span>
<span class="cm">	 *	{ u32			pid, tid; } &amp;&amp; PERF_SAMPLE_TID</span>
<span class="cm">	 *	{ u64			time;     } &amp;&amp; PERF_SAMPLE_TIME</span>
<span class="cm">	 *	{ u64			addr;     } &amp;&amp; PERF_SAMPLE_ADDR</span>
<span class="cm">	 *	{ u64			id;	  } &amp;&amp; PERF_SAMPLE_ID</span>
<span class="cm">	 *	{ u64			stream_id;} &amp;&amp; PERF_SAMPLE_STREAM_ID</span>
<span class="cm">	 *	{ u32			cpu, res; } &amp;&amp; PERF_SAMPLE_CPU</span>
<span class="cm">	 *	{ u64			period;   } &amp;&amp; PERF_SAMPLE_PERIOD</span>
<span class="cm">	 *</span>
<span class="cm">	 *	{ struct read_format	values;	  } &amp;&amp; PERF_SAMPLE_READ</span>
<span class="cm">	 *</span>
<span class="cm">	 *	{ u64			nr,</span>
<span class="cm">	 *	  u64			ips[nr];  } &amp;&amp; PERF_SAMPLE_CALLCHAIN</span>
<span class="cm">	 *</span>
<span class="cm">	 *	#</span>
<span class="cm">	 *	# The RAW record below is opaque data wrt the ABI</span>
<span class="cm">	 *	#</span>
<span class="cm">	 *	# That is, the ABI doesn&#39;t make any promises wrt to</span>
<span class="cm">	 *	# the stability of its content, it may vary depending</span>
<span class="cm">	 *	# on event, hardware, kernel version and phase of</span>
<span class="cm">	 *	# the moon.</span>
<span class="cm">	 *	#</span>
<span class="cm">	 *	# In other words, PERF_SAMPLE_RAW contents are not an ABI.</span>
<span class="cm">	 *	#</span>
<span class="cm">	 *</span>
<span class="cm">	 *	{ u32			size;</span>
<span class="cm">	 *	  char                  data[size];}&amp;&amp; PERF_SAMPLE_RAW</span>
<span class="cm">	 *</span>
<span class="cm">	 *	{ u64 from, to, flags } lbr[nr];} &amp;&amp; PERF_SAMPLE_BRANCH_STACK</span>
<span class="cm">	 * };</span>
<span class="cm">	 */</span>
	<span class="n">PERF_RECORD_SAMPLE</span>			<span class="o">=</span> <span class="mi">9</span><span class="p">,</span>

	<span class="n">PERF_RECORD_MAX</span><span class="p">,</span>			<span class="cm">/* non-ABI */</span>
<span class="p">};</span>

<span class="cp">#define PERF_MAX_STACK_DEPTH		127</span>

<span class="k">enum</span> <span class="n">perf_callchain_context</span> <span class="p">{</span>
	<span class="n">PERF_CONTEXT_HV</span>			<span class="o">=</span> <span class="p">(</span><span class="n">__u64</span><span class="p">)</span><span class="o">-</span><span class="mi">32</span><span class="p">,</span>
	<span class="n">PERF_CONTEXT_KERNEL</span>		<span class="o">=</span> <span class="p">(</span><span class="n">__u64</span><span class="p">)</span><span class="o">-</span><span class="mi">128</span><span class="p">,</span>
	<span class="n">PERF_CONTEXT_USER</span>		<span class="o">=</span> <span class="p">(</span><span class="n">__u64</span><span class="p">)</span><span class="o">-</span><span class="mi">512</span><span class="p">,</span>

	<span class="n">PERF_CONTEXT_GUEST</span>		<span class="o">=</span> <span class="p">(</span><span class="n">__u64</span><span class="p">)</span><span class="o">-</span><span class="mi">2048</span><span class="p">,</span>
	<span class="n">PERF_CONTEXT_GUEST_KERNEL</span>	<span class="o">=</span> <span class="p">(</span><span class="n">__u64</span><span class="p">)</span><span class="o">-</span><span class="mi">2176</span><span class="p">,</span>
	<span class="n">PERF_CONTEXT_GUEST_USER</span>		<span class="o">=</span> <span class="p">(</span><span class="n">__u64</span><span class="p">)</span><span class="o">-</span><span class="mi">2560</span><span class="p">,</span>

	<span class="n">PERF_CONTEXT_MAX</span>		<span class="o">=</span> <span class="p">(</span><span class="n">__u64</span><span class="p">)</span><span class="o">-</span><span class="mi">4095</span><span class="p">,</span>
<span class="p">};</span>

<span class="cp">#define PERF_FLAG_FD_NO_GROUP		(1U &lt;&lt; 0)</span>
<span class="cp">#define PERF_FLAG_FD_OUTPUT		(1U &lt;&lt; 1)</span>
<span class="cp">#define PERF_FLAG_PID_CGROUP		(1U &lt;&lt; 2) </span><span class="cm">/* pid=cgroup id, per-cpu mode only */</span><span class="cp"></span>

<span class="cp">#ifdef __KERNEL__</span>
<span class="cm">/*</span>
<span class="cm"> * Kernel-internal data types and definitions:</span>
<span class="cm"> */</span>

<span class="cp">#ifdef CONFIG_PERF_EVENTS</span>
<span class="cp"># include &lt;linux/cgroup.h&gt;</span>
<span class="cp"># include &lt;asm/perf_event.h&gt;</span>
<span class="cp"># include &lt;asm/local64.h&gt;</span>
<span class="cp">#endif</span>

<span class="k">struct</span> <span class="n">perf_guest_info_callbacks</span> <span class="p">{</span>
	<span class="kt">int</span>				<span class="p">(</span><span class="o">*</span><span class="n">is_in_guest</span><span class="p">)(</span><span class="kt">void</span><span class="p">);</span>
	<span class="kt">int</span>				<span class="p">(</span><span class="o">*</span><span class="n">is_user_mode</span><span class="p">)(</span><span class="kt">void</span><span class="p">);</span>
	<span class="kt">unsigned</span> <span class="kt">long</span>			<span class="p">(</span><span class="o">*</span><span class="n">get_guest_ip</span><span class="p">)(</span><span class="kt">void</span><span class="p">);</span>
<span class="p">};</span>

<span class="cp">#ifdef CONFIG_HAVE_HW_BREAKPOINT</span>
<span class="cp">#include &lt;asm/hw_breakpoint.h&gt;</span>
<span class="cp">#endif</span>

<span class="cp">#include &lt;linux/list.h&gt;</span>
<span class="cp">#include &lt;linux/mutex.h&gt;</span>
<span class="cp">#include &lt;linux/rculist.h&gt;</span>
<span class="cp">#include &lt;linux/rcupdate.h&gt;</span>
<span class="cp">#include &lt;linux/spinlock.h&gt;</span>
<span class="cp">#include &lt;linux/hrtimer.h&gt;</span>
<span class="cp">#include &lt;linux/fs.h&gt;</span>
<span class="cp">#include &lt;linux/pid_namespace.h&gt;</span>
<span class="cp">#include &lt;linux/workqueue.h&gt;</span>
<span class="cp">#include &lt;linux/ftrace.h&gt;</span>
<span class="cp">#include &lt;linux/cpu.h&gt;</span>
<span class="cp">#include &lt;linux/irq_work.h&gt;</span>
<span class="cp">#include &lt;linux/static_key.h&gt;</span>
<span class="cp">#include &lt;linux/atomic.h&gt;</span>
<span class="cp">#include &lt;linux/sysfs.h&gt;</span>
<span class="cp">#include &lt;asm/local.h&gt;</span>

<span class="k">struct</span> <span class="n">perf_callchain_entry</span> <span class="p">{</span>
	<span class="n">__u64</span>				<span class="n">nr</span><span class="p">;</span>
	<span class="n">__u64</span>				<span class="n">ip</span><span class="p">[</span><span class="n">PERF_MAX_STACK_DEPTH</span><span class="p">];</span>
<span class="p">};</span>

<span class="k">struct</span> <span class="n">perf_raw_record</span> <span class="p">{</span>
	<span class="n">u32</span>				<span class="n">size</span><span class="p">;</span>
	<span class="kt">void</span>				<span class="o">*</span><span class="n">data</span><span class="p">;</span>
<span class="p">};</span>

<span class="cm">/*</span>
<span class="cm"> * single taken branch record layout:</span>
<span class="cm"> *</span>
<span class="cm"> *      from: source instruction (may not always be a branch insn)</span>
<span class="cm"> *        to: branch target</span>
<span class="cm"> *   mispred: branch target was mispredicted</span>
<span class="cm"> * predicted: branch target was predicted</span>
<span class="cm"> *</span>
<span class="cm"> * support for mispred, predicted is optional. In case it</span>
<span class="cm"> * is not supported mispred = predicted = 0.</span>
<span class="cm"> */</span>
<span class="k">struct</span> <span class="n">perf_branch_entry</span> <span class="p">{</span>
	<span class="n">__u64</span>	<span class="n">from</span><span class="p">;</span>
	<span class="n">__u64</span>	<span class="n">to</span><span class="p">;</span>
	<span class="n">__u64</span>	<span class="n">mispred</span><span class="o">:</span><span class="mi">1</span><span class="p">,</span>  <span class="cm">/* target mispredicted */</span>
		<span class="nl">predicted:</span><span class="mi">1</span><span class="p">,</span><span class="cm">/* target predicted */</span>
		<span class="nl">reserved:</span><span class="mi">62</span><span class="p">;</span>
<span class="p">};</span>

<span class="cm">/*</span>
<span class="cm"> * branch stack layout:</span>
<span class="cm"> *  nr: number of taken branches stored in entries[]</span>
<span class="cm"> *</span>
<span class="cm"> * Note that nr can vary from sample to sample</span>
<span class="cm"> * branches (to, from) are stored from most recent</span>
<span class="cm"> * to least recent, i.e., entries[0] contains the most</span>
<span class="cm"> * recent branch.</span>
<span class="cm"> */</span>
<span class="k">struct</span> <span class="n">perf_branch_stack</span> <span class="p">{</span>
	<span class="n">__u64</span>				<span class="n">nr</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">perf_branch_entry</span>	<span class="n">entries</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
<span class="p">};</span>

<span class="k">struct</span> <span class="n">task_struct</span><span class="p">;</span>

<span class="cm">/*</span>
<span class="cm"> * extra PMU register associated with an event</span>
<span class="cm"> */</span>
<span class="k">struct</span> <span class="n">hw_perf_event_extra</span> <span class="p">{</span>
	<span class="n">u64</span>		<span class="n">config</span><span class="p">;</span>	<span class="cm">/* register value */</span>
	<span class="kt">unsigned</span> <span class="kt">int</span>	<span class="n">reg</span><span class="p">;</span>	<span class="cm">/* register address or index */</span>
	<span class="kt">int</span>		<span class="n">alloc</span><span class="p">;</span>	<span class="cm">/* extra register already allocated */</span>
	<span class="kt">int</span>		<span class="n">idx</span><span class="p">;</span>	<span class="cm">/* index in shared_regs-&gt;regs[] */</span>
<span class="p">};</span>

<span class="cm">/**</span>
<span class="cm"> * struct hw_perf_event - performance event hardware details:</span>
<span class="cm"> */</span>
<span class="k">struct</span> <span class="n">hw_perf_event</span> <span class="p">{</span>
<span class="cp">#ifdef CONFIG_PERF_EVENTS</span>
	<span class="k">union</span> <span class="p">{</span>
		<span class="k">struct</span> <span class="p">{</span> <span class="cm">/* hardware */</span>
			<span class="n">u64</span>		<span class="n">config</span><span class="p">;</span>
			<span class="n">u64</span>		<span class="n">last_tag</span><span class="p">;</span>
			<span class="kt">unsigned</span> <span class="kt">long</span>	<span class="n">config_base</span><span class="p">;</span>
			<span class="kt">unsigned</span> <span class="kt">long</span>	<span class="n">event_base</span><span class="p">;</span>
			<span class="kt">int</span>		<span class="n">idx</span><span class="p">;</span>
			<span class="kt">int</span>		<span class="n">last_cpu</span><span class="p">;</span>

			<span class="k">struct</span> <span class="n">hw_perf_event_extra</span> <span class="n">extra_reg</span><span class="p">;</span>
			<span class="k">struct</span> <span class="n">hw_perf_event_extra</span> <span class="n">branch_reg</span><span class="p">;</span>
		<span class="p">};</span>
		<span class="k">struct</span> <span class="p">{</span> <span class="cm">/* software */</span>
			<span class="k">struct</span> <span class="n">hrtimer</span>	<span class="n">hrtimer</span><span class="p">;</span>
		<span class="p">};</span>
<span class="cp">#ifdef CONFIG_HAVE_HW_BREAKPOINT</span>
		<span class="k">struct</span> <span class="p">{</span> <span class="cm">/* breakpoint */</span>
			<span class="k">struct</span> <span class="n">arch_hw_breakpoint</span>	<span class="n">info</span><span class="p">;</span>
			<span class="k">struct</span> <span class="n">list_head</span>		<span class="n">bp_list</span><span class="p">;</span>
			<span class="cm">/*</span>
<span class="cm">			 * Crufty hack to avoid the chicken and egg</span>
<span class="cm">			 * problem hw_breakpoint has with context</span>
<span class="cm">			 * creation and event initalization.</span>
<span class="cm">			 */</span>
			<span class="k">struct</span> <span class="n">task_struct</span>		<span class="o">*</span><span class="n">bp_target</span><span class="p">;</span>
		<span class="p">};</span>
<span class="cp">#endif</span>
	<span class="p">};</span>
	<span class="kt">int</span>				<span class="n">state</span><span class="p">;</span>
	<span class="n">local64_t</span>			<span class="n">prev_count</span><span class="p">;</span>
	<span class="n">u64</span>				<span class="n">sample_period</span><span class="p">;</span>
	<span class="n">u64</span>				<span class="n">last_period</span><span class="p">;</span>
	<span class="n">local64_t</span>			<span class="n">period_left</span><span class="p">;</span>
	<span class="n">u64</span>                             <span class="n">interrupts_seq</span><span class="p">;</span>
	<span class="n">u64</span>				<span class="n">interrupts</span><span class="p">;</span>

	<span class="n">u64</span>				<span class="n">freq_time_stamp</span><span class="p">;</span>
	<span class="n">u64</span>				<span class="n">freq_count_stamp</span><span class="p">;</span>
<span class="cp">#endif</span>
<span class="p">};</span>

<span class="cm">/*</span>
<span class="cm"> * hw_perf_event::state flags</span>
<span class="cm"> */</span>
<span class="cp">#define PERF_HES_STOPPED	0x01 </span><span class="cm">/* the counter is stopped */</span><span class="cp"></span>
<span class="cp">#define PERF_HES_UPTODATE	0x02 </span><span class="cm">/* event-&gt;count up-to-date */</span><span class="cp"></span>
<span class="cp">#define PERF_HES_ARCH		0x04</span>

<span class="k">struct</span> <span class="n">perf_event</span><span class="p">;</span>

<span class="cm">/*</span>
<span class="cm"> * Common implementation detail of pmu::{start,commit,cancel}_txn</span>
<span class="cm"> */</span>
<span class="cp">#define PERF_EVENT_TXN 0x1</span>

<span class="cm">/**</span>
<span class="cm"> * struct pmu - generic performance monitoring unit</span>
<span class="cm"> */</span>
<span class="k">struct</span> <span class="n">pmu</span> <span class="p">{</span>
	<span class="k">struct</span> <span class="n">list_head</span>		<span class="n">entry</span><span class="p">;</span>

	<span class="k">struct</span> <span class="n">device</span>			<span class="o">*</span><span class="n">dev</span><span class="p">;</span>
	<span class="k">const</span> <span class="k">struct</span> <span class="n">attribute_group</span>	<span class="o">**</span><span class="n">attr_groups</span><span class="p">;</span>
	<span class="kt">char</span>				<span class="o">*</span><span class="n">name</span><span class="p">;</span>
	<span class="kt">int</span>				<span class="n">type</span><span class="p">;</span>

	<span class="kt">int</span> <span class="o">*</span> <span class="n">__percpu</span>			<span class="n">pmu_disable_count</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">perf_cpu_context</span> <span class="o">*</span> <span class="n">__percpu</span> <span class="n">pmu_cpu_context</span><span class="p">;</span>
	<span class="kt">int</span>				<span class="n">task_ctx_nr</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * Fully disable/enable this PMU, can be used to protect from the PMI</span>
<span class="cm">	 * as well as for lazy/batch writing of the MSRs.</span>
<span class="cm">	 */</span>
	<span class="kt">void</span> <span class="p">(</span><span class="o">*</span><span class="n">pmu_enable</span><span class="p">)</span>		<span class="p">(</span><span class="k">struct</span> <span class="n">pmu</span> <span class="o">*</span><span class="n">pmu</span><span class="p">);</span> <span class="cm">/* optional */</span>
	<span class="kt">void</span> <span class="p">(</span><span class="o">*</span><span class="n">pmu_disable</span><span class="p">)</span>		<span class="p">(</span><span class="k">struct</span> <span class="n">pmu</span> <span class="o">*</span><span class="n">pmu</span><span class="p">);</span> <span class="cm">/* optional */</span>

	<span class="cm">/*</span>
<span class="cm">	 * Try and initialize the event for this PMU.</span>
<span class="cm">	 * Should return -ENOENT when the @event doesn&#39;t match this PMU.</span>
<span class="cm">	 */</span>
	<span class="kt">int</span> <span class="p">(</span><span class="o">*</span><span class="n">event_init</span><span class="p">)</span>		<span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">);</span>

<span class="cp">#define PERF_EF_START	0x01		</span><span class="cm">/* start the counter when adding    */</span><span class="cp"></span>
<span class="cp">#define PERF_EF_RELOAD	0x02		</span><span class="cm">/* reload the counter when starting */</span><span class="cp"></span>
<span class="cp">#define PERF_EF_UPDATE	0x04		</span><span class="cm">/* update the counter when stopping */</span><span class="cp"></span>

	<span class="cm">/*</span>
<span class="cm">	 * Adds/Removes a counter to/from the PMU, can be done inside</span>
<span class="cm">	 * a transaction, see the -&gt;*_txn() methods.</span>
<span class="cm">	 */</span>
	<span class="kt">int</span>  <span class="p">(</span><span class="o">*</span><span class="n">add</span><span class="p">)</span>			<span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">,</span> <span class="kt">int</span> <span class="n">flags</span><span class="p">);</span>
	<span class="kt">void</span> <span class="p">(</span><span class="o">*</span><span class="n">del</span><span class="p">)</span>			<span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">,</span> <span class="kt">int</span> <span class="n">flags</span><span class="p">);</span>

	<span class="cm">/*</span>
<span class="cm">	 * Starts/Stops a counter present on the PMU. The PMI handler</span>
<span class="cm">	 * should stop the counter when perf_event_overflow() returns</span>
<span class="cm">	 * !0. -&gt;start() will be used to continue.</span>
<span class="cm">	 */</span>
	<span class="kt">void</span> <span class="p">(</span><span class="o">*</span><span class="n">start</span><span class="p">)</span>			<span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">,</span> <span class="kt">int</span> <span class="n">flags</span><span class="p">);</span>
	<span class="kt">void</span> <span class="p">(</span><span class="o">*</span><span class="n">stop</span><span class="p">)</span>			<span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">,</span> <span class="kt">int</span> <span class="n">flags</span><span class="p">);</span>

	<span class="cm">/*</span>
<span class="cm">	 * Updates the counter value of the event.</span>
<span class="cm">	 */</span>
	<span class="kt">void</span> <span class="p">(</span><span class="o">*</span><span class="n">read</span><span class="p">)</span>			<span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">);</span>

	<span class="cm">/*</span>
<span class="cm">	 * Group events scheduling is treated as a transaction, add</span>
<span class="cm">	 * group events as a whole and perform one schedulability test.</span>
<span class="cm">	 * If the test fails, roll back the whole group</span>
<span class="cm">	 *</span>
<span class="cm">	 * Start the transaction, after this -&gt;add() doesn&#39;t need to</span>
<span class="cm">	 * do schedulability tests.</span>
<span class="cm">	 */</span>
	<span class="kt">void</span> <span class="p">(</span><span class="o">*</span><span class="n">start_txn</span><span class="p">)</span>		<span class="p">(</span><span class="k">struct</span> <span class="n">pmu</span> <span class="o">*</span><span class="n">pmu</span><span class="p">);</span> <span class="cm">/* optional */</span>
	<span class="cm">/*</span>
<span class="cm">	 * If -&gt;start_txn() disabled the -&gt;add() schedulability test</span>
<span class="cm">	 * then -&gt;commit_txn() is required to perform one. On success</span>
<span class="cm">	 * the transaction is closed. On error the transaction is kept</span>
<span class="cm">	 * open until -&gt;cancel_txn() is called.</span>
<span class="cm">	 */</span>
	<span class="kt">int</span>  <span class="p">(</span><span class="o">*</span><span class="n">commit_txn</span><span class="p">)</span>		<span class="p">(</span><span class="k">struct</span> <span class="n">pmu</span> <span class="o">*</span><span class="n">pmu</span><span class="p">);</span> <span class="cm">/* optional */</span>
	<span class="cm">/*</span>
<span class="cm">	 * Will cancel the transaction, assumes -&gt;del() is called</span>
<span class="cm">	 * for each successful -&gt;add() during the transaction.</span>
<span class="cm">	 */</span>
	<span class="kt">void</span> <span class="p">(</span><span class="o">*</span><span class="n">cancel_txn</span><span class="p">)</span>		<span class="p">(</span><span class="k">struct</span> <span class="n">pmu</span> <span class="o">*</span><span class="n">pmu</span><span class="p">);</span> <span class="cm">/* optional */</span>

	<span class="cm">/*</span>
<span class="cm">	 * Will return the value for perf_event_mmap_page::index for this event,</span>
<span class="cm">	 * if no implementation is provided it will default to: event-&gt;hw.idx + 1.</span>
<span class="cm">	 */</span>
	<span class="kt">int</span> <span class="p">(</span><span class="o">*</span><span class="n">event_idx</span><span class="p">)</span>		<span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">);</span> <span class="cm">/*optional */</span>

	<span class="cm">/*</span>
<span class="cm">	 * flush branch stack on context-switches (needed in cpu-wide mode)</span>
<span class="cm">	 */</span>
	<span class="kt">void</span> <span class="p">(</span><span class="o">*</span><span class="n">flush_branch_stack</span><span class="p">)</span>	<span class="p">(</span><span class="kt">void</span><span class="p">);</span>
<span class="p">};</span>

<span class="cm">/**</span>
<span class="cm"> * enum perf_event_active_state - the states of a event</span>
<span class="cm"> */</span>
<span class="k">enum</span> <span class="n">perf_event_active_state</span> <span class="p">{</span>
	<span class="n">PERF_EVENT_STATE_ERROR</span>		<span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span>
	<span class="n">PERF_EVENT_STATE_OFF</span>		<span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
	<span class="n">PERF_EVENT_STATE_INACTIVE</span>	<span class="o">=</span>  <span class="mi">0</span><span class="p">,</span>
	<span class="n">PERF_EVENT_STATE_ACTIVE</span>		<span class="o">=</span>  <span class="mi">1</span><span class="p">,</span>
<span class="p">};</span>

<span class="k">struct</span> <span class="n">file</span><span class="p">;</span>
<span class="k">struct</span> <span class="n">perf_sample_data</span><span class="p">;</span>

<span class="k">typedef</span> <span class="kt">void</span> <span class="p">(</span><span class="o">*</span><span class="n">perf_overflow_handler_t</span><span class="p">)(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="p">,</span>
					<span class="k">struct</span> <span class="n">perf_sample_data</span> <span class="o">*</span><span class="p">,</span>
					<span class="k">struct</span> <span class="n">pt_regs</span> <span class="o">*</span><span class="n">regs</span><span class="p">);</span>

<span class="k">enum</span> <span class="n">perf_group_flag</span> <span class="p">{</span>
	<span class="n">PERF_GROUP_SOFTWARE</span>		<span class="o">=</span> <span class="mh">0x1</span><span class="p">,</span>
<span class="p">};</span>

<span class="cp">#define SWEVENT_HLIST_BITS		8</span>
<span class="cp">#define SWEVENT_HLIST_SIZE		(1 &lt;&lt; SWEVENT_HLIST_BITS)</span>

<span class="k">struct</span> <span class="n">swevent_hlist</span> <span class="p">{</span>
	<span class="k">struct</span> <span class="n">hlist_head</span>		<span class="n">heads</span><span class="p">[</span><span class="n">SWEVENT_HLIST_SIZE</span><span class="p">];</span>
	<span class="k">struct</span> <span class="n">rcu_head</span>			<span class="n">rcu_head</span><span class="p">;</span>
<span class="p">};</span>

<span class="cp">#define PERF_ATTACH_CONTEXT	0x01</span>
<span class="cp">#define PERF_ATTACH_GROUP	0x02</span>
<span class="cp">#define PERF_ATTACH_TASK	0x04</span>

<span class="cp">#ifdef CONFIG_CGROUP_PERF</span>
<span class="cm">/*</span>
<span class="cm"> * perf_cgroup_info keeps track of time_enabled for a cgroup.</span>
<span class="cm"> * This is a per-cpu dynamically allocated data structure.</span>
<span class="cm"> */</span>
<span class="k">struct</span> <span class="n">perf_cgroup_info</span> <span class="p">{</span>
	<span class="n">u64</span>				<span class="n">time</span><span class="p">;</span>
	<span class="n">u64</span>				<span class="n">timestamp</span><span class="p">;</span>
<span class="p">};</span>

<span class="k">struct</span> <span class="n">perf_cgroup</span> <span class="p">{</span>
	<span class="k">struct</span>				<span class="n">cgroup_subsys_state</span> <span class="n">css</span><span class="p">;</span>
	<span class="k">struct</span>				<span class="n">perf_cgroup_info</span> <span class="o">*</span><span class="n">info</span><span class="p">;</span>	<span class="cm">/* timing info, one per cpu */</span>
<span class="p">};</span>
<span class="cp">#endif</span>

<span class="k">struct</span> <span class="n">ring_buffer</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * struct perf_event - performance event kernel representation:</span>
<span class="cm"> */</span>
<span class="k">struct</span> <span class="n">perf_event</span> <span class="p">{</span>
<span class="cp">#ifdef CONFIG_PERF_EVENTS</span>
	<span class="k">struct</span> <span class="n">list_head</span>		<span class="n">group_entry</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">list_head</span>		<span class="n">event_entry</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">list_head</span>		<span class="n">sibling_list</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">hlist_node</span>		<span class="n">hlist_entry</span><span class="p">;</span>
	<span class="kt">int</span>				<span class="n">nr_siblings</span><span class="p">;</span>
	<span class="kt">int</span>				<span class="n">group_flags</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">perf_event</span>		<span class="o">*</span><span class="n">group_leader</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">pmu</span>			<span class="o">*</span><span class="n">pmu</span><span class="p">;</span>

	<span class="k">enum</span> <span class="n">perf_event_active_state</span>	<span class="n">state</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">int</span>			<span class="n">attach_state</span><span class="p">;</span>
	<span class="n">local64_t</span>			<span class="n">count</span><span class="p">;</span>
	<span class="n">atomic64_t</span>			<span class="n">child_count</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * These are the total time in nanoseconds that the event</span>
<span class="cm">	 * has been enabled (i.e. eligible to run, and the task has</span>
<span class="cm">	 * been scheduled in, if this is a per-task event)</span>
<span class="cm">	 * and running (scheduled onto the CPU), respectively.</span>
<span class="cm">	 *</span>
<span class="cm">	 * They are computed from tstamp_enabled, tstamp_running and</span>
<span class="cm">	 * tstamp_stopped when the event is in INACTIVE or ACTIVE state.</span>
<span class="cm">	 */</span>
	<span class="n">u64</span>				<span class="n">total_time_enabled</span><span class="p">;</span>
	<span class="n">u64</span>				<span class="n">total_time_running</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * These are timestamps used for computing total_time_enabled</span>
<span class="cm">	 * and total_time_running when the event is in INACTIVE or</span>
<span class="cm">	 * ACTIVE state, measured in nanoseconds from an arbitrary point</span>
<span class="cm">	 * in time.</span>
<span class="cm">	 * tstamp_enabled: the notional time when the event was enabled</span>
<span class="cm">	 * tstamp_running: the notional time when the event was scheduled on</span>
<span class="cm">	 * tstamp_stopped: in INACTIVE state, the notional time when the</span>
<span class="cm">	 *	event was scheduled off.</span>
<span class="cm">	 */</span>
	<span class="n">u64</span>				<span class="n">tstamp_enabled</span><span class="p">;</span>
	<span class="n">u64</span>				<span class="n">tstamp_running</span><span class="p">;</span>
	<span class="n">u64</span>				<span class="n">tstamp_stopped</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * timestamp shadows the actual context timing but it can</span>
<span class="cm">	 * be safely used in NMI interrupt context. It reflects the</span>
<span class="cm">	 * context time as it was when the event was last scheduled in.</span>
<span class="cm">	 *</span>
<span class="cm">	 * ctx_time already accounts for ctx-&gt;timestamp. Therefore to</span>
<span class="cm">	 * compute ctx_time for a sample, simply add perf_clock().</span>
<span class="cm">	 */</span>
	<span class="n">u64</span>				<span class="n">shadow_ctx_time</span><span class="p">;</span>

	<span class="k">struct</span> <span class="n">perf_event_attr</span>		<span class="n">attr</span><span class="p">;</span>
	<span class="n">u16</span>				<span class="n">header_size</span><span class="p">;</span>
	<span class="n">u16</span>				<span class="n">id_header_size</span><span class="p">;</span>
	<span class="n">u16</span>				<span class="n">read_size</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">hw_perf_event</span>		<span class="n">hw</span><span class="p">;</span>

	<span class="k">struct</span> <span class="n">perf_event_context</span>	<span class="o">*</span><span class="n">ctx</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">file</span>			<span class="o">*</span><span class="n">filp</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * These accumulate total time (in nanoseconds) that children</span>
<span class="cm">	 * events have been enabled and running, respectively.</span>
<span class="cm">	 */</span>
	<span class="n">atomic64_t</span>			<span class="n">child_total_time_enabled</span><span class="p">;</span>
	<span class="n">atomic64_t</span>			<span class="n">child_total_time_running</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * Protect attach/detach and child_list:</span>
<span class="cm">	 */</span>
	<span class="k">struct</span> <span class="n">mutex</span>			<span class="n">child_mutex</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">list_head</span>		<span class="n">child_list</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">perf_event</span>		<span class="o">*</span><span class="n">parent</span><span class="p">;</span>

	<span class="kt">int</span>				<span class="n">oncpu</span><span class="p">;</span>
	<span class="kt">int</span>				<span class="n">cpu</span><span class="p">;</span>

	<span class="k">struct</span> <span class="n">list_head</span>		<span class="n">owner_entry</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">task_struct</span>		<span class="o">*</span><span class="n">owner</span><span class="p">;</span>

	<span class="cm">/* mmap bits */</span>
	<span class="k">struct</span> <span class="n">mutex</span>			<span class="n">mmap_mutex</span><span class="p">;</span>
	<span class="n">atomic_t</span>			<span class="n">mmap_count</span><span class="p">;</span>
	<span class="kt">int</span>				<span class="n">mmap_locked</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">user_struct</span>		<span class="o">*</span><span class="n">mmap_user</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">ring_buffer</span>		<span class="o">*</span><span class="n">rb</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">list_head</span>		<span class="n">rb_entry</span><span class="p">;</span>

	<span class="cm">/* poll related */</span>
	<span class="n">wait_queue_head_t</span>		<span class="n">waitq</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">fasync_struct</span>		<span class="o">*</span><span class="n">fasync</span><span class="p">;</span>

	<span class="cm">/* delayed work for NMIs and such */</span>
	<span class="kt">int</span>				<span class="n">pending_wakeup</span><span class="p">;</span>
	<span class="kt">int</span>				<span class="n">pending_kill</span><span class="p">;</span>
	<span class="kt">int</span>				<span class="n">pending_disable</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">irq_work</span>			<span class="n">pending</span><span class="p">;</span>

	<span class="n">atomic_t</span>			<span class="n">event_limit</span><span class="p">;</span>

	<span class="kt">void</span> <span class="p">(</span><span class="o">*</span><span class="n">destroy</span><span class="p">)(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="p">);</span>
	<span class="k">struct</span> <span class="n">rcu_head</span>			<span class="n">rcu_head</span><span class="p">;</span>

	<span class="k">struct</span> <span class="n">pid_namespace</span>		<span class="o">*</span><span class="n">ns</span><span class="p">;</span>
	<span class="n">u64</span>				<span class="n">id</span><span class="p">;</span>

	<span class="n">perf_overflow_handler_t</span>		<span class="n">overflow_handler</span><span class="p">;</span>
	<span class="kt">void</span>				<span class="o">*</span><span class="n">overflow_handler_context</span><span class="p">;</span>

<span class="cp">#ifdef CONFIG_EVENT_TRACING</span>
	<span class="k">struct</span> <span class="n">ftrace_event_call</span>	<span class="o">*</span><span class="n">tp_event</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">event_filter</span>		<span class="o">*</span><span class="n">filter</span><span class="p">;</span>
<span class="cp">#ifdef CONFIG_FUNCTION_TRACER</span>
	<span class="k">struct</span> <span class="n">ftrace_ops</span>               <span class="n">ftrace_ops</span><span class="p">;</span>
<span class="cp">#endif</span>
<span class="cp">#endif</span>

<span class="cp">#ifdef CONFIG_CGROUP_PERF</span>
	<span class="k">struct</span> <span class="n">perf_cgroup</span>		<span class="o">*</span><span class="n">cgrp</span><span class="p">;</span> <span class="cm">/* cgroup event is attach to */</span>
	<span class="kt">int</span>				<span class="n">cgrp_defer_enabled</span><span class="p">;</span>
<span class="cp">#endif</span>

<span class="cp">#endif </span><span class="cm">/* CONFIG_PERF_EVENTS */</span><span class="cp"></span>
<span class="p">};</span>

<span class="k">enum</span> <span class="n">perf_event_context_type</span> <span class="p">{</span>
	<span class="n">task_context</span><span class="p">,</span>
	<span class="n">cpu_context</span><span class="p">,</span>
<span class="p">};</span>

<span class="cm">/**</span>
<span class="cm"> * struct perf_event_context - event context structure</span>
<span class="cm"> *</span>
<span class="cm"> * Used as a container for task events and CPU events as well:</span>
<span class="cm"> */</span>
<span class="k">struct</span> <span class="n">perf_event_context</span> <span class="p">{</span>
	<span class="k">struct</span> <span class="n">pmu</span>			<span class="o">*</span><span class="n">pmu</span><span class="p">;</span>
	<span class="k">enum</span> <span class="n">perf_event_context_type</span>	<span class="n">type</span><span class="p">;</span>
	<span class="cm">/*</span>
<span class="cm">	 * Protect the states of the events in the list,</span>
<span class="cm">	 * nr_active, and the list:</span>
<span class="cm">	 */</span>
	<span class="n">raw_spinlock_t</span>			<span class="n">lock</span><span class="p">;</span>
	<span class="cm">/*</span>
<span class="cm">	 * Protect the list of events.  Locking either mutex or lock</span>
<span class="cm">	 * is sufficient to ensure the list doesn&#39;t change; to change</span>
<span class="cm">	 * the list you need to lock both the mutex and the spinlock.</span>
<span class="cm">	 */</span>
	<span class="k">struct</span> <span class="n">mutex</span>			<span class="n">mutex</span><span class="p">;</span>

	<span class="k">struct</span> <span class="n">list_head</span>		<span class="n">pinned_groups</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">list_head</span>		<span class="n">flexible_groups</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">list_head</span>		<span class="n">event_list</span><span class="p">;</span>
	<span class="kt">int</span>				<span class="n">nr_events</span><span class="p">;</span>
	<span class="kt">int</span>				<span class="n">nr_active</span><span class="p">;</span>
	<span class="kt">int</span>				<span class="n">is_active</span><span class="p">;</span>
	<span class="kt">int</span>				<span class="n">nr_stat</span><span class="p">;</span>
	<span class="kt">int</span>				<span class="n">nr_freq</span><span class="p">;</span>
	<span class="kt">int</span>				<span class="n">rotate_disable</span><span class="p">;</span>
	<span class="n">atomic_t</span>			<span class="n">refcount</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">task_struct</span>		<span class="o">*</span><span class="n">task</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * Context clock, runs when context enabled.</span>
<span class="cm">	 */</span>
	<span class="n">u64</span>				<span class="n">time</span><span class="p">;</span>
	<span class="n">u64</span>				<span class="n">timestamp</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * These fields let us detect when two contexts have both</span>
<span class="cm">	 * been cloned (inherited) from a common ancestor.</span>
<span class="cm">	 */</span>
	<span class="k">struct</span> <span class="n">perf_event_context</span>	<span class="o">*</span><span class="n">parent_ctx</span><span class="p">;</span>
	<span class="n">u64</span>				<span class="n">parent_gen</span><span class="p">;</span>
	<span class="n">u64</span>				<span class="n">generation</span><span class="p">;</span>
	<span class="kt">int</span>				<span class="n">pin_count</span><span class="p">;</span>
	<span class="kt">int</span>				<span class="n">nr_cgroups</span><span class="p">;</span>	 <span class="cm">/* cgroup evts */</span>
	<span class="kt">int</span>				<span class="n">nr_branch_stack</span><span class="p">;</span> <span class="cm">/* branch_stack evt */</span>
	<span class="k">struct</span> <span class="n">rcu_head</span>			<span class="n">rcu_head</span><span class="p">;</span>
<span class="p">};</span>

<span class="cm">/*</span>
<span class="cm"> * Number of contexts where an event can trigger:</span>
<span class="cm"> *	task, softirq, hardirq, nmi.</span>
<span class="cm"> */</span>
<span class="cp">#define PERF_NR_CONTEXTS	4</span>

<span class="cm">/**</span>
<span class="cm"> * struct perf_event_cpu_context - per cpu event context structure</span>
<span class="cm"> */</span>
<span class="k">struct</span> <span class="n">perf_cpu_context</span> <span class="p">{</span>
	<span class="k">struct</span> <span class="n">perf_event_context</span>	<span class="n">ctx</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">perf_event_context</span>	<span class="o">*</span><span class="n">task_ctx</span><span class="p">;</span>
	<span class="kt">int</span>				<span class="n">active_oncpu</span><span class="p">;</span>
	<span class="kt">int</span>				<span class="n">exclusive</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">list_head</span>		<span class="n">rotation_list</span><span class="p">;</span>
	<span class="kt">int</span>				<span class="n">jiffies_interval</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">pmu</span>			<span class="o">*</span><span class="n">active_pmu</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">perf_cgroup</span>		<span class="o">*</span><span class="n">cgrp</span><span class="p">;</span>
<span class="p">};</span>

<span class="k">struct</span> <span class="n">perf_output_handle</span> <span class="p">{</span>
	<span class="k">struct</span> <span class="n">perf_event</span>		<span class="o">*</span><span class="n">event</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">ring_buffer</span>		<span class="o">*</span><span class="n">rb</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span>			<span class="n">wakeup</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span>			<span class="n">size</span><span class="p">;</span>
	<span class="kt">void</span>				<span class="o">*</span><span class="n">addr</span><span class="p">;</span>
	<span class="kt">int</span>				<span class="n">page</span><span class="p">;</span>
<span class="p">};</span>

<span class="cp">#ifdef CONFIG_PERF_EVENTS</span>

<span class="k">extern</span> <span class="kt">int</span> <span class="n">perf_pmu_register</span><span class="p">(</span><span class="k">struct</span> <span class="n">pmu</span> <span class="o">*</span><span class="n">pmu</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">name</span><span class="p">,</span> <span class="kt">int</span> <span class="n">type</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_pmu_unregister</span><span class="p">(</span><span class="k">struct</span> <span class="n">pmu</span> <span class="o">*</span><span class="n">pmu</span><span class="p">);</span>

<span class="k">extern</span> <span class="kt">int</span> <span class="n">perf_num_counters</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span>
<span class="k">extern</span> <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">perf_pmu_name</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">__perf_event_task_sched_in</span><span class="p">(</span><span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">prev</span><span class="p">,</span>
				       <span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">task</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">__perf_event_task_sched_out</span><span class="p">(</span><span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">prev</span><span class="p">,</span>
					<span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">next</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">int</span> <span class="n">perf_event_init_task</span><span class="p">(</span><span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">child</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_event_exit_task</span><span class="p">(</span><span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">child</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_event_free_task</span><span class="p">(</span><span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">task</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_event_delayed_put</span><span class="p">(</span><span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">task</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_event_print_debug</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_pmu_disable</span><span class="p">(</span><span class="k">struct</span> <span class="n">pmu</span> <span class="o">*</span><span class="n">pmu</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_pmu_enable</span><span class="p">(</span><span class="k">struct</span> <span class="n">pmu</span> <span class="o">*</span><span class="n">pmu</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">int</span> <span class="n">perf_event_task_disable</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">int</span> <span class="n">perf_event_task_enable</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">int</span> <span class="n">perf_event_refresh</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">,</span> <span class="kt">int</span> <span class="n">refresh</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_event_update_userpage</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">int</span> <span class="n">perf_event_release_kernel</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">);</span>
<span class="k">extern</span> <span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span>
<span class="n">perf_event_create_kernel_counter</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_event_attr</span> <span class="o">*</span><span class="n">attr</span><span class="p">,</span>
				<span class="kt">int</span> <span class="n">cpu</span><span class="p">,</span>
				<span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">task</span><span class="p">,</span>
				<span class="n">perf_overflow_handler_t</span> <span class="n">callback</span><span class="p">,</span>
				<span class="kt">void</span> <span class="o">*</span><span class="n">context</span><span class="p">);</span>
<span class="k">extern</span> <span class="n">u64</span> <span class="n">perf_event_read_value</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">,</span>
				 <span class="n">u64</span> <span class="o">*</span><span class="n">enabled</span><span class="p">,</span> <span class="n">u64</span> <span class="o">*</span><span class="n">running</span><span class="p">);</span>


<span class="k">struct</span> <span class="n">perf_sample_data</span> <span class="p">{</span>
	<span class="n">u64</span>				<span class="n">type</span><span class="p">;</span>

	<span class="n">u64</span>				<span class="n">ip</span><span class="p">;</span>
	<span class="k">struct</span> <span class="p">{</span>
		<span class="n">u32</span>	<span class="n">pid</span><span class="p">;</span>
		<span class="n">u32</span>	<span class="n">tid</span><span class="p">;</span>
	<span class="p">}</span>				<span class="n">tid_entry</span><span class="p">;</span>
	<span class="n">u64</span>				<span class="n">time</span><span class="p">;</span>
	<span class="n">u64</span>				<span class="n">addr</span><span class="p">;</span>
	<span class="n">u64</span>				<span class="n">id</span><span class="p">;</span>
	<span class="n">u64</span>				<span class="n">stream_id</span><span class="p">;</span>
	<span class="k">struct</span> <span class="p">{</span>
		<span class="n">u32</span>	<span class="n">cpu</span><span class="p">;</span>
		<span class="n">u32</span>	<span class="n">reserved</span><span class="p">;</span>
	<span class="p">}</span>				<span class="n">cpu_entry</span><span class="p">;</span>
	<span class="n">u64</span>				<span class="n">period</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">perf_callchain_entry</span>	<span class="o">*</span><span class="n">callchain</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">perf_raw_record</span>		<span class="o">*</span><span class="n">raw</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">perf_branch_stack</span>	<span class="o">*</span><span class="n">br_stack</span><span class="p">;</span>
<span class="p">};</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">perf_sample_data_init</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_sample_data</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span>
					 <span class="n">u64</span> <span class="n">addr</span><span class="p">,</span> <span class="n">u64</span> <span class="n">period</span><span class="p">)</span>
<span class="p">{</span>
	<span class="cm">/* remaining struct members initialized in perf_prepare_sample() */</span>
	<span class="n">data</span><span class="o">-&gt;</span><span class="n">addr</span> <span class="o">=</span> <span class="n">addr</span><span class="p">;</span>
	<span class="n">data</span><span class="o">-&gt;</span><span class="n">raw</span>  <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
	<span class="n">data</span><span class="o">-&gt;</span><span class="n">br_stack</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
	<span class="n">data</span><span class="o">-&gt;</span><span class="n">period</span>	<span class="o">=</span> <span class="n">period</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_output_sample</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_output_handle</span> <span class="o">*</span><span class="n">handle</span><span class="p">,</span>
			       <span class="k">struct</span> <span class="n">perf_event_header</span> <span class="o">*</span><span class="n">header</span><span class="p">,</span>
			       <span class="k">struct</span> <span class="n">perf_sample_data</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span>
			       <span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_prepare_sample</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_event_header</span> <span class="o">*</span><span class="n">header</span><span class="p">,</span>
				<span class="k">struct</span> <span class="n">perf_sample_data</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span>
				<span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">,</span>
				<span class="k">struct</span> <span class="n">pt_regs</span> <span class="o">*</span><span class="n">regs</span><span class="p">);</span>

<span class="k">extern</span> <span class="kt">int</span> <span class="n">perf_event_overflow</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">,</span>
				 <span class="k">struct</span> <span class="n">perf_sample_data</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span>
				 <span class="k">struct</span> <span class="n">pt_regs</span> <span class="o">*</span><span class="n">regs</span><span class="p">);</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="n">bool</span> <span class="nf">is_sampling_event</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="n">event</span><span class="o">-&gt;</span><span class="n">attr</span><span class="p">.</span><span class="n">sample_period</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

<span class="cm">/*</span>
<span class="cm"> * Return 1 for a software event, 0 for a hardware event</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">int</span> <span class="nf">is_software_event</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="n">event</span><span class="o">-&gt;</span><span class="n">pmu</span><span class="o">-&gt;</span><span class="n">task_ctx_nr</span> <span class="o">==</span> <span class="n">perf_sw_context</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">extern</span> <span class="k">struct</span> <span class="n">static_key</span> <span class="n">perf_swevent_enabled</span><span class="p">[</span><span class="n">PERF_COUNT_SW_MAX</span><span class="p">];</span>

<span class="k">extern</span> <span class="kt">void</span> <span class="n">__perf_sw_event</span><span class="p">(</span><span class="n">u32</span><span class="p">,</span> <span class="n">u64</span><span class="p">,</span> <span class="k">struct</span> <span class="n">pt_regs</span> <span class="o">*</span><span class="p">,</span> <span class="n">u64</span><span class="p">);</span>

<span class="cp">#ifndef perf_arch_fetch_caller_regs</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">perf_arch_fetch_caller_regs</span><span class="p">(</span><span class="k">struct</span> <span class="n">pt_regs</span> <span class="o">*</span><span class="n">regs</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">ip</span><span class="p">)</span> <span class="p">{</span> <span class="p">}</span>
<span class="cp">#endif</span>

<span class="cm">/*</span>
<span class="cm"> * Take a snapshot of the regs. Skip ip and frame pointer to</span>
<span class="cm"> * the nth caller. We only need a few of the regs:</span>
<span class="cm"> * - ip for PERF_SAMPLE_IP</span>
<span class="cm"> * - cs for user_mode() tests</span>
<span class="cm"> * - bp for callchains</span>
<span class="cm"> * - eflags, for future purposes, just in case</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">perf_fetch_caller_regs</span><span class="p">(</span><span class="k">struct</span> <span class="n">pt_regs</span> <span class="o">*</span><span class="n">regs</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">memset</span><span class="p">(</span><span class="n">regs</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="o">*</span><span class="n">regs</span><span class="p">));</span>

	<span class="n">perf_arch_fetch_caller_regs</span><span class="p">(</span><span class="n">regs</span><span class="p">,</span> <span class="n">CALLER_ADDR0</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">static</span> <span class="n">__always_inline</span> <span class="kt">void</span>
<span class="nf">perf_sw_event</span><span class="p">(</span><span class="n">u32</span> <span class="n">event_id</span><span class="p">,</span> <span class="n">u64</span> <span class="n">nr</span><span class="p">,</span> <span class="k">struct</span> <span class="n">pt_regs</span> <span class="o">*</span><span class="n">regs</span><span class="p">,</span> <span class="n">u64</span> <span class="n">addr</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">struct</span> <span class="n">pt_regs</span> <span class="n">hot_regs</span><span class="p">;</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">static_key_false</span><span class="p">(</span><span class="o">&amp;</span><span class="n">perf_swevent_enabled</span><span class="p">[</span><span class="n">event_id</span><span class="p">]))</span> <span class="p">{</span>
		<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">regs</span><span class="p">)</span> <span class="p">{</span>
			<span class="n">perf_fetch_caller_regs</span><span class="p">(</span><span class="o">&amp;</span><span class="n">hot_regs</span><span class="p">);</span>
			<span class="n">regs</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">hot_regs</span><span class="p">;</span>
		<span class="p">}</span>
		<span class="n">__perf_sw_event</span><span class="p">(</span><span class="n">event_id</span><span class="p">,</span> <span class="n">nr</span><span class="p">,</span> <span class="n">regs</span><span class="p">,</span> <span class="n">addr</span><span class="p">);</span>
	<span class="p">}</span>
<span class="p">}</span>

<span class="k">extern</span> <span class="k">struct</span> <span class="n">static_key_deferred</span> <span class="n">perf_sched_events</span><span class="p">;</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">perf_event_task_sched_in</span><span class="p">(</span><span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">prev</span><span class="p">,</span>
					    <span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">task</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">static_key_false</span><span class="p">(</span><span class="o">&amp;</span><span class="n">perf_sched_events</span><span class="p">.</span><span class="n">key</span><span class="p">))</span>
		<span class="n">__perf_event_task_sched_in</span><span class="p">(</span><span class="n">prev</span><span class="p">,</span> <span class="n">task</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">perf_event_task_sched_out</span><span class="p">(</span><span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">prev</span><span class="p">,</span>
					     <span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">next</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">perf_sw_event</span><span class="p">(</span><span class="n">PERF_COUNT_SW_CONTEXT_SWITCHES</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">static_key_false</span><span class="p">(</span><span class="o">&amp;</span><span class="n">perf_sched_events</span><span class="p">.</span><span class="n">key</span><span class="p">))</span>
		<span class="n">__perf_event_task_sched_out</span><span class="p">(</span><span class="n">prev</span><span class="p">,</span> <span class="n">next</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_event_mmap</span><span class="p">(</span><span class="k">struct</span> <span class="n">vm_area_struct</span> <span class="o">*</span><span class="n">vma</span><span class="p">);</span>
<span class="k">extern</span> <span class="k">struct</span> <span class="n">perf_guest_info_callbacks</span> <span class="o">*</span><span class="n">perf_guest_cbs</span><span class="p">;</span>
<span class="k">extern</span> <span class="kt">int</span> <span class="n">perf_register_guest_info_callbacks</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_guest_info_callbacks</span> <span class="o">*</span><span class="n">callbacks</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">int</span> <span class="n">perf_unregister_guest_info_callbacks</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_guest_info_callbacks</span> <span class="o">*</span><span class="n">callbacks</span><span class="p">);</span>

<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_event_comm</span><span class="p">(</span><span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">tsk</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_event_fork</span><span class="p">(</span><span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">tsk</span><span class="p">);</span>

<span class="cm">/* Callchains */</span>
<span class="n">DECLARE_PER_CPU</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_callchain_entry</span><span class="p">,</span> <span class="n">perf_callchain_entry</span><span class="p">);</span>

<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_callchain_user</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_callchain_entry</span> <span class="o">*</span><span class="n">entry</span><span class="p">,</span> <span class="k">struct</span> <span class="n">pt_regs</span> <span class="o">*</span><span class="n">regs</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_callchain_kernel</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_callchain_entry</span> <span class="o">*</span><span class="n">entry</span><span class="p">,</span> <span class="k">struct</span> <span class="n">pt_regs</span> <span class="o">*</span><span class="n">regs</span><span class="p">);</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">perf_callchain_store</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_callchain_entry</span> <span class="o">*</span><span class="n">entry</span><span class="p">,</span> <span class="n">u64</span> <span class="n">ip</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">entry</span><span class="o">-&gt;</span><span class="n">nr</span> <span class="o">&lt;</span> <span class="n">PERF_MAX_STACK_DEPTH</span><span class="p">)</span>
		<span class="n">entry</span><span class="o">-&gt;</span><span class="n">ip</span><span class="p">[</span><span class="n">entry</span><span class="o">-&gt;</span><span class="n">nr</span><span class="o">++</span><span class="p">]</span> <span class="o">=</span> <span class="n">ip</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">extern</span> <span class="kt">int</span> <span class="n">sysctl_perf_event_paranoid</span><span class="p">;</span>
<span class="k">extern</span> <span class="kt">int</span> <span class="n">sysctl_perf_event_mlock</span><span class="p">;</span>
<span class="k">extern</span> <span class="kt">int</span> <span class="n">sysctl_perf_event_sample_rate</span><span class="p">;</span>

<span class="k">extern</span> <span class="kt">int</span> <span class="n">perf_proc_update_handler</span><span class="p">(</span><span class="k">struct</span> <span class="n">ctl_table</span> <span class="o">*</span><span class="n">table</span><span class="p">,</span> <span class="kt">int</span> <span class="n">write</span><span class="p">,</span>
		<span class="kt">void</span> <span class="n">__user</span> <span class="o">*</span><span class="n">buffer</span><span class="p">,</span> <span class="kt">size_t</span> <span class="o">*</span><span class="n">lenp</span><span class="p">,</span>
		<span class="n">loff_t</span> <span class="o">*</span><span class="n">ppos</span><span class="p">);</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="n">bool</span> <span class="nf">perf_paranoid_tracepoint_raw</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="n">sysctl_perf_event_paranoid</span> <span class="o">&gt;</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="n">bool</span> <span class="nf">perf_paranoid_cpu</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="n">sysctl_perf_event_paranoid</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="n">bool</span> <span class="nf">perf_paranoid_kernel</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="n">sysctl_perf_event_paranoid</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_event_init</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_tp_event</span><span class="p">(</span><span class="n">u64</span> <span class="n">addr</span><span class="p">,</span> <span class="n">u64</span> <span class="n">count</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">record</span><span class="p">,</span>
			  <span class="kt">int</span> <span class="n">entry_size</span><span class="p">,</span> <span class="k">struct</span> <span class="n">pt_regs</span> <span class="o">*</span><span class="n">regs</span><span class="p">,</span>
			  <span class="k">struct</span> <span class="n">hlist_head</span> <span class="o">*</span><span class="n">head</span><span class="p">,</span> <span class="kt">int</span> <span class="n">rctx</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_bp_event</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">data</span><span class="p">);</span>

<span class="cp">#ifndef perf_misc_flags</span>
<span class="cp"># define perf_misc_flags(regs) \</span>
<span class="cp">		(user_mode(regs) ? PERF_RECORD_MISC_USER : PERF_RECORD_MISC_KERNEL)</span>
<span class="cp"># define perf_instruction_pointer(regs)	instruction_pointer(regs)</span>
<span class="cp">#endif</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="n">bool</span> <span class="nf">has_branch_stack</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="n">event</span><span class="o">-&gt;</span><span class="n">attr</span><span class="p">.</span><span class="n">sample_type</span> <span class="o">&amp;</span> <span class="n">PERF_SAMPLE_BRANCH_STACK</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">extern</span> <span class="kt">int</span> <span class="n">perf_output_begin</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_output_handle</span> <span class="o">*</span><span class="n">handle</span><span class="p">,</span>
			     <span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">size</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_output_end</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_output_handle</span> <span class="o">*</span><span class="n">handle</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_output_copy</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_output_handle</span> <span class="o">*</span><span class="n">handle</span><span class="p">,</span>
			     <span class="k">const</span> <span class="kt">void</span> <span class="o">*</span><span class="n">buf</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">len</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">int</span> <span class="n">perf_swevent_get_recursion_context</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_swevent_put_recursion_context</span><span class="p">(</span><span class="kt">int</span> <span class="n">rctx</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_event_enable</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_event_disable</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">perf_event_task_tick</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span>
<span class="cp">#else</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span>
<span class="nf">perf_event_task_sched_in</span><span class="p">(</span><span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">prev</span><span class="p">,</span>
			 <span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">task</span><span class="p">)</span>			<span class="p">{</span> <span class="p">}</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span>
<span class="nf">perf_event_task_sched_out</span><span class="p">(</span><span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">prev</span><span class="p">,</span>
			  <span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">next</span><span class="p">)</span>			<span class="p">{</span> <span class="p">}</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">int</span> <span class="nf">perf_event_init_task</span><span class="p">(</span><span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">child</span><span class="p">)</span>	<span class="p">{</span> <span class="k">return</span> <span class="mi">0</span><span class="p">;</span> <span class="p">}</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">perf_event_exit_task</span><span class="p">(</span><span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">child</span><span class="p">)</span>	<span class="p">{</span> <span class="p">}</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">perf_event_free_task</span><span class="p">(</span><span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">task</span><span class="p">)</span>	<span class="p">{</span> <span class="p">}</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">perf_event_delayed_put</span><span class="p">(</span><span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">task</span><span class="p">)</span>	<span class="p">{</span> <span class="p">}</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">perf_event_print_debug</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>				<span class="p">{</span> <span class="p">}</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">int</span> <span class="nf">perf_event_task_disable</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>				<span class="p">{</span> <span class="k">return</span> <span class="o">-</span><span class="n">EINVAL</span><span class="p">;</span> <span class="p">}</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">int</span> <span class="nf">perf_event_task_enable</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>				<span class="p">{</span> <span class="k">return</span> <span class="o">-</span><span class="n">EINVAL</span><span class="p">;</span> <span class="p">}</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">int</span> <span class="nf">perf_event_refresh</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">,</span> <span class="kt">int</span> <span class="n">refresh</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="o">-</span><span class="n">EINVAL</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span>
<span class="nf">perf_sw_event</span><span class="p">(</span><span class="n">u32</span> <span class="n">event_id</span><span class="p">,</span> <span class="n">u64</span> <span class="n">nr</span><span class="p">,</span> <span class="k">struct</span> <span class="n">pt_regs</span> <span class="o">*</span><span class="n">regs</span><span class="p">,</span> <span class="n">u64</span> <span class="n">addr</span><span class="p">)</span>	<span class="p">{</span> <span class="p">}</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span>
<span class="nf">perf_bp_event</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">data</span><span class="p">)</span>			<span class="p">{</span> <span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">int</span> <span class="nf">perf_register_guest_info_callbacks</span>
<span class="p">(</span><span class="k">struct</span> <span class="n">perf_guest_info_callbacks</span> <span class="o">*</span><span class="n">callbacks</span><span class="p">)</span>				<span class="p">{</span> <span class="k">return</span> <span class="mi">0</span><span class="p">;</span> <span class="p">}</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">int</span> <span class="nf">perf_unregister_guest_info_callbacks</span>
<span class="p">(</span><span class="k">struct</span> <span class="n">perf_guest_info_callbacks</span> <span class="o">*</span><span class="n">callbacks</span><span class="p">)</span>				<span class="p">{</span> <span class="k">return</span> <span class="mi">0</span><span class="p">;</span> <span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">perf_event_mmap</span><span class="p">(</span><span class="k">struct</span> <span class="n">vm_area_struct</span> <span class="o">*</span><span class="n">vma</span><span class="p">)</span>		<span class="p">{</span> <span class="p">}</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">perf_event_comm</span><span class="p">(</span><span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">tsk</span><span class="p">)</span>		<span class="p">{</span> <span class="p">}</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">perf_event_fork</span><span class="p">(</span><span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">tsk</span><span class="p">)</span>		<span class="p">{</span> <span class="p">}</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">perf_event_init</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>				<span class="p">{</span> <span class="p">}</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">int</span>  <span class="nf">perf_swevent_get_recursion_context</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>		<span class="p">{</span> <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span> <span class="p">}</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">perf_swevent_put_recursion_context</span><span class="p">(</span><span class="kt">int</span> <span class="n">rctx</span><span class="p">)</span>		<span class="p">{</span> <span class="p">}</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">perf_event_enable</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">)</span>		<span class="p">{</span> <span class="p">}</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">perf_event_disable</span><span class="p">(</span><span class="k">struct</span> <span class="n">perf_event</span> <span class="o">*</span><span class="n">event</span><span class="p">)</span>		<span class="p">{</span> <span class="p">}</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">perf_event_task_tick</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>				<span class="p">{</span> <span class="p">}</span>
<span class="cp">#endif</span>

<span class="cp">#define perf_output_put(handle, x) perf_output_copy((handle), &amp;(x), sizeof(x))</span>

<span class="cm">/*</span>
<span class="cm"> * This has to have a higher priority than migration_notifier in sched.c.</span>
<span class="cm"> */</span>
<span class="cp">#define perf_cpu_notifier(fn)						\</span>
<span class="cp">do {									\</span>
<span class="cp">	static struct notifier_block fn##_nb __cpuinitdata =		\</span>
<span class="cp">		{ .notifier_call = fn, .priority = CPU_PRI_PERF };	\</span>
<span class="cp">	fn(&amp;fn##_nb, (unsigned long)CPU_UP_PREPARE,			\</span>
<span class="cp">		(void *)(unsigned long)smp_processor_id());		\</span>
<span class="cp">	fn(&amp;fn##_nb, (unsigned long)CPU_STARTING,			\</span>
<span class="cp">		(void *)(unsigned long)smp_processor_id());		\</span>
<span class="cp">	fn(&amp;fn##_nb, (unsigned long)CPU_ONLINE,				\</span>
<span class="cp">		(void *)(unsigned long)smp_processor_id());		\</span>
<span class="cp">	register_cpu_notifier(&amp;fn##_nb);				\</span>
<span class="cp">} while (0)</span>


<span class="cp">#define PMU_FORMAT_ATTR(_name, _format)					\</span>
<span class="cp">static ssize_t								\</span>
<span class="cp">_name##_show(struct device *dev,					\</span>
<span class="cp">			       struct device_attribute *attr,		\</span>
<span class="cp">			       char *page)				\</span>
<span class="cp">{									\</span>
<span class="cp">	BUILD_BUG_ON(sizeof(_format) &gt;= PAGE_SIZE);			\</span>
<span class="cp">	return sprintf(page, _format &quot;\n&quot;);				\</span>
<span class="cp">}									\</span>
<span class="cp">									\</span>
<span class="cp">static struct device_attribute format_attr_##_name = __ATTR_RO(_name)</span>

<span class="cp">#endif </span><span class="cm">/* __KERNEL__ */</span><span class="cp"></span>
<span class="cp">#endif </span><span class="cm">/* _LINUX_PERF_EVENT_H */</span><span class="cp"></span>

</pre></div></td></tr>

</tbody>
</table>
</div>

</body>
<script>docas={repo:"joekychen/linux",depth:2}</script>
<script>document.write('<script src=' + ('__proto__' in {} ? 'http://cdnjs.cloudflare.com/ajax/libs/zepto/1.0rc1/zepto.min.js' : 'https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js')+'><\\/script>')</script>
<script src="http://baoshan.github.com/moment/min/moment.min.js"></script>
<script src="../../javascript/docco.min.js"></script>
</html>
