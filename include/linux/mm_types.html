<!DOCTYPE html>
<html><head><title>joekychen/linux » include › linux › mm_types.h

</title>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta name="generator" content="Docco">
<link rel="stylesheet" media="all" href="../../stylesheets/docco.min.css" />


</head>
<body>
<div id="container">
<div id="background"></div>
<table cellpadding="0" cellspacing="0">
<thead><tr><th class="docs"><a id="home" href="../../index.html"></a><h1>mm_types.h</h1></th><th class="code"></th></tr></thead>
<tbody>


<tr id="section-1"><td class="docs"><div class="pilwrap"><a class="pilcrow" href="#section-1">&#182;</a></div></td><td class="code"><div class="highlight"><pre><span class="cp">#ifndef _LINUX_MM_TYPES_H</span>
<span class="cp">#define _LINUX_MM_TYPES_H</span>

<span class="cp">#include &lt;linux/auxvec.h&gt;</span>
<span class="cp">#include &lt;linux/types.h&gt;</span>
<span class="cp">#include &lt;linux/threads.h&gt;</span>
<span class="cp">#include &lt;linux/list.h&gt;</span>
<span class="cp">#include &lt;linux/spinlock.h&gt;</span>
<span class="cp">#include &lt;linux/prio_tree.h&gt;</span>
<span class="cp">#include &lt;linux/rbtree.h&gt;</span>
<span class="cp">#include &lt;linux/rwsem.h&gt;</span>
<span class="cp">#include &lt;linux/completion.h&gt;</span>
<span class="cp">#include &lt;linux/cpumask.h&gt;</span>
<span class="cp">#include &lt;linux/page-debug-flags.h&gt;</span>
<span class="cp">#include &lt;linux/uprobes.h&gt;</span>
<span class="cp">#include &lt;asm/page.h&gt;</span>
<span class="cp">#include &lt;asm/mmu.h&gt;</span>

<span class="cp">#ifndef AT_VECTOR_SIZE_ARCH</span>
<span class="cp">#define AT_VECTOR_SIZE_ARCH 0</span>
<span class="cp">#endif</span>
<span class="cp">#define AT_VECTOR_SIZE (2*(AT_VECTOR_SIZE_ARCH + AT_VECTOR_SIZE_BASE + 1))</span>

<span class="k">struct</span> <span class="n">address_space</span><span class="p">;</span>

<span class="cp">#define USE_SPLIT_PTLOCKS	(NR_CPUS &gt;= CONFIG_SPLIT_PTLOCK_CPUS)</span>

<span class="cm">/*</span>
<span class="cm"> * Each physical page in the system has a struct page associated with</span>
<span class="cm"> * it to keep track of whatever it is we are using the page for at the</span>
<span class="cm"> * moment. Note that we have no way to track which tasks are using</span>
<span class="cm"> * a page, though if it is a pagecache page, rmap structures can tell us</span>
<span class="cm"> * who is mapping it.</span>
<span class="cm"> *</span>
<span class="cm"> * The objects in struct page are organized in double word blocks in</span>
<span class="cm"> * order to allows us to use atomic double word operations on portions</span>
<span class="cm"> * of struct page. That is currently only used by slub but the arrangement</span>
<span class="cm"> * allows the use of atomic double word operations on the flags/mapping</span>
<span class="cm"> * and lru list pointers also.</span>
<span class="cm"> */</span>
<span class="k">struct</span> <span class="n">page</span> <span class="p">{</span>
	<span class="cm">/* First double word block */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">;</span>		<span class="cm">/* Atomic flags, some possibly</span>
<span class="cm">					 * updated asynchronously */</span>
	<span class="k">struct</span> <span class="n">address_space</span> <span class="o">*</span><span class="n">mapping</span><span class="p">;</span>	<span class="cm">/* If low bit clear, points to</span>
<span class="cm">					 * inode address_space, or NULL.</span>
<span class="cm">					 * If page mapped as anonymous</span>
<span class="cm">					 * memory, low bit is set, and</span>
<span class="cm">					 * it points to anon_vma object:</span>
<span class="cm">					 * see PAGE_MAPPING_ANON below.</span>
<span class="cm">					 */</span>
	<span class="cm">/* Second double word */</span>
	<span class="k">struct</span> <span class="p">{</span>
		<span class="k">union</span> <span class="p">{</span>
			<span class="n">pgoff_t</span> <span class="n">index</span><span class="p">;</span>		<span class="cm">/* Our offset within mapping. */</span>
			<span class="kt">void</span> <span class="o">*</span><span class="n">freelist</span><span class="p">;</span>		<span class="cm">/* slub first free object */</span>
		<span class="p">};</span>

		<span class="k">union</span> <span class="p">{</span>
<span class="cp">#if defined(CONFIG_HAVE_CMPXCHG_DOUBLE) &amp;&amp; \</span>
<span class="cp">	defined(CONFIG_HAVE_ALIGNED_STRUCT_PAGE)</span>
			<span class="cm">/* Used for cmpxchg_double in slub */</span>
			<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">counters</span><span class="p">;</span>
<span class="cp">#else</span>
			<span class="cm">/*</span>
<span class="cm">			 * Keep _count separate from slub cmpxchg_double data.</span>
<span class="cm">			 * As the rest of the double word is protected by</span>
<span class="cm">			 * slab_lock but _count is not.</span>
<span class="cm">			 */</span>
			<span class="kt">unsigned</span> <span class="n">counters</span><span class="p">;</span>
<span class="cp">#endif</span>

			<span class="k">struct</span> <span class="p">{</span>

				<span class="k">union</span> <span class="p">{</span>
					<span class="cm">/*</span>
<span class="cm">					 * Count of ptes mapped in</span>
<span class="cm">					 * mms, to show when page is</span>
<span class="cm">					 * mapped &amp; limit reverse map</span>
<span class="cm">					 * searches.</span>
<span class="cm">					 *</span>
<span class="cm">					 * Used also for tail pages</span>
<span class="cm">					 * refcounting instead of</span>
<span class="cm">					 * _count. Tail pages cannot</span>
<span class="cm">					 * be mapped and keeping the</span>
<span class="cm">					 * tail page _count zero at</span>
<span class="cm">					 * all times guarantees</span>
<span class="cm">					 * get_page_unless_zero() will</span>
<span class="cm">					 * never succeed on tail</span>
<span class="cm">					 * pages.</span>
<span class="cm">					 */</span>
					<span class="n">atomic_t</span> <span class="n">_mapcount</span><span class="p">;</span>

					<span class="k">struct</span> <span class="p">{</span>
						<span class="kt">unsigned</span> <span class="n">inuse</span><span class="o">:</span><span class="mi">16</span><span class="p">;</span>
						<span class="kt">unsigned</span> <span class="n">objects</span><span class="o">:</span><span class="mi">15</span><span class="p">;</span>
						<span class="kt">unsigned</span> <span class="n">frozen</span><span class="o">:</span><span class="mi">1</span><span class="p">;</span>
					<span class="p">};</span>
				<span class="p">};</span>
				<span class="n">atomic_t</span> <span class="n">_count</span><span class="p">;</span>		<span class="cm">/* Usage count, see below. */</span>
			<span class="p">};</span>
		<span class="p">};</span>
	<span class="p">};</span>

	<span class="cm">/* Third double word block */</span>
	<span class="k">union</span> <span class="p">{</span>
		<span class="k">struct</span> <span class="n">list_head</span> <span class="n">lru</span><span class="p">;</span>	<span class="cm">/* Pageout list, eg. active_list</span>
<span class="cm">					 * protected by zone-&gt;lru_lock !</span>
<span class="cm">					 */</span>
		<span class="k">struct</span> <span class="p">{</span>		<span class="cm">/* slub per cpu partial pages */</span>
			<span class="k">struct</span> <span class="n">page</span> <span class="o">*</span><span class="n">next</span><span class="p">;</span>	<span class="cm">/* Next partial slab */</span>
<span class="cp">#ifdef CONFIG_64BIT</span>
			<span class="kt">int</span> <span class="n">pages</span><span class="p">;</span>	<span class="cm">/* Nr of partial slabs left */</span>
			<span class="kt">int</span> <span class="n">pobjects</span><span class="p">;</span>	<span class="cm">/* Approximate # of objects */</span>
<span class="cp">#else</span>
			<span class="kt">short</span> <span class="kt">int</span> <span class="n">pages</span><span class="p">;</span>
			<span class="kt">short</span> <span class="kt">int</span> <span class="n">pobjects</span><span class="p">;</span>
<span class="cp">#endif</span>
		<span class="p">};</span>
	<span class="p">};</span>

	<span class="cm">/* Remainder is not double word aligned */</span>
	<span class="k">union</span> <span class="p">{</span>
		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">private</span><span class="p">;</span>		<span class="cm">/* Mapping-private opaque data:</span>
<span class="cm">					 	 * usually used for buffer_heads</span>
<span class="cm">						 * if PagePrivate set; used for</span>
<span class="cm">						 * swp_entry_t if PageSwapCache;</span>
<span class="cm">						 * indicates order in the buddy</span>
<span class="cm">						 * system if PG_buddy is set.</span>
<span class="cm">						 */</span>
<span class="cp">#if USE_SPLIT_PTLOCKS</span>
		<span class="n">spinlock_t</span> <span class="n">ptl</span><span class="p">;</span>
<span class="cp">#endif</span>
		<span class="k">struct</span> <span class="n">kmem_cache</span> <span class="o">*</span><span class="n">slab</span><span class="p">;</span>	<span class="cm">/* SLUB: Pointer to slab */</span>
		<span class="k">struct</span> <span class="n">page</span> <span class="o">*</span><span class="n">first_page</span><span class="p">;</span>	<span class="cm">/* Compound tail pages */</span>
	<span class="p">};</span>

	<span class="cm">/*</span>
<span class="cm">	 * On machines where all RAM is mapped into kernel address space,</span>
<span class="cm">	 * we can simply calculate the virtual address. On machines with</span>
<span class="cm">	 * highmem some memory is mapped into kernel virtual memory</span>
<span class="cm">	 * dynamically, so we need a place to store that address.</span>
<span class="cm">	 * Note that this field could be 16 bits on x86 ... ;)</span>
<span class="cm">	 *</span>
<span class="cm">	 * Architectures with slow multiplication can define</span>
<span class="cm">	 * WANT_PAGE_VIRTUAL in asm/page.h</span>
<span class="cm">	 */</span>
<span class="cp">#if defined(WANT_PAGE_VIRTUAL)</span>
	<span class="kt">void</span> <span class="o">*</span><span class="k">virtual</span><span class="p">;</span>			<span class="cm">/* Kernel virtual address (NULL if</span>
<span class="cm">					   not kmapped, ie. highmem) */</span>
<span class="cp">#endif </span><span class="cm">/* WANT_PAGE_VIRTUAL */</span><span class="cp"></span>
<span class="cp">#ifdef CONFIG_WANT_PAGE_DEBUG_FLAGS</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">debug_flags</span><span class="p">;</span>	<span class="cm">/* Use atomic bitops on this */</span>
<span class="cp">#endif</span>

<span class="cp">#ifdef CONFIG_KMEMCHECK</span>
	<span class="cm">/*</span>
<span class="cm">	 * kmemcheck wants to track the status of each byte in a page; this</span>
<span class="cm">	 * is a pointer to such a status block. NULL if not tracked.</span>
<span class="cm">	 */</span>
	<span class="kt">void</span> <span class="o">*</span><span class="n">shadow</span><span class="p">;</span>
<span class="cp">#endif</span>
<span class="p">}</span>
<span class="cm">/*</span>
<span class="cm"> * The struct page can be forced to be double word aligned so that atomic ops</span>
<span class="cm"> * on double words work. The SLUB allocator can make use of such a feature.</span>
<span class="cm"> */</span>
<span class="cp">#ifdef CONFIG_HAVE_ALIGNED_STRUCT_PAGE</span>
	<span class="n">__aligned</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span><span class="p">))</span>
<span class="cp">#endif</span>
<span class="p">;</span>

<span class="k">struct</span> <span class="n">page_frag</span> <span class="p">{</span>
	<span class="k">struct</span> <span class="n">page</span> <span class="o">*</span><span class="n">page</span><span class="p">;</span>
<span class="cp">#if (BITS_PER_LONG &gt; 32) || (PAGE_SIZE &gt;= 65536)</span>
	<span class="n">__u32</span> <span class="n">offset</span><span class="p">;</span>
	<span class="n">__u32</span> <span class="n">size</span><span class="p">;</span>
<span class="cp">#else</span>
	<span class="n">__u16</span> <span class="n">offset</span><span class="p">;</span>
	<span class="n">__u16</span> <span class="n">size</span><span class="p">;</span>
<span class="cp">#endif</span>
<span class="p">};</span>

<span class="k">typedef</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">__nocast</span> <span class="n">vm_flags_t</span><span class="p">;</span>

<span class="cm">/*</span>
<span class="cm"> * A region containing a mapping of a non-memory backed file under NOMMU</span>
<span class="cm"> * conditions.  These are held in a global tree and are pinned by the VMAs that</span>
<span class="cm"> * map parts of them.</span>
<span class="cm"> */</span>
<span class="k">struct</span> <span class="n">vm_region</span> <span class="p">{</span>
	<span class="k">struct</span> <span class="n">rb_node</span>	<span class="n">vm_rb</span><span class="p">;</span>		<span class="cm">/* link in global region tree */</span>
	<span class="n">vm_flags_t</span>	<span class="n">vm_flags</span><span class="p">;</span>	<span class="cm">/* VMA vm_flags */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span>	<span class="n">vm_start</span><span class="p">;</span>	<span class="cm">/* start address of region */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span>	<span class="n">vm_end</span><span class="p">;</span>		<span class="cm">/* region initialised to here */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span>	<span class="n">vm_top</span><span class="p">;</span>		<span class="cm">/* region allocated to here */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span>	<span class="n">vm_pgoff</span><span class="p">;</span>	<span class="cm">/* the offset in vm_file corresponding to vm_start */</span>
	<span class="k">struct</span> <span class="n">file</span>	<span class="o">*</span><span class="n">vm_file</span><span class="p">;</span>	<span class="cm">/* the backing file or NULL */</span>

	<span class="kt">int</span>		<span class="n">vm_usage</span><span class="p">;</span>	<span class="cm">/* region usage count (access under nommu_region_sem) */</span>
	<span class="n">bool</span>		<span class="n">vm_icache_flushed</span> <span class="o">:</span> <span class="mi">1</span><span class="p">;</span> <span class="cm">/* true if the icache has been flushed for</span>
<span class="cm">						* this region */</span>
<span class="p">};</span>

<span class="cm">/*</span>
<span class="cm"> * This struct defines a memory VMM memory area. There is one of these</span>
<span class="cm"> * per VM-area/task.  A VM area is any part of the process virtual memory</span>
<span class="cm"> * space that has a special rule for the page-fault handlers (ie a shared</span>
<span class="cm"> * library, the executable area etc).</span>
<span class="cm"> */</span>
<span class="k">struct</span> <span class="n">vm_area_struct</span> <span class="p">{</span>
	<span class="k">struct</span> <span class="n">mm_struct</span> <span class="o">*</span> <span class="n">vm_mm</span><span class="p">;</span>	<span class="cm">/* The address space we belong to. */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">vm_start</span><span class="p">;</span>		<span class="cm">/* Our start address within vm_mm. */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">vm_end</span><span class="p">;</span>		<span class="cm">/* The first byte after our end address</span>
<span class="cm">					   within vm_mm. */</span>

	<span class="cm">/* linked list of VM areas per task, sorted by address */</span>
	<span class="k">struct</span> <span class="n">vm_area_struct</span> <span class="o">*</span><span class="n">vm_next</span><span class="p">,</span> <span class="o">*</span><span class="n">vm_prev</span><span class="p">;</span>

	<span class="n">pgprot_t</span> <span class="n">vm_page_prot</span><span class="p">;</span>		<span class="cm">/* Access permissions of this VMA. */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">vm_flags</span><span class="p">;</span>		<span class="cm">/* Flags, see mm.h. */</span>

	<span class="k">struct</span> <span class="n">rb_node</span> <span class="n">vm_rb</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * For areas with an address space and backing store,</span>
<span class="cm">	 * linkage into the address_space-&gt;i_mmap prio tree, or</span>
<span class="cm">	 * linkage to the list of like vmas hanging off its node, or</span>
<span class="cm">	 * linkage of vma in the address_space-&gt;i_mmap_nonlinear list.</span>
<span class="cm">	 */</span>
	<span class="k">union</span> <span class="p">{</span>
		<span class="k">struct</span> <span class="p">{</span>
			<span class="k">struct</span> <span class="n">list_head</span> <span class="n">list</span><span class="p">;</span>
			<span class="kt">void</span> <span class="o">*</span><span class="n">parent</span><span class="p">;</span>	<span class="cm">/* aligns with prio_tree_node parent */</span>
			<span class="k">struct</span> <span class="n">vm_area_struct</span> <span class="o">*</span><span class="n">head</span><span class="p">;</span>
		<span class="p">}</span> <span class="n">vm_set</span><span class="p">;</span>

		<span class="k">struct</span> <span class="n">raw_prio_tree_node</span> <span class="n">prio_tree_node</span><span class="p">;</span>
	<span class="p">}</span> <span class="n">shared</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * A file&#39;s MAP_PRIVATE vma can be in both i_mmap tree and anon_vma</span>
<span class="cm">	 * list, after a COW of one of the file pages.	A MAP_SHARED vma</span>
<span class="cm">	 * can only be in the i_mmap tree.  An anonymous MAP_PRIVATE, stack</span>
<span class="cm">	 * or brk vma (with NULL file) can only be in an anon_vma list.</span>
<span class="cm">	 */</span>
	<span class="k">struct</span> <span class="n">list_head</span> <span class="n">anon_vma_chain</span><span class="p">;</span> <span class="cm">/* Serialized by mmap_sem &amp;</span>
<span class="cm">					  * page_table_lock */</span>
	<span class="k">struct</span> <span class="n">anon_vma</span> <span class="o">*</span><span class="n">anon_vma</span><span class="p">;</span>	<span class="cm">/* Serialized by page_table_lock */</span>

	<span class="cm">/* Function pointers to deal with this struct. */</span>
	<span class="k">const</span> <span class="k">struct</span> <span class="n">vm_operations_struct</span> <span class="o">*</span><span class="n">vm_ops</span><span class="p">;</span>

	<span class="cm">/* Information about our backing store: */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">vm_pgoff</span><span class="p">;</span>		<span class="cm">/* Offset (within vm_file) in PAGE_SIZE</span>
<span class="cm">					   units, *not* PAGE_CACHE_SIZE */</span>
	<span class="k">struct</span> <span class="n">file</span> <span class="o">*</span> <span class="n">vm_file</span><span class="p">;</span>		<span class="cm">/* File we map to (can be NULL). */</span>
	<span class="kt">void</span> <span class="o">*</span> <span class="n">vm_private_data</span><span class="p">;</span>		<span class="cm">/* was vm_pte (shared mem) */</span>

<span class="cp">#ifndef CONFIG_MMU</span>
	<span class="k">struct</span> <span class="n">vm_region</span> <span class="o">*</span><span class="n">vm_region</span><span class="p">;</span>	<span class="cm">/* NOMMU mapping region */</span>
<span class="cp">#endif</span>
<span class="cp">#ifdef CONFIG_NUMA</span>
	<span class="k">struct</span> <span class="n">mempolicy</span> <span class="o">*</span><span class="n">vm_policy</span><span class="p">;</span>	<span class="cm">/* NUMA policy for the VMA */</span>
<span class="cp">#endif</span>
<span class="p">};</span>

<span class="k">struct</span> <span class="n">core_thread</span> <span class="p">{</span>
	<span class="k">struct</span> <span class="n">task_struct</span> <span class="o">*</span><span class="n">task</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">core_thread</span> <span class="o">*</span><span class="n">next</span><span class="p">;</span>
<span class="p">};</span>

<span class="k">struct</span> <span class="n">core_state</span> <span class="p">{</span>
	<span class="n">atomic_t</span> <span class="n">nr_threads</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">core_thread</span> <span class="n">dumper</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">completion</span> <span class="n">startup</span><span class="p">;</span>
<span class="p">};</span>

<span class="k">enum</span> <span class="p">{</span>
	<span class="n">MM_FILEPAGES</span><span class="p">,</span>
	<span class="n">MM_ANONPAGES</span><span class="p">,</span>
	<span class="n">MM_SWAPENTS</span><span class="p">,</span>
	<span class="n">NR_MM_COUNTERS</span>
<span class="p">};</span>

<span class="cp">#if USE_SPLIT_PTLOCKS &amp;&amp; defined(CONFIG_MMU)</span>
<span class="cp">#define SPLIT_RSS_COUNTING</span>
<span class="cm">/* per-thread cached information, */</span>
<span class="k">struct</span> <span class="n">task_rss_stat</span> <span class="p">{</span>
	<span class="kt">int</span> <span class="n">events</span><span class="p">;</span>	<span class="cm">/* for synchronization threshold */</span>
	<span class="kt">int</span> <span class="n">count</span><span class="p">[</span><span class="n">NR_MM_COUNTERS</span><span class="p">];</span>
<span class="p">};</span>
<span class="cp">#endif </span><span class="cm">/* USE_SPLIT_PTLOCKS */</span><span class="cp"></span>

<span class="k">struct</span> <span class="n">mm_rss_stat</span> <span class="p">{</span>
	<span class="n">atomic_long_t</span> <span class="n">count</span><span class="p">[</span><span class="n">NR_MM_COUNTERS</span><span class="p">];</span>
<span class="p">};</span>

<span class="k">struct</span> <span class="n">mm_struct</span> <span class="p">{</span>
	<span class="k">struct</span> <span class="n">vm_area_struct</span> <span class="o">*</span> <span class="n">mmap</span><span class="p">;</span>		<span class="cm">/* list of VMAs */</span>
	<span class="k">struct</span> <span class="n">rb_root</span> <span class="n">mm_rb</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">vm_area_struct</span> <span class="o">*</span> <span class="n">mmap_cache</span><span class="p">;</span>	<span class="cm">/* last find_vma result */</span>
<span class="cp">#ifdef CONFIG_MMU</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="p">(</span><span class="o">*</span><span class="n">get_unmapped_area</span><span class="p">)</span> <span class="p">(</span><span class="k">struct</span> <span class="n">file</span> <span class="o">*</span><span class="n">filp</span><span class="p">,</span>
				<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">addr</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">len</span><span class="p">,</span>
				<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">pgoff</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">);</span>
	<span class="kt">void</span> <span class="p">(</span><span class="o">*</span><span class="n">unmap_area</span><span class="p">)</span> <span class="p">(</span><span class="k">struct</span> <span class="n">mm_struct</span> <span class="o">*</span><span class="n">mm</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">addr</span><span class="p">);</span>
<span class="cp">#endif</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">mmap_base</span><span class="p">;</span>		<span class="cm">/* base of mmap area */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">task_size</span><span class="p">;</span>		<span class="cm">/* size of task vm space */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">cached_hole_size</span><span class="p">;</span> 	<span class="cm">/* if non-zero, the largest hole below free_area_cache */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">free_area_cache</span><span class="p">;</span>		<span class="cm">/* first hole of size cached_hole_size or larger */</span>
	<span class="n">pgd_t</span> <span class="o">*</span> <span class="n">pgd</span><span class="p">;</span>
	<span class="n">atomic_t</span> <span class="n">mm_users</span><span class="p">;</span>			<span class="cm">/* How many users with user space? */</span>
	<span class="n">atomic_t</span> <span class="n">mm_count</span><span class="p">;</span>			<span class="cm">/* How many references to &quot;struct mm_struct&quot; (users count as 1) */</span>
	<span class="kt">int</span> <span class="n">map_count</span><span class="p">;</span>				<span class="cm">/* number of VMAs */</span>

	<span class="n">spinlock_t</span> <span class="n">page_table_lock</span><span class="p">;</span>		<span class="cm">/* Protects page tables and some counters */</span>
	<span class="k">struct</span> <span class="n">rw_semaphore</span> <span class="n">mmap_sem</span><span class="p">;</span>

	<span class="k">struct</span> <span class="n">list_head</span> <span class="n">mmlist</span><span class="p">;</span>		<span class="cm">/* List of maybe swapped mm&#39;s.	These are globally strung</span>
<span class="cm">						 * together off init_mm.mmlist, and are protected</span>
<span class="cm">						 * by mmlist_lock</span>
<span class="cm">						 */</span>


	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">hiwater_rss</span><span class="p">;</span>	<span class="cm">/* High-watermark of RSS usage */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">hiwater_vm</span><span class="p">;</span>	<span class="cm">/* High-water virtual memory usage */</span>

	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">total_vm</span><span class="p">;</span>		<span class="cm">/* Total pages mapped */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">locked_vm</span><span class="p">;</span>	<span class="cm">/* Pages that have PG_mlocked set */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">pinned_vm</span><span class="p">;</span>	<span class="cm">/* Refcount permanently increased */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">shared_vm</span><span class="p">;</span>	<span class="cm">/* Shared pages (files) */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">exec_vm</span><span class="p">;</span>		<span class="cm">/* VM_EXEC &amp; ~VM_WRITE */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">stack_vm</span><span class="p">;</span>		<span class="cm">/* VM_GROWSUP/DOWN */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">reserved_vm</span><span class="p">;</span>	<span class="cm">/* VM_RESERVED|VM_IO pages */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">def_flags</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">nr_ptes</span><span class="p">;</span>		<span class="cm">/* Page table pages */</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">start_code</span><span class="p">,</span> <span class="n">end_code</span><span class="p">,</span> <span class="n">start_data</span><span class="p">,</span> <span class="n">end_data</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">start_brk</span><span class="p">,</span> <span class="n">brk</span><span class="p">,</span> <span class="n">start_stack</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">arg_start</span><span class="p">,</span> <span class="n">arg_end</span><span class="p">,</span> <span class="n">env_start</span><span class="p">,</span> <span class="n">env_end</span><span class="p">;</span>

	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">saved_auxv</span><span class="p">[</span><span class="n">AT_VECTOR_SIZE</span><span class="p">];</span> <span class="cm">/* for /proc/PID/auxv */</span>

	<span class="cm">/*</span>
<span class="cm">	 * Special counters, in some configurations protected by the</span>
<span class="cm">	 * page_table_lock, in other configurations by being atomic.</span>
<span class="cm">	 */</span>
	<span class="k">struct</span> <span class="n">mm_rss_stat</span> <span class="n">rss_stat</span><span class="p">;</span>

	<span class="k">struct</span> <span class="n">linux_binfmt</span> <span class="o">*</span><span class="n">binfmt</span><span class="p">;</span>

	<span class="n">cpumask_var_t</span> <span class="n">cpu_vm_mask_var</span><span class="p">;</span>

	<span class="cm">/* Architecture-specific MM context */</span>
	<span class="n">mm_context_t</span> <span class="n">context</span><span class="p">;</span>

	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">;</span> <span class="cm">/* Must use atomic bitops to access the bits */</span>

	<span class="k">struct</span> <span class="n">core_state</span> <span class="o">*</span><span class="n">core_state</span><span class="p">;</span> <span class="cm">/* coredumping support */</span>
<span class="cp">#ifdef CONFIG_AIO</span>
	<span class="n">spinlock_t</span>		<span class="n">ioctx_lock</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">hlist_head</span>	<span class="n">ioctx_list</span><span class="p">;</span>
<span class="cp">#endif</span>
<span class="cp">#ifdef CONFIG_MM_OWNER</span>
	<span class="cm">/*</span>
<span class="cm">	 * &quot;owner&quot; points to a task that is regarded as the canonical</span>
<span class="cm">	 * user/owner of this mm. All of the following must be true in</span>
<span class="cm">	 * order for it to be changed:</span>
<span class="cm">	 *</span>
<span class="cm">	 * current == mm-&gt;owner</span>
<span class="cm">	 * current-&gt;mm != mm</span>
<span class="cm">	 * new_owner-&gt;mm == mm</span>
<span class="cm">	 * new_owner-&gt;alloc_lock is held</span>
<span class="cm">	 */</span>
	<span class="k">struct</span> <span class="n">task_struct</span> <span class="n">__rcu</span> <span class="o">*</span><span class="n">owner</span><span class="p">;</span>
<span class="cp">#endif</span>

	<span class="cm">/* store ref to file /proc/&lt;pid&gt;/exe symlink points to */</span>
	<span class="k">struct</span> <span class="n">file</span> <span class="o">*</span><span class="n">exe_file</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">num_exe_file_vmas</span><span class="p">;</span>
<span class="cp">#ifdef CONFIG_MMU_NOTIFIER</span>
	<span class="k">struct</span> <span class="n">mmu_notifier_mm</span> <span class="o">*</span><span class="n">mmu_notifier_mm</span><span class="p">;</span>
<span class="cp">#endif</span>
<span class="cp">#ifdef CONFIG_TRANSPARENT_HUGEPAGE</span>
	<span class="n">pgtable_t</span> <span class="n">pmd_huge_pte</span><span class="p">;</span> <span class="cm">/* protected by page_table_lock */</span>
<span class="cp">#endif</span>
<span class="cp">#ifdef CONFIG_CPUMASK_OFFSTACK</span>
	<span class="k">struct</span> <span class="n">cpumask</span> <span class="n">cpumask_allocation</span><span class="p">;</span>
<span class="cp">#endif</span>
	<span class="k">struct</span> <span class="n">uprobes_state</span> <span class="n">uprobes_state</span><span class="p">;</span>
<span class="p">};</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">mm_init_cpumask</span><span class="p">(</span><span class="k">struct</span> <span class="n">mm_struct</span> <span class="o">*</span><span class="n">mm</span><span class="p">)</span>
<span class="p">{</span>
<span class="cp">#ifdef CONFIG_CPUMASK_OFFSTACK</span>
	<span class="n">mm</span><span class="o">-&gt;</span><span class="n">cpu_vm_mask_var</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">mm</span><span class="o">-&gt;</span><span class="n">cpumask_allocation</span><span class="p">;</span>
<span class="cp">#endif</span>
<span class="p">}</span>

<span class="cm">/* Future-safe accessor for struct mm_struct&#39;s cpu_vm_mask. */</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="n">cpumask_t</span> <span class="o">*</span><span class="nf">mm_cpumask</span><span class="p">(</span><span class="k">struct</span> <span class="n">mm_struct</span> <span class="o">*</span><span class="n">mm</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="n">mm</span><span class="o">-&gt;</span><span class="n">cpu_vm_mask_var</span><span class="p">;</span>
<span class="p">}</span>

<span class="cp">#endif </span><span class="cm">/* _LINUX_MM_TYPES_H */</span><span class="cp"></span>

</pre></div></td></tr>

</tbody>
</table>
</div>

</body>
<script>docas={repo:"joekychen/linux",depth:2}</script>
<script>document.write('<script src=' + ('__proto__' in {} ? 'http://cdnjs.cloudflare.com/ajax/libs/zepto/1.0rc1/zepto.min.js' : 'https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js')+'><\\/script>')</script>
<script src="http://baoshan.github.com/moment/min/moment.min.js"></script>
<script src="../../javascript/docco.min.js"></script>
</html>
