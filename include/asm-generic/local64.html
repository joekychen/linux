<!DOCTYPE html>
<html><head><title>joekychen/linux » include › asm-generic › local64.h

</title>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta name="generator" content="Docco">
<link rel="stylesheet" media="all" href="../../stylesheets/docco.min.css" />


</head>
<body>
<div id="container">
<div id="background"></div>
<table cellpadding="0" cellspacing="0">
<thead><tr><th class="docs"><a id="home" href="../../index.html"></a><h1>local64.h</h1></th><th class="code"></th></tr></thead>
<tbody>


<tr id="section-1"><td class="docs"><div class="pilwrap"><a class="pilcrow" href="#section-1">&#182;</a></div></td><td class="code"><div class="highlight"><pre><span class="cp">#ifndef _ASM_GENERIC_LOCAL64_H</span>
<span class="cp">#define _ASM_GENERIC_LOCAL64_H</span>

<span class="cp">#include &lt;linux/percpu.h&gt;</span>
<span class="cp">#include &lt;asm/types.h&gt;</span>

<span class="cm">/*</span>
<span class="cm"> * A signed long type for operations which are atomic for a single CPU.</span>
<span class="cm"> * Usually used in combination with per-cpu variables.</span>
<span class="cm"> *</span>
<span class="cm"> * This is the default implementation, which uses atomic64_t.  Which is</span>
<span class="cm"> * rather pointless.  The whole point behind local64_t is that some processors</span>
<span class="cm"> * can perform atomic adds and subtracts in a manner which is atomic wrt IRQs</span>
<span class="cm"> * running on this CPU.  local64_t allows exploitation of such capabilities.</span>
<span class="cm"> */</span>

<span class="cm">/* Implement in terms of atomics. */</span>

<span class="cp">#if BITS_PER_LONG == 64</span>

<span class="cp">#include &lt;asm/local.h&gt;</span>

<span class="k">typedef</span> <span class="k">struct</span> <span class="p">{</span>
	<span class="n">local_t</span> <span class="n">a</span><span class="p">;</span>
<span class="p">}</span> <span class="n">local64_t</span><span class="p">;</span>

<span class="cp">#define LOCAL64_INIT(i)	{ LOCAL_INIT(i) }</span>

<span class="cp">#define local64_read(l)		local_read(&amp;(l)-&gt;a)</span>
<span class="cp">#define local64_set(l,i)	local_set((&amp;(l)-&gt;a),(i))</span>
<span class="cp">#define local64_inc(l)		local_inc(&amp;(l)-&gt;a)</span>
<span class="cp">#define local64_dec(l)		local_dec(&amp;(l)-&gt;a)</span>
<span class="cp">#define local64_add(i,l)	local_add((i),(&amp;(l)-&gt;a))</span>
<span class="cp">#define local64_sub(i,l)	local_sub((i),(&amp;(l)-&gt;a))</span>

<span class="cp">#define local64_sub_and_test(i, l) local_sub_and_test((i), (&amp;(l)-&gt;a))</span>
<span class="cp">#define local64_dec_and_test(l) local_dec_and_test(&amp;(l)-&gt;a)</span>
<span class="cp">#define local64_inc_and_test(l) local_inc_and_test(&amp;(l)-&gt;a)</span>
<span class="cp">#define local64_add_negative(i, l) local_add_negative((i), (&amp;(l)-&gt;a))</span>
<span class="cp">#define local64_add_return(i, l) local_add_return((i), (&amp;(l)-&gt;a))</span>
<span class="cp">#define local64_sub_return(i, l) local_sub_return((i), (&amp;(l)-&gt;a))</span>
<span class="cp">#define local64_inc_return(l)	local_inc_return(&amp;(l)-&gt;a)</span>

<span class="cp">#define local64_cmpxchg(l, o, n) local_cmpxchg((&amp;(l)-&gt;a), (o), (n))</span>
<span class="cp">#define local64_xchg(l, n)	local_xchg((&amp;(l)-&gt;a), (n))</span>
<span class="cp">#define local64_add_unless(l, _a, u) local_add_unless((&amp;(l)-&gt;a), (_a), (u))</span>
<span class="cp">#define local64_inc_not_zero(l)	local_inc_not_zero(&amp;(l)-&gt;a)</span>

<span class="cm">/* Non-atomic variants, ie. preemption disabled and won&#39;t be touched</span>
<span class="cm"> * in interrupt, etc.  Some archs can optimize this case well. */</span>
<span class="cp">#define __local64_inc(l)	local64_set((l), local64_read(l) + 1)</span>
<span class="cp">#define __local64_dec(l)	local64_set((l), local64_read(l) - 1)</span>
<span class="cp">#define __local64_add(i,l)	local64_set((l), local64_read(l) + (i))</span>
<span class="cp">#define __local64_sub(i,l)	local64_set((l), local64_read(l) - (i))</span>

<span class="cp">#else </span><span class="cm">/* BITS_PER_LONG != 64 */</span><span class="cp"></span>

<span class="cp">#include &lt;linux/atomic.h&gt;</span>

<span class="cm">/* Don&#39;t use typedef: don&#39;t want them to be mixed with atomic_t&#39;s. */</span>
<span class="k">typedef</span> <span class="k">struct</span> <span class="p">{</span>
	<span class="n">atomic64_t</span> <span class="n">a</span><span class="p">;</span>
<span class="p">}</span> <span class="n">local64_t</span><span class="p">;</span>

<span class="cp">#define LOCAL64_INIT(i)	{ ATOMIC_LONG_INIT(i) }</span>

<span class="cp">#define local64_read(l)		atomic64_read(&amp;(l)-&gt;a)</span>
<span class="cp">#define local64_set(l,i)	atomic64_set((&amp;(l)-&gt;a),(i))</span>
<span class="cp">#define local64_inc(l)		atomic64_inc(&amp;(l)-&gt;a)</span>
<span class="cp">#define local64_dec(l)		atomic64_dec(&amp;(l)-&gt;a)</span>
<span class="cp">#define local64_add(i,l)	atomic64_add((i),(&amp;(l)-&gt;a))</span>
<span class="cp">#define local64_sub(i,l)	atomic64_sub((i),(&amp;(l)-&gt;a))</span>

<span class="cp">#define local64_sub_and_test(i, l) atomic64_sub_and_test((i), (&amp;(l)-&gt;a))</span>
<span class="cp">#define local64_dec_and_test(l) atomic64_dec_and_test(&amp;(l)-&gt;a)</span>
<span class="cp">#define local64_inc_and_test(l) atomic64_inc_and_test(&amp;(l)-&gt;a)</span>
<span class="cp">#define local64_add_negative(i, l) atomic64_add_negative((i), (&amp;(l)-&gt;a))</span>
<span class="cp">#define local64_add_return(i, l) atomic64_add_return((i), (&amp;(l)-&gt;a))</span>
<span class="cp">#define local64_sub_return(i, l) atomic64_sub_return((i), (&amp;(l)-&gt;a))</span>
<span class="cp">#define local64_inc_return(l)	atomic64_inc_return(&amp;(l)-&gt;a)</span>

<span class="cp">#define local64_cmpxchg(l, o, n) atomic64_cmpxchg((&amp;(l)-&gt;a), (o), (n))</span>
<span class="cp">#define local64_xchg(l, n)	atomic64_xchg((&amp;(l)-&gt;a), (n))</span>
<span class="cp">#define local64_add_unless(l, _a, u) atomic64_add_unless((&amp;(l)-&gt;a), (_a), (u))</span>
<span class="cp">#define local64_inc_not_zero(l)	atomic64_inc_not_zero(&amp;(l)-&gt;a)</span>

<span class="cm">/* Non-atomic variants, ie. preemption disabled and won&#39;t be touched</span>
<span class="cm"> * in interrupt, etc.  Some archs can optimize this case well. */</span>
<span class="cp">#define __local64_inc(l)	local64_set((l), local64_read(l) + 1)</span>
<span class="cp">#define __local64_dec(l)	local64_set((l), local64_read(l) - 1)</span>
<span class="cp">#define __local64_add(i,l)	local64_set((l), local64_read(l) + (i))</span>
<span class="cp">#define __local64_sub(i,l)	local64_set((l), local64_read(l) - (i))</span>

<span class="cp">#endif </span><span class="cm">/* BITS_PER_LONG != 64 */</span><span class="cp"></span>

<span class="cp">#endif </span><span class="cm">/* _ASM_GENERIC_LOCAL64_H */</span><span class="cp"></span>

</pre></div></td></tr>

</tbody>
</table>
</div>

</body>
<script>docas={repo:"joekychen/linux",depth:2}</script>
<script>document.write('<script src=' + ('__proto__' in {} ? 'http://cdnjs.cloudflare.com/ajax/libs/zepto/1.0rc1/zepto.min.js' : 'https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js')+'><\\/script>')</script>
<script src="http://baoshan.github.com/moment/min/moment.min.js"></script>
<script src="../../javascript/docco.min.js"></script>
</html>
