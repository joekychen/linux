<!DOCTYPE html>
<html><head><title>joekychen/linux » arch › x86 › kernel › nmi.c

</title>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta name="generator" content="Docco">
<link rel="stylesheet" media="all" href="../../../stylesheets/docco.min.css" />


</head>
<body>
<div id="container">
<div id="background"></div>
<table cellpadding="0" cellspacing="0">
<thead><tr><th class="docs"><a id="home" href="../../../index.html"></a><h1>nmi.c</h1></th><th class="code"></th></tr></thead>
<tbody>


<tr id="section-1"><td class="docs"><div class="pilwrap"><a class="pilcrow" href="#section-1">&#182;</a></div></td><td class="code"><div class="highlight"><pre><span class="cm">/*</span>
<span class="cm"> *  Copyright (C) 1991, 1992  Linus Torvalds</span>
<span class="cm"> *  Copyright (C) 2000, 2001, 2002 Andi Kleen, SuSE Labs</span>
<span class="cm"> *  Copyright (C) 2011	Don Zickus Red Hat, Inc.</span>
<span class="cm"> *</span>
<span class="cm"> *  Pentium III FXSR, SSE support</span>
<span class="cm"> *	Gareth Hughes &lt;gareth@valinux.com&gt;, May 2000</span>
<span class="cm"> */</span>

<span class="cm">/*</span>
<span class="cm"> * Handle hardware traps and faults.</span>
<span class="cm"> */</span>
<span class="cp">#include &lt;linux/spinlock.h&gt;</span>
<span class="cp">#include &lt;linux/kprobes.h&gt;</span>
<span class="cp">#include &lt;linux/kdebug.h&gt;</span>
<span class="cp">#include &lt;linux/nmi.h&gt;</span>
<span class="cp">#include &lt;linux/delay.h&gt;</span>
<span class="cp">#include &lt;linux/hardirq.h&gt;</span>
<span class="cp">#include &lt;linux/slab.h&gt;</span>
<span class="cp">#include &lt;linux/export.h&gt;</span>

<span class="cp">#if defined(CONFIG_EDAC)</span>
<span class="cp">#include &lt;linux/edac.h&gt;</span>
<span class="cp">#endif</span>

<span class="cp">#include &lt;linux/atomic.h&gt;</span>
<span class="cp">#include &lt;asm/traps.h&gt;</span>
<span class="cp">#include &lt;asm/mach_traps.h&gt;</span>
<span class="cp">#include &lt;asm/nmi.h&gt;</span>
<span class="cp">#include &lt;asm/x86_init.h&gt;</span>

<span class="k">struct</span> <span class="n">nmi_desc</span> <span class="p">{</span>
	<span class="n">spinlock_t</span> <span class="n">lock</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">list_head</span> <span class="n">head</span><span class="p">;</span>
<span class="p">};</span>

<span class="k">static</span> <span class="k">struct</span> <span class="n">nmi_desc</span> <span class="n">nmi_desc</span><span class="p">[</span><span class="n">NMI_MAX</span><span class="p">]</span> <span class="o">=</span> 
<span class="p">{</span>
	<span class="p">{</span>
		<span class="p">.</span><span class="n">lock</span> <span class="o">=</span> <span class="n">__SPIN_LOCK_UNLOCKED</span><span class="p">(</span><span class="o">&amp;</span><span class="n">nmi_desc</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">lock</span><span class="p">),</span>
		<span class="p">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">LIST_HEAD_INIT</span><span class="p">(</span><span class="n">nmi_desc</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">head</span><span class="p">),</span>
	<span class="p">},</span>
	<span class="p">{</span>
		<span class="p">.</span><span class="n">lock</span> <span class="o">=</span> <span class="n">__SPIN_LOCK_UNLOCKED</span><span class="p">(</span><span class="o">&amp;</span><span class="n">nmi_desc</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">lock</span><span class="p">),</span>
		<span class="p">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">LIST_HEAD_INIT</span><span class="p">(</span><span class="n">nmi_desc</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">head</span><span class="p">),</span>
	<span class="p">},</span>
	<span class="p">{</span>
		<span class="p">.</span><span class="n">lock</span> <span class="o">=</span> <span class="n">__SPIN_LOCK_UNLOCKED</span><span class="p">(</span><span class="o">&amp;</span><span class="n">nmi_desc</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">lock</span><span class="p">),</span>
		<span class="p">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">LIST_HEAD_INIT</span><span class="p">(</span><span class="n">nmi_desc</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">head</span><span class="p">),</span>
	<span class="p">},</span>
	<span class="p">{</span>
		<span class="p">.</span><span class="n">lock</span> <span class="o">=</span> <span class="n">__SPIN_LOCK_UNLOCKED</span><span class="p">(</span><span class="o">&amp;</span><span class="n">nmi_desc</span><span class="p">[</span><span class="mi">3</span><span class="p">].</span><span class="n">lock</span><span class="p">),</span>
		<span class="p">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">LIST_HEAD_INIT</span><span class="p">(</span><span class="n">nmi_desc</span><span class="p">[</span><span class="mi">3</span><span class="p">].</span><span class="n">head</span><span class="p">),</span>
	<span class="p">},</span>

<span class="p">};</span>

<span class="k">struct</span> <span class="n">nmi_stats</span> <span class="p">{</span>
	<span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">normal</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">unknown</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">external</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">swallow</span><span class="p">;</span>
<span class="p">};</span>

<span class="k">static</span> <span class="n">DEFINE_PER_CPU</span><span class="p">(</span><span class="k">struct</span> <span class="n">nmi_stats</span><span class="p">,</span> <span class="n">nmi_stats</span><span class="p">);</span>

<span class="k">static</span> <span class="kt">int</span> <span class="n">ignore_nmis</span><span class="p">;</span>

<span class="kt">int</span> <span class="n">unknown_nmi_panic</span><span class="p">;</span>
<span class="cm">/*</span>
<span class="cm"> * Prevent NMI reason port (0x61) being accessed simultaneously, can</span>
<span class="cm"> * only be used in NMI handler.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="n">DEFINE_RAW_SPINLOCK</span><span class="p">(</span><span class="n">nmi_reason_lock</span><span class="p">);</span>

<span class="k">static</span> <span class="kt">int</span> <span class="n">__init</span> <span class="nf">setup_unknown_nmi_panic</span><span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="n">str</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">unknown_nmi_panic</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
	<span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">__setup</span><span class="p">(</span><span class="s">&quot;unknown_nmi_panic&quot;</span><span class="p">,</span> <span class="n">setup_unknown_nmi_panic</span><span class="p">);</span>

<span class="cp">#define nmi_to_desc(type) (&amp;nmi_desc[type])</span>

<span class="k">static</span> <span class="kt">int</span> <span class="n">__kprobes</span> <span class="nf">nmi_handle</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">type</span><span class="p">,</span> <span class="k">struct</span> <span class="n">pt_regs</span> <span class="o">*</span><span class="n">regs</span><span class="p">,</span> <span class="n">bool</span> <span class="n">b2b</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">struct</span> <span class="n">nmi_desc</span> <span class="o">*</span><span class="n">desc</span> <span class="o">=</span> <span class="n">nmi_to_desc</span><span class="p">(</span><span class="n">type</span><span class="p">);</span>
	<span class="k">struct</span> <span class="n">nmiaction</span> <span class="o">*</span><span class="n">a</span><span class="p">;</span>
	<span class="kt">int</span> <span class="n">handled</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span>

	<span class="n">rcu_read_lock</span><span class="p">();</span>

	<span class="cm">/*</span>
<span class="cm">	 * NMIs are edge-triggered, which means if you have enough</span>
<span class="cm">	 * of them concurrently, you can lose some because only one</span>
<span class="cm">	 * can be latched at any given time.  Walk the whole list</span>
<span class="cm">	 * to handle those situations.</span>
<span class="cm">	 */</span>
	<span class="n">list_for_each_entry_rcu</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">desc</span><span class="o">-&gt;</span><span class="n">head</span><span class="p">,</span> <span class="n">list</span><span class="p">)</span>
		<span class="n">handled</span> <span class="o">+=</span> <span class="n">a</span><span class="o">-&gt;</span><span class="n">handler</span><span class="p">(</span><span class="n">type</span><span class="p">,</span> <span class="n">regs</span><span class="p">);</span>

	<span class="n">rcu_read_unlock</span><span class="p">();</span>

	<span class="cm">/* return total number of NMI events handled */</span>
	<span class="k">return</span> <span class="n">handled</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">__register_nmi_handler</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">type</span><span class="p">,</span> <span class="k">struct</span> <span class="n">nmiaction</span> <span class="o">*</span><span class="n">action</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">struct</span> <span class="n">nmi_desc</span> <span class="o">*</span><span class="n">desc</span> <span class="o">=</span> <span class="n">nmi_to_desc</span><span class="p">(</span><span class="n">type</span><span class="p">);</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">;</span>

	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">action</span><span class="o">-&gt;</span><span class="n">handler</span><span class="p">)</span>
		<span class="k">return</span> <span class="o">-</span><span class="n">EINVAL</span><span class="p">;</span>

	<span class="n">spin_lock_irqsave</span><span class="p">(</span><span class="o">&amp;</span><span class="n">desc</span><span class="o">-&gt;</span><span class="n">lock</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>

	<span class="cm">/*</span>
<span class="cm">	 * most handlers of type NMI_UNKNOWN never return because</span>
<span class="cm">	 * they just assume the NMI is theirs.  Just a sanity check</span>
<span class="cm">	 * to manage expectations</span>
<span class="cm">	 */</span>
	<span class="n">WARN_ON_ONCE</span><span class="p">(</span><span class="n">type</span> <span class="o">==</span> <span class="n">NMI_UNKNOWN</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">list_empty</span><span class="p">(</span><span class="o">&amp;</span><span class="n">desc</span><span class="o">-&gt;</span><span class="n">head</span><span class="p">));</span>
	<span class="n">WARN_ON_ONCE</span><span class="p">(</span><span class="n">type</span> <span class="o">==</span> <span class="n">NMI_SERR</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">list_empty</span><span class="p">(</span><span class="o">&amp;</span><span class="n">desc</span><span class="o">-&gt;</span><span class="n">head</span><span class="p">));</span>
	<span class="n">WARN_ON_ONCE</span><span class="p">(</span><span class="n">type</span> <span class="o">==</span> <span class="n">NMI_IO_CHECK</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">list_empty</span><span class="p">(</span><span class="o">&amp;</span><span class="n">desc</span><span class="o">-&gt;</span><span class="n">head</span><span class="p">));</span>

	<span class="cm">/*</span>
<span class="cm">	 * some handlers need to be executed first otherwise a fake</span>
<span class="cm">	 * event confuses some handlers (kdump uses this flag)</span>
<span class="cm">	 */</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">action</span><span class="o">-&gt;</span><span class="n">flags</span> <span class="o">&amp;</span> <span class="n">NMI_FLAG_FIRST</span><span class="p">)</span>
		<span class="n">list_add_rcu</span><span class="p">(</span><span class="o">&amp;</span><span class="n">action</span><span class="o">-&gt;</span><span class="n">list</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">desc</span><span class="o">-&gt;</span><span class="n">head</span><span class="p">);</span>
	<span class="k">else</span>
		<span class="n">list_add_tail_rcu</span><span class="p">(</span><span class="o">&amp;</span><span class="n">action</span><span class="o">-&gt;</span><span class="n">list</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">desc</span><span class="o">-&gt;</span><span class="n">head</span><span class="p">);</span>
	
	<span class="n">spin_unlock_irqrestore</span><span class="p">(</span><span class="o">&amp;</span><span class="n">desc</span><span class="o">-&gt;</span><span class="n">lock</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>
	<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">EXPORT_SYMBOL</span><span class="p">(</span><span class="n">__register_nmi_handler</span><span class="p">);</span>

<span class="kt">void</span> <span class="nf">unregister_nmi_handler</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">type</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">name</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">struct</span> <span class="n">nmi_desc</span> <span class="o">*</span><span class="n">desc</span> <span class="o">=</span> <span class="n">nmi_to_desc</span><span class="p">(</span><span class="n">type</span><span class="p">);</span>
	<span class="k">struct</span> <span class="n">nmiaction</span> <span class="o">*</span><span class="n">n</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">;</span>

	<span class="n">spin_lock_irqsave</span><span class="p">(</span><span class="o">&amp;</span><span class="n">desc</span><span class="o">-&gt;</span><span class="n">lock</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>

	<span class="n">list_for_each_entry_rcu</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">desc</span><span class="o">-&gt;</span><span class="n">head</span><span class="p">,</span> <span class="n">list</span><span class="p">)</span> <span class="p">{</span>
		<span class="cm">/*</span>
<span class="cm">		 * the name passed in to describe the nmi handler</span>
<span class="cm">		 * is used as the lookup key</span>
<span class="cm">		 */</span>
		<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">strcmp</span><span class="p">(</span><span class="n">n</span><span class="o">-&gt;</span><span class="n">name</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span> <span class="p">{</span>
			<span class="n">WARN</span><span class="p">(</span><span class="n">in_nmi</span><span class="p">(),</span>
				<span class="s">&quot;Trying to free NMI (%s) from NMI context!</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">n</span><span class="o">-&gt;</span><span class="n">name</span><span class="p">);</span>
			<span class="n">list_del_rcu</span><span class="p">(</span><span class="o">&amp;</span><span class="n">n</span><span class="o">-&gt;</span><span class="n">list</span><span class="p">);</span>
			<span class="k">break</span><span class="p">;</span>
		<span class="p">}</span>
	<span class="p">}</span>

	<span class="n">spin_unlock_irqrestore</span><span class="p">(</span><span class="o">&amp;</span><span class="n">desc</span><span class="o">-&gt;</span><span class="n">lock</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>
	<span class="n">synchronize_rcu</span><span class="p">();</span>
<span class="p">}</span>
<span class="n">EXPORT_SYMBOL_GPL</span><span class="p">(</span><span class="n">unregister_nmi_handler</span><span class="p">);</span>

<span class="k">static</span> <span class="n">__kprobes</span> <span class="kt">void</span>
<span class="nf">pci_serr_error</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">char</span> <span class="n">reason</span><span class="p">,</span> <span class="k">struct</span> <span class="n">pt_regs</span> <span class="o">*</span><span class="n">regs</span><span class="p">)</span>
<span class="p">{</span>
	<span class="cm">/* check to see if anyone registered against these types of errors */</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">nmi_handle</span><span class="p">(</span><span class="n">NMI_SERR</span><span class="p">,</span> <span class="n">regs</span><span class="p">,</span> <span class="nb">false</span><span class="p">))</span>
		<span class="k">return</span><span class="p">;</span>

	<span class="n">pr_emerg</span><span class="p">(</span><span class="s">&quot;NMI: PCI system error (SERR) for reason %02x on CPU %d.</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span>
		 <span class="n">reason</span><span class="p">,</span> <span class="n">smp_processor_id</span><span class="p">());</span>

	<span class="cm">/*</span>
<span class="cm">	 * On some machines, PCI SERR line is used to report memory</span>
<span class="cm">	 * errors. EDAC makes use of it.</span>
<span class="cm">	 */</span>
<span class="cp">#if defined(CONFIG_EDAC)</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">edac_handler_set</span><span class="p">())</span> <span class="p">{</span>
		<span class="n">edac_atomic_assert_error</span><span class="p">();</span>
		<span class="k">return</span><span class="p">;</span>
	<span class="p">}</span>
<span class="cp">#endif</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">panic_on_unrecovered_nmi</span><span class="p">)</span>
		<span class="n">panic</span><span class="p">(</span><span class="s">&quot;NMI: Not continuing&quot;</span><span class="p">);</span>

	<span class="n">pr_emerg</span><span class="p">(</span><span class="s">&quot;Dazed and confused, but trying to continue</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>

	<span class="cm">/* Clear and disable the PCI SERR error line. */</span>
	<span class="n">reason</span> <span class="o">=</span> <span class="p">(</span><span class="n">reason</span> <span class="o">&amp;</span> <span class="n">NMI_REASON_CLEAR_MASK</span><span class="p">)</span> <span class="o">|</span> <span class="n">NMI_REASON_CLEAR_SERR</span><span class="p">;</span>
	<span class="n">outb</span><span class="p">(</span><span class="n">reason</span><span class="p">,</span> <span class="n">NMI_REASON_PORT</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">static</span> <span class="n">__kprobes</span> <span class="kt">void</span>
<span class="nf">io_check_error</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">char</span> <span class="n">reason</span><span class="p">,</span> <span class="k">struct</span> <span class="n">pt_regs</span> <span class="o">*</span><span class="n">regs</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">i</span><span class="p">;</span>

	<span class="cm">/* check to see if anyone registered against these types of errors */</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">nmi_handle</span><span class="p">(</span><span class="n">NMI_IO_CHECK</span><span class="p">,</span> <span class="n">regs</span><span class="p">,</span> <span class="nb">false</span><span class="p">))</span>
		<span class="k">return</span><span class="p">;</span>

	<span class="n">pr_emerg</span><span class="p">(</span>
	<span class="s">&quot;NMI: IOCK error (debug interrupt?) for reason %02x on CPU %d.</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span>
		 <span class="n">reason</span><span class="p">,</span> <span class="n">smp_processor_id</span><span class="p">());</span>
	<span class="n">show_regs</span><span class="p">(</span><span class="n">regs</span><span class="p">);</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">panic_on_io_nmi</span><span class="p">)</span>
		<span class="n">panic</span><span class="p">(</span><span class="s">&quot;NMI IOCK error: Not continuing&quot;</span><span class="p">);</span>

	<span class="cm">/* Re-enable the IOCK line, wait for a few seconds */</span>
	<span class="n">reason</span> <span class="o">=</span> <span class="p">(</span><span class="n">reason</span> <span class="o">&amp;</span> <span class="n">NMI_REASON_CLEAR_MASK</span><span class="p">)</span> <span class="o">|</span> <span class="n">NMI_REASON_CLEAR_IOCHK</span><span class="p">;</span>
	<span class="n">outb</span><span class="p">(</span><span class="n">reason</span><span class="p">,</span> <span class="n">NMI_REASON_PORT</span><span class="p">);</span>

	<span class="n">i</span> <span class="o">=</span> <span class="mi">20000</span><span class="p">;</span>
	<span class="k">while</span> <span class="p">(</span><span class="o">--</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">touch_nmi_watchdog</span><span class="p">();</span>
		<span class="n">udelay</span><span class="p">(</span><span class="mi">100</span><span class="p">);</span>
	<span class="p">}</span>

	<span class="n">reason</span> <span class="o">&amp;=</span> <span class="o">~</span><span class="n">NMI_REASON_CLEAR_IOCHK</span><span class="p">;</span>
	<span class="n">outb</span><span class="p">(</span><span class="n">reason</span><span class="p">,</span> <span class="n">NMI_REASON_PORT</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">static</span> <span class="n">__kprobes</span> <span class="kt">void</span>
<span class="nf">unknown_nmi_error</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">char</span> <span class="n">reason</span><span class="p">,</span> <span class="k">struct</span> <span class="n">pt_regs</span> <span class="o">*</span><span class="n">regs</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">int</span> <span class="n">handled</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * Use &#39;false&#39; as back-to-back NMIs are dealt with one level up.</span>
<span class="cm">	 * Of course this makes having multiple &#39;unknown&#39; handlers useless</span>
<span class="cm">	 * as only the first one is ever run (unless it can actually determine</span>
<span class="cm">	 * if it caused the NMI)</span>
<span class="cm">	 */</span>
	<span class="n">handled</span> <span class="o">=</span> <span class="n">nmi_handle</span><span class="p">(</span><span class="n">NMI_UNKNOWN</span><span class="p">,</span> <span class="n">regs</span><span class="p">,</span> <span class="nb">false</span><span class="p">);</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">handled</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">__this_cpu_add</span><span class="p">(</span><span class="n">nmi_stats</span><span class="p">.</span><span class="n">unknown</span><span class="p">,</span> <span class="n">handled</span><span class="p">);</span>
		<span class="k">return</span><span class="p">;</span>
	<span class="p">}</span>

	<span class="n">__this_cpu_add</span><span class="p">(</span><span class="n">nmi_stats</span><span class="p">.</span><span class="n">unknown</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>

	<span class="n">pr_emerg</span><span class="p">(</span><span class="s">&quot;Uhhuh. NMI received for unknown reason %02x on CPU %d.</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span>
		 <span class="n">reason</span><span class="p">,</span> <span class="n">smp_processor_id</span><span class="p">());</span>

	<span class="n">pr_emerg</span><span class="p">(</span><span class="s">&quot;Do you have a strange power saving mode enabled?</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">unknown_nmi_panic</span> <span class="o">||</span> <span class="n">panic_on_unrecovered_nmi</span><span class="p">)</span>
		<span class="n">panic</span><span class="p">(</span><span class="s">&quot;NMI: Not continuing&quot;</span><span class="p">);</span>

	<span class="n">pr_emerg</span><span class="p">(</span><span class="s">&quot;Dazed and confused, but trying to continue</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">static</span> <span class="n">DEFINE_PER_CPU</span><span class="p">(</span><span class="n">bool</span><span class="p">,</span> <span class="n">swallow_nmi</span><span class="p">);</span>
<span class="k">static</span> <span class="n">DEFINE_PER_CPU</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span><span class="p">,</span> <span class="n">last_nmi_rip</span><span class="p">);</span>

<span class="k">static</span> <span class="n">__kprobes</span> <span class="kt">void</span> <span class="nf">default_do_nmi</span><span class="p">(</span><span class="k">struct</span> <span class="n">pt_regs</span> <span class="o">*</span><span class="n">regs</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">unsigned</span> <span class="kt">char</span> <span class="n">reason</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="kt">int</span> <span class="n">handled</span><span class="p">;</span>
	<span class="n">bool</span> <span class="n">b2b</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * CPU-specific NMI must be processed before non-CPU-specific</span>
<span class="cm">	 * NMI, otherwise we may lose it, because the CPU-specific</span>
<span class="cm">	 * NMI can not be detected/processed on other CPUs.</span>
<span class="cm">	 */</span>

	<span class="cm">/*</span>
<span class="cm">	 * Back-to-back NMIs are interesting because they can either</span>
<span class="cm">	 * be two NMI or more than two NMIs (any thing over two is dropped</span>
<span class="cm">	 * due to NMI being edge-triggered).  If this is the second half</span>
<span class="cm">	 * of the back-to-back NMI, assume we dropped things and process</span>
<span class="cm">	 * more handlers.  Otherwise reset the &#39;swallow&#39; NMI behaviour</span>
<span class="cm">	 */</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">regs</span><span class="o">-&gt;</span><span class="n">ip</span> <span class="o">==</span> <span class="n">__this_cpu_read</span><span class="p">(</span><span class="n">last_nmi_rip</span><span class="p">))</span>
		<span class="n">b2b</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>
	<span class="k">else</span>
		<span class="n">__this_cpu_write</span><span class="p">(</span><span class="n">swallow_nmi</span><span class="p">,</span> <span class="nb">false</span><span class="p">);</span>

	<span class="n">__this_cpu_write</span><span class="p">(</span><span class="n">last_nmi_rip</span><span class="p">,</span> <span class="n">regs</span><span class="o">-&gt;</span><span class="n">ip</span><span class="p">);</span>

	<span class="n">handled</span> <span class="o">=</span> <span class="n">nmi_handle</span><span class="p">(</span><span class="n">NMI_LOCAL</span><span class="p">,</span> <span class="n">regs</span><span class="p">,</span> <span class="n">b2b</span><span class="p">);</span>
	<span class="n">__this_cpu_add</span><span class="p">(</span><span class="n">nmi_stats</span><span class="p">.</span><span class="n">normal</span><span class="p">,</span> <span class="n">handled</span><span class="p">);</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">handled</span><span class="p">)</span> <span class="p">{</span>
		<span class="cm">/*</span>
<span class="cm">		 * There are cases when a NMI handler handles multiple</span>
<span class="cm">		 * events in the current NMI.  One of these events may</span>
<span class="cm">		 * be queued for in the next NMI.  Because the event is</span>
<span class="cm">		 * already handled, the next NMI will result in an unknown</span>
<span class="cm">		 * NMI.  Instead lets flag this for a potential NMI to</span>
<span class="cm">		 * swallow.</span>
<span class="cm">		 */</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">handled</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
			<span class="n">__this_cpu_write</span><span class="p">(</span><span class="n">swallow_nmi</span><span class="p">,</span> <span class="nb">true</span><span class="p">);</span>
		<span class="k">return</span><span class="p">;</span>
	<span class="p">}</span>

	<span class="cm">/* Non-CPU-specific NMI: NMI sources can be processed on any CPU */</span>
	<span class="n">raw_spin_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">nmi_reason_lock</span><span class="p">);</span>
	<span class="n">reason</span> <span class="o">=</span> <span class="n">x86_platform</span><span class="p">.</span><span class="n">get_nmi_reason</span><span class="p">();</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">reason</span> <span class="o">&amp;</span> <span class="n">NMI_REASON_MASK</span><span class="p">)</span> <span class="p">{</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">reason</span> <span class="o">&amp;</span> <span class="n">NMI_REASON_SERR</span><span class="p">)</span>
			<span class="n">pci_serr_error</span><span class="p">(</span><span class="n">reason</span><span class="p">,</span> <span class="n">regs</span><span class="p">);</span>
		<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">reason</span> <span class="o">&amp;</span> <span class="n">NMI_REASON_IOCHK</span><span class="p">)</span>
			<span class="n">io_check_error</span><span class="p">(</span><span class="n">reason</span><span class="p">,</span> <span class="n">regs</span><span class="p">);</span>
<span class="cp">#ifdef CONFIG_X86_32</span>
		<span class="cm">/*</span>
<span class="cm">		 * Reassert NMI in case it became active</span>
<span class="cm">		 * meanwhile as it&#39;s edge-triggered:</span>
<span class="cm">		 */</span>
		<span class="n">reassert_nmi</span><span class="p">();</span>
<span class="cp">#endif</span>
		<span class="n">__this_cpu_add</span><span class="p">(</span><span class="n">nmi_stats</span><span class="p">.</span><span class="n">external</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
		<span class="n">raw_spin_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">nmi_reason_lock</span><span class="p">);</span>
		<span class="k">return</span><span class="p">;</span>
	<span class="p">}</span>
	<span class="n">raw_spin_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">nmi_reason_lock</span><span class="p">);</span>

	<span class="cm">/*</span>
<span class="cm">	 * Only one NMI can be latched at a time.  To handle</span>
<span class="cm">	 * this we may process multiple nmi handlers at once to</span>
<span class="cm">	 * cover the case where an NMI is dropped.  The downside</span>
<span class="cm">	 * to this approach is we may process an NMI prematurely,</span>
<span class="cm">	 * while its real NMI is sitting latched.  This will cause</span>
<span class="cm">	 * an unknown NMI on the next run of the NMI processing.</span>
<span class="cm">	 *</span>
<span class="cm">	 * We tried to flag that condition above, by setting the</span>
<span class="cm">	 * swallow_nmi flag when we process more than one event.</span>
<span class="cm">	 * This condition is also only present on the second half</span>
<span class="cm">	 * of a back-to-back NMI, so we flag that condition too.</span>
<span class="cm">	 *</span>
<span class="cm">	 * If both are true, we assume we already processed this</span>
<span class="cm">	 * NMI previously and we swallow it.  Otherwise we reset</span>
<span class="cm">	 * the logic.</span>
<span class="cm">	 *</span>
<span class="cm">	 * There are scenarios where we may accidentally swallow</span>
<span class="cm">	 * a &#39;real&#39; unknown NMI.  For example, while processing</span>
<span class="cm">	 * a perf NMI another perf NMI comes in along with a</span>
<span class="cm">	 * &#39;real&#39; unknown NMI.  These two NMIs get combined into</span>
<span class="cm">	 * one (as descibed above).  When the next NMI gets</span>
<span class="cm">	 * processed, it will be flagged by perf as handled, but</span>
<span class="cm">	 * noone will know that there was a &#39;real&#39; unknown NMI sent</span>
<span class="cm">	 * also.  As a result it gets swallowed.  Or if the first</span>
<span class="cm">	 * perf NMI returns two events handled then the second</span>
<span class="cm">	 * NMI will get eaten by the logic below, again losing a</span>
<span class="cm">	 * &#39;real&#39; unknown NMI.  But this is the best we can do</span>
<span class="cm">	 * for now.</span>
<span class="cm">	 */</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">b2b</span> <span class="o">&amp;&amp;</span> <span class="n">__this_cpu_read</span><span class="p">(</span><span class="n">swallow_nmi</span><span class="p">))</span>
		<span class="n">__this_cpu_add</span><span class="p">(</span><span class="n">nmi_stats</span><span class="p">.</span><span class="n">swallow</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
	<span class="k">else</span>
		<span class="n">unknown_nmi_error</span><span class="p">(</span><span class="n">reason</span><span class="p">,</span> <span class="n">regs</span><span class="p">);</span>
<span class="p">}</span>

<span class="cm">/*</span>
<span class="cm"> * NMIs can hit breakpoints which will cause it to lose its</span>
<span class="cm"> * NMI context with the CPU when the breakpoint does an iret.</span>
<span class="cm"> */</span>
<span class="cp">#ifdef CONFIG_X86_32</span>
<span class="cm">/*</span>
<span class="cm"> * For i386, NMIs use the same stack as the kernel, and we can</span>
<span class="cm"> * add a workaround to the iret problem in C. Simply have 3 states</span>
<span class="cm"> * the NMI can be in.</span>
<span class="cm"> *</span>
<span class="cm"> *  1) not running</span>
<span class="cm"> *  2) executing</span>
<span class="cm"> *  3) latched</span>
<span class="cm"> *</span>
<span class="cm"> * When no NMI is in progress, it is in the &quot;not running&quot; state.</span>
<span class="cm"> * When an NMI comes in, it goes into the &quot;executing&quot; state.</span>
<span class="cm"> * Normally, if another NMI is triggered, it does not interrupt</span>
<span class="cm"> * the running NMI and the HW will simply latch it so that when</span>
<span class="cm"> * the first NMI finishes, it will restart the second NMI.</span>
<span class="cm"> * (Note, the latch is binary, thus multiple NMIs triggering,</span>
<span class="cm"> *  when one is running, are ignored. Only one NMI is restarted.)</span>
<span class="cm"> *</span>
<span class="cm"> * If an NMI hits a breakpoint that executes an iret, another</span>
<span class="cm"> * NMI can preempt it. We do not want to allow this new NMI</span>
<span class="cm"> * to run, but we want to execute it when the first one finishes.</span>
<span class="cm"> * We set the state to &quot;latched&quot;, and the first NMI will perform</span>
<span class="cm"> * an cmpxchg on the state, and if it doesn&#39;t successfully</span>
<span class="cm"> * reset the state to &quot;not running&quot; it will restart the next</span>
<span class="cm"> * NMI.</span>
<span class="cm"> */</span>
<span class="k">enum</span> <span class="n">nmi_states</span> <span class="p">{</span>
	<span class="n">NMI_NOT_RUNNING</span><span class="p">,</span>
	<span class="n">NMI_EXECUTING</span><span class="p">,</span>
	<span class="n">NMI_LATCHED</span><span class="p">,</span>
<span class="p">};</span>
<span class="k">static</span> <span class="n">DEFINE_PER_CPU</span><span class="p">(</span><span class="k">enum</span> <span class="n">nmi_states</span><span class="p">,</span> <span class="n">nmi_state</span><span class="p">);</span>

<span class="cp">#define nmi_nesting_preprocess(regs)					\</span>
<span class="cp">	do {								\</span>
<span class="cp">		if (__get_cpu_var(nmi_state) != NMI_NOT_RUNNING) {	\</span>
<span class="cp">			__get_cpu_var(nmi_state) = NMI_LATCHED;		\</span>
<span class="cp">			return;						\</span>
<span class="cp">		}							\</span>
<span class="cp">	nmi_restart:							\</span>
<span class="cp">		__get_cpu_var(nmi_state) = NMI_EXECUTING;		\</span>
<span class="cp">	} while (0)</span>

<span class="cp">#define nmi_nesting_postprocess()					\</span>
<span class="cp">	do {								\</span>
<span class="cp">		if (cmpxchg(&amp;__get_cpu_var(nmi_state),			\</span>
<span class="cp">		    NMI_EXECUTING, NMI_NOT_RUNNING) != NMI_EXECUTING)	\</span>
<span class="cp">			goto nmi_restart;				\</span>
<span class="cp">	} while (0)</span>
<span class="cp">#else </span><span class="cm">/* x86_64 */</span><span class="cp"></span>
<span class="cm">/*</span>
<span class="cm"> * In x86_64 things are a bit more difficult. This has the same problem</span>
<span class="cm"> * where an NMI hitting a breakpoint that calls iret will remove the</span>
<span class="cm"> * NMI context, allowing a nested NMI to enter. What makes this more</span>
<span class="cm"> * difficult is that both NMIs and breakpoints have their own stack.</span>
<span class="cm"> * When a new NMI or breakpoint is executed, the stack is set to a fixed</span>
<span class="cm"> * point. If an NMI is nested, it will have its stack set at that same</span>
<span class="cm"> * fixed address that the first NMI had, and will start corrupting the</span>
<span class="cm"> * stack. This is handled in entry_64.S, but the same problem exists with</span>
<span class="cm"> * the breakpoint stack.</span>
<span class="cm"> *</span>
<span class="cm"> * If a breakpoint is being processed, and the debug stack is being used,</span>
<span class="cm"> * if an NMI comes in and also hits a breakpoint, the stack pointer</span>
<span class="cm"> * will be set to the same fixed address as the breakpoint that was</span>
<span class="cm"> * interrupted, causing that stack to be corrupted. To handle this case,</span>
<span class="cm"> * check if the stack that was interrupted is the debug stack, and if</span>
<span class="cm"> * so, change the IDT so that new breakpoints will use the current stack</span>
<span class="cm"> * and not switch to the fixed address. On return of the NMI, switch back</span>
<span class="cm"> * to the original IDT.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="n">DEFINE_PER_CPU</span><span class="p">(</span><span class="kt">int</span><span class="p">,</span> <span class="n">update_debug_stack</span><span class="p">);</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">nmi_nesting_preprocess</span><span class="p">(</span><span class="k">struct</span> <span class="n">pt_regs</span> <span class="o">*</span><span class="n">regs</span><span class="p">)</span>
<span class="p">{</span>
	<span class="cm">/*</span>
<span class="cm">	 * If we interrupted a breakpoint, it is possible that</span>
<span class="cm">	 * the nmi handler will have breakpoints too. We need to</span>
<span class="cm">	 * change the IDT such that breakpoints that happen here</span>
<span class="cm">	 * continue to use the NMI stack.</span>
<span class="cm">	 */</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">unlikely</span><span class="p">(</span><span class="n">is_debug_stack</span><span class="p">(</span><span class="n">regs</span><span class="o">-&gt;</span><span class="n">sp</span><span class="p">)))</span> <span class="p">{</span>
		<span class="n">debug_stack_set_zero</span><span class="p">();</span>
		<span class="n">this_cpu_write</span><span class="p">(</span><span class="n">update_debug_stack</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
	<span class="p">}</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">nmi_nesting_postprocess</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">unlikely</span><span class="p">(</span><span class="n">this_cpu_read</span><span class="p">(</span><span class="n">update_debug_stack</span><span class="p">)))</span> <span class="p">{</span>
		<span class="n">debug_stack_reset</span><span class="p">();</span>
		<span class="n">this_cpu_write</span><span class="p">(</span><span class="n">update_debug_stack</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
	<span class="p">}</span>
<span class="p">}</span>
<span class="cp">#endif</span>

<span class="n">dotraplinkage</span> <span class="n">notrace</span> <span class="n">__kprobes</span> <span class="kt">void</span>
<span class="nf">do_nmi</span><span class="p">(</span><span class="k">struct</span> <span class="n">pt_regs</span> <span class="o">*</span><span class="n">regs</span><span class="p">,</span> <span class="kt">long</span> <span class="n">error_code</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">nmi_nesting_preprocess</span><span class="p">(</span><span class="n">regs</span><span class="p">);</span>

	<span class="n">nmi_enter</span><span class="p">();</span>

	<span class="n">inc_irq_stat</span><span class="p">(</span><span class="n">__nmi_count</span><span class="p">);</span>

	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">ignore_nmis</span><span class="p">)</span>
		<span class="n">default_do_nmi</span><span class="p">(</span><span class="n">regs</span><span class="p">);</span>

	<span class="n">nmi_exit</span><span class="p">();</span>

	<span class="cm">/* On i386, may loop back to preprocess */</span>
	<span class="n">nmi_nesting_postprocess</span><span class="p">();</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="nf">stop_nmi</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">ignore_nmis</span><span class="o">++</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="nf">restart_nmi</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">ignore_nmis</span><span class="o">--</span><span class="p">;</span>
<span class="p">}</span>

<span class="cm">/* reset the back-to-back NMI logic */</span>
<span class="kt">void</span> <span class="nf">local_touch_nmi</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">__this_cpu_write</span><span class="p">(</span><span class="n">last_nmi_rip</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
<span class="p">}</span>

</pre></div></td></tr>

</tbody>
</table>
</div>

</body>
<script>docas={repo:"joekychen/linux",depth:3}</script>
<script>document.write('<script src=' + ('__proto__' in {} ? 'http://cdnjs.cloudflare.com/ajax/libs/zepto/1.0rc1/zepto.min.js' : 'https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js')+'><\\/script>')</script>
<script src="http://baoshan.github.com/moment/min/moment.min.js"></script>
<script src="../../../javascript/docco.min.js"></script>
</html>
