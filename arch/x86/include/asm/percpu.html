<!DOCTYPE html>
<html><head><title>joekychen/linux » arch › x86 › include › asm › percpu.h

</title>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta name="generator" content="Docco">
<link rel="stylesheet" media="all" href="../../../../stylesheets/docco.min.css" />


</head>
<body>
<div id="container">
<div id="background"></div>
<table cellpadding="0" cellspacing="0">
<thead><tr><th class="docs"><a id="home" href="../../../../index.html"></a><h1>percpu.h</h1></th><th class="code"></th></tr></thead>
<tbody>


<tr id="section-1"><td class="docs"><div class="pilwrap"><a class="pilcrow" href="#section-1">&#182;</a></div></td><td class="code"><div class="highlight"><pre><span class="cp">#ifndef _ASM_X86_PERCPU_H</span>
<span class="cp">#define _ASM_X86_PERCPU_H</span>

<span class="cp">#ifdef CONFIG_X86_64</span>
<span class="cp">#define __percpu_seg		gs</span>
<span class="cp">#define __percpu_mov_op		movq</span>
<span class="cp">#else</span>
<span class="cp">#define __percpu_seg		fs</span>
<span class="cp">#define __percpu_mov_op		movl</span>
<span class="cp">#endif</span>

<span class="cp">#ifdef __ASSEMBLY__</span>

<span class="cm">/*</span>
<span class="cm"> * PER_CPU finds an address of a per-cpu variable.</span>
<span class="cm"> *</span>
<span class="cm"> * Args:</span>
<span class="cm"> *    var - variable name</span>
<span class="cm"> *    reg - 32bit register</span>
<span class="cm"> *</span>
<span class="cm"> * The resulting address is stored in the &quot;reg&quot; argument.</span>
<span class="cm"> *</span>
<span class="cm"> * Example:</span>
<span class="cm"> *    PER_CPU(cpu_gdt_descr, %ebx)</span>
<span class="cm"> */</span>
<span class="cp">#ifdef CONFIG_SMP</span>
<span class="cp">#define PER_CPU(var, reg)						\</span>
<span class="cp">	__percpu_mov_op %__percpu_seg:this_cpu_off, reg;		\</span>
<span class="cp">	lea var(reg), reg</span>
<span class="cp">#define PER_CPU_VAR(var)	%__percpu_seg:var</span>
<span class="cp">#else </span><span class="cm">/* ! SMP */</span><span class="cp"></span>
<span class="cp">#define PER_CPU(var, reg)	__percpu_mov_op $var, reg</span>
<span class="cp">#define PER_CPU_VAR(var)	var</span>
<span class="cp">#endif	</span><span class="cm">/* SMP */</span><span class="cp"></span>

<span class="cp">#ifdef CONFIG_X86_64_SMP</span>
<span class="cp">#define INIT_PER_CPU_VAR(var)  init_per_cpu__##var</span>
<span class="cp">#else</span>
<span class="cp">#define INIT_PER_CPU_VAR(var)  var</span>
<span class="cp">#endif</span>

<span class="cp">#else </span><span class="cm">/* ...!ASSEMBLY */</span><span class="cp"></span>

<span class="cp">#include &lt;linux/kernel.h&gt;</span>
<span class="cp">#include &lt;linux/stringify.h&gt;</span>

<span class="cp">#ifdef CONFIG_SMP</span>
<span class="cp">#define __percpu_prefix		&quot;%%&quot;__stringify(__percpu_seg)&quot;:&quot;</span>
<span class="cp">#define __my_cpu_offset		this_cpu_read(this_cpu_off)</span>

<span class="cm">/*</span>
<span class="cm"> * Compared to the generic __my_cpu_offset version, the following</span>
<span class="cm"> * saves one instruction and avoids clobbering a temp register.</span>
<span class="cm"> */</span>
<span class="cp">#define __this_cpu_ptr(ptr)				\</span>
<span class="cp">({							\</span>
<span class="cp">	unsigned long tcp_ptr__;			\</span>
<span class="cp">	__verify_pcpu_ptr(ptr);				\</span>
<span class="cp">	asm volatile(&quot;add &quot; __percpu_arg(1) &quot;, %0&quot;	\</span>
<span class="cp">		     : &quot;=r&quot; (tcp_ptr__)			\</span>
<span class="cp">		     : &quot;m&quot; (this_cpu_off), &quot;0&quot; (ptr));	\</span>
<span class="cp">	(typeof(*(ptr)) __kernel __force *)tcp_ptr__;	\</span>
<span class="cp">})</span>
<span class="cp">#else</span>
<span class="cp">#define __percpu_prefix		&quot;&quot;</span>
<span class="cp">#endif</span>

<span class="cp">#define __percpu_arg(x)		__percpu_prefix &quot;%P&quot; #x</span>

<span class="cm">/*</span>
<span class="cm"> * Initialized pointers to per-cpu variables needed for the boot</span>
<span class="cm"> * processor need to use these macros to get the proper address</span>
<span class="cm"> * offset from __per_cpu_load on SMP.</span>
<span class="cm"> *</span>
<span class="cm"> * There also must be an entry in vmlinux_64.lds.S</span>
<span class="cm"> */</span>
<span class="cp">#define DECLARE_INIT_PER_CPU(var) \</span>
<span class="cp">       extern typeof(var) init_per_cpu_var(var)</span>

<span class="cp">#ifdef CONFIG_X86_64_SMP</span>
<span class="cp">#define init_per_cpu_var(var)  init_per_cpu__##var</span>
<span class="cp">#else</span>
<span class="cp">#define init_per_cpu_var(var)  var</span>
<span class="cp">#endif</span>

<span class="cm">/* For arch-specific code, we can use direct single-insn ops (they</span>
<span class="cm"> * don&#39;t give an lvalue though). */</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">__bad_percpu_size</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span>

<span class="cp">#define percpu_to_op(op, var, val)			\</span>
<span class="cp">do {							\</span>
<span class="cp">	typedef typeof(var) pto_T__;			\</span>
<span class="cp">	if (0) {					\</span>
<span class="cp">		pto_T__ pto_tmp__;			\</span>
<span class="cp">		pto_tmp__ = (val);			\</span>
<span class="cp">		(void)pto_tmp__;			\</span>
<span class="cp">	}						\</span>
<span class="cp">	switch (sizeof(var)) {				\</span>
<span class="cp">	case 1:						\</span>
<span class="cp">		asm(op &quot;b %1,&quot;__percpu_arg(0)		\</span>
<span class="cp">		    : &quot;+m&quot; (var)			\</span>
<span class="cp">		    : &quot;qi&quot; ((pto_T__)(val)));		\</span>
<span class="cp">		break;					\</span>
<span class="cp">	case 2:						\</span>
<span class="cp">		asm(op &quot;w %1,&quot;__percpu_arg(0)		\</span>
<span class="cp">		    : &quot;+m&quot; (var)			\</span>
<span class="cp">		    : &quot;ri&quot; ((pto_T__)(val)));		\</span>
<span class="cp">		break;					\</span>
<span class="cp">	case 4:						\</span>
<span class="cp">		asm(op &quot;l %1,&quot;__percpu_arg(0)		\</span>
<span class="cp">		    : &quot;+m&quot; (var)			\</span>
<span class="cp">		    : &quot;ri&quot; ((pto_T__)(val)));		\</span>
<span class="cp">		break;					\</span>
<span class="cp">	case 8:						\</span>
<span class="cp">		asm(op &quot;q %1,&quot;__percpu_arg(0)		\</span>
<span class="cp">		    : &quot;+m&quot; (var)			\</span>
<span class="cp">		    : &quot;re&quot; ((pto_T__)(val)));		\</span>
<span class="cp">		break;					\</span>
<span class="cp">	default: __bad_percpu_size();			\</span>
<span class="cp">	}						\</span>
<span class="cp">} while (0)</span>

<span class="cm">/*</span>
<span class="cm"> * Generate a percpu add to memory instruction and optimize code</span>
<span class="cm"> * if one is added or subtracted.</span>
<span class="cm"> */</span>
<span class="cp">#define percpu_add_op(var, val)						\</span>
<span class="cp">do {									\</span>
<span class="cp">	typedef typeof(var) pao_T__;					\</span>
<span class="cp">	const int pao_ID__ = (__builtin_constant_p(val) &amp;&amp;		\</span>
<span class="cp">			      ((val) == 1 || (val) == -1)) ? (val) : 0;	\</span>
<span class="cp">	if (0) {							\</span>
<span class="cp">		pao_T__ pao_tmp__;					\</span>
<span class="cp">		pao_tmp__ = (val);					\</span>
<span class="cp">		(void)pao_tmp__;					\</span>
<span class="cp">	}								\</span>
<span class="cp">	switch (sizeof(var)) {						\</span>
<span class="cp">	case 1:								\</span>
<span class="cp">		if (pao_ID__ == 1)					\</span>
<span class="cp">			asm(&quot;incb &quot;__percpu_arg(0) : &quot;+m&quot; (var));	\</span>
<span class="cp">		else if (pao_ID__ == -1)				\</span>
<span class="cp">			asm(&quot;decb &quot;__percpu_arg(0) : &quot;+m&quot; (var));	\</span>
<span class="cp">		else							\</span>
<span class="cp">			asm(&quot;addb %1, &quot;__percpu_arg(0)			\</span>
<span class="cp">			    : &quot;+m&quot; (var)				\</span>
<span class="cp">			    : &quot;qi&quot; ((pao_T__)(val)));			\</span>
<span class="cp">		break;							\</span>
<span class="cp">	case 2:								\</span>
<span class="cp">		if (pao_ID__ == 1)					\</span>
<span class="cp">			asm(&quot;incw &quot;__percpu_arg(0) : &quot;+m&quot; (var));	\</span>
<span class="cp">		else if (pao_ID__ == -1)				\</span>
<span class="cp">			asm(&quot;decw &quot;__percpu_arg(0) : &quot;+m&quot; (var));	\</span>
<span class="cp">		else							\</span>
<span class="cp">			asm(&quot;addw %1, &quot;__percpu_arg(0)			\</span>
<span class="cp">			    : &quot;+m&quot; (var)				\</span>
<span class="cp">			    : &quot;ri&quot; ((pao_T__)(val)));			\</span>
<span class="cp">		break;							\</span>
<span class="cp">	case 4:								\</span>
<span class="cp">		if (pao_ID__ == 1)					\</span>
<span class="cp">			asm(&quot;incl &quot;__percpu_arg(0) : &quot;+m&quot; (var));	\</span>
<span class="cp">		else if (pao_ID__ == -1)				\</span>
<span class="cp">			asm(&quot;decl &quot;__percpu_arg(0) : &quot;+m&quot; (var));	\</span>
<span class="cp">		else							\</span>
<span class="cp">			asm(&quot;addl %1, &quot;__percpu_arg(0)			\</span>
<span class="cp">			    : &quot;+m&quot; (var)				\</span>
<span class="cp">			    : &quot;ri&quot; ((pao_T__)(val)));			\</span>
<span class="cp">		break;							\</span>
<span class="cp">	case 8:								\</span>
<span class="cp">		if (pao_ID__ == 1)					\</span>
<span class="cp">			asm(&quot;incq &quot;__percpu_arg(0) : &quot;+m&quot; (var));	\</span>
<span class="cp">		else if (pao_ID__ == -1)				\</span>
<span class="cp">			asm(&quot;decq &quot;__percpu_arg(0) : &quot;+m&quot; (var));	\</span>
<span class="cp">		else							\</span>
<span class="cp">			asm(&quot;addq %1, &quot;__percpu_arg(0)			\</span>
<span class="cp">			    : &quot;+m&quot; (var)				\</span>
<span class="cp">			    : &quot;re&quot; ((pao_T__)(val)));			\</span>
<span class="cp">		break;							\</span>
<span class="cp">	default: __bad_percpu_size();					\</span>
<span class="cp">	}								\</span>
<span class="cp">} while (0)</span>

<span class="cp">#define percpu_from_op(op, var, constraint)		\</span>
<span class="cp">({							\</span>
<span class="cp">	typeof(var) pfo_ret__;				\</span>
<span class="cp">	switch (sizeof(var)) {				\</span>
<span class="cp">	case 1:						\</span>
<span class="cp">		asm(op &quot;b &quot;__percpu_arg(1)&quot;,%0&quot;		\</span>
<span class="cp">		    : &quot;=q&quot; (pfo_ret__)			\</span>
<span class="cp">		    : constraint);			\</span>
<span class="cp">		break;					\</span>
<span class="cp">	case 2:						\</span>
<span class="cp">		asm(op &quot;w &quot;__percpu_arg(1)&quot;,%0&quot;		\</span>
<span class="cp">		    : &quot;=r&quot; (pfo_ret__)			\</span>
<span class="cp">		    : constraint);			\</span>
<span class="cp">		break;					\</span>
<span class="cp">	case 4:						\</span>
<span class="cp">		asm(op &quot;l &quot;__percpu_arg(1)&quot;,%0&quot;		\</span>
<span class="cp">		    : &quot;=r&quot; (pfo_ret__)			\</span>
<span class="cp">		    : constraint);			\</span>
<span class="cp">		break;					\</span>
<span class="cp">	case 8:						\</span>
<span class="cp">		asm(op &quot;q &quot;__percpu_arg(1)&quot;,%0&quot;		\</span>
<span class="cp">		    : &quot;=r&quot; (pfo_ret__)			\</span>
<span class="cp">		    : constraint);			\</span>
<span class="cp">		break;					\</span>
<span class="cp">	default: __bad_percpu_size();			\</span>
<span class="cp">	}						\</span>
<span class="cp">	pfo_ret__;					\</span>
<span class="cp">})</span>

<span class="cp">#define percpu_unary_op(op, var)			\</span>
<span class="cp">({							\</span>
<span class="cp">	switch (sizeof(var)) {				\</span>
<span class="cp">	case 1:						\</span>
<span class="cp">		asm(op &quot;b &quot;__percpu_arg(0)		\</span>
<span class="cp">		    : &quot;+m&quot; (var));			\</span>
<span class="cp">		break;					\</span>
<span class="cp">	case 2:						\</span>
<span class="cp">		asm(op &quot;w &quot;__percpu_arg(0)		\</span>
<span class="cp">		    : &quot;+m&quot; (var));			\</span>
<span class="cp">		break;					\</span>
<span class="cp">	case 4:						\</span>
<span class="cp">		asm(op &quot;l &quot;__percpu_arg(0)		\</span>
<span class="cp">		    : &quot;+m&quot; (var));			\</span>
<span class="cp">		break;					\</span>
<span class="cp">	case 8:						\</span>
<span class="cp">		asm(op &quot;q &quot;__percpu_arg(0)		\</span>
<span class="cp">		    : &quot;+m&quot; (var));			\</span>
<span class="cp">		break;					\</span>
<span class="cp">	default: __bad_percpu_size();			\</span>
<span class="cp">	}						\</span>
<span class="cp">})</span>

<span class="cm">/*</span>
<span class="cm"> * Add return operation</span>
<span class="cm"> */</span>
<span class="cp">#define percpu_add_return_op(var, val)					\</span>
<span class="cp">({									\</span>
<span class="cp">	typeof(var) paro_ret__ = val;					\</span>
<span class="cp">	switch (sizeof(var)) {						\</span>
<span class="cp">	case 1:								\</span>
<span class="cp">		asm(&quot;xaddb %0, &quot;__percpu_arg(1)				\</span>
<span class="cp">			    : &quot;+q&quot; (paro_ret__), &quot;+m&quot; (var)		\</span>
<span class="cp">			    : : &quot;memory&quot;);				\</span>
<span class="cp">		break;							\</span>
<span class="cp">	case 2:								\</span>
<span class="cp">		asm(&quot;xaddw %0, &quot;__percpu_arg(1)				\</span>
<span class="cp">			    : &quot;+r&quot; (paro_ret__), &quot;+m&quot; (var)		\</span>
<span class="cp">			    : : &quot;memory&quot;);				\</span>
<span class="cp">		break;							\</span>
<span class="cp">	case 4:								\</span>
<span class="cp">		asm(&quot;xaddl %0, &quot;__percpu_arg(1)				\</span>
<span class="cp">			    : &quot;+r&quot; (paro_ret__), &quot;+m&quot; (var)		\</span>
<span class="cp">			    : : &quot;memory&quot;);				\</span>
<span class="cp">		break;							\</span>
<span class="cp">	case 8:								\</span>
<span class="cp">		asm(&quot;xaddq %0, &quot;__percpu_arg(1)				\</span>
<span class="cp">			    : &quot;+re&quot; (paro_ret__), &quot;+m&quot; (var)		\</span>
<span class="cp">			    : : &quot;memory&quot;);				\</span>
<span class="cp">		break;							\</span>
<span class="cp">	default: __bad_percpu_size();					\</span>
<span class="cp">	}								\</span>
<span class="cp">	paro_ret__ += val;						\</span>
<span class="cp">	paro_ret__;							\</span>
<span class="cp">})</span>

<span class="cm">/*</span>
<span class="cm"> * xchg is implemented using cmpxchg without a lock prefix. xchg is</span>
<span class="cm"> * expensive due to the implied lock prefix.  The processor cannot prefetch</span>
<span class="cm"> * cachelines if xchg is used.</span>
<span class="cm"> */</span>
<span class="cp">#define percpu_xchg_op(var, nval)					\</span>
<span class="cp">({									\</span>
<span class="cp">	typeof(var) pxo_ret__;						\</span>
<span class="cp">	typeof(var) pxo_new__ = (nval);					\</span>
<span class="cp">	switch (sizeof(var)) {						\</span>
<span class="cp">	case 1:								\</span>
<span class="cp">		asm(&quot;\n\tmov &quot;__percpu_arg(1)&quot;,%%al&quot;			\</span>
<span class="cp">		    &quot;\n1:\tcmpxchgb %2, &quot;__percpu_arg(1)		\</span>
<span class="cp">		    &quot;\n\tjnz 1b&quot;					\</span>
<span class="cp">			    : &quot;=&amp;a&quot; (pxo_ret__), &quot;+m&quot; (var)		\</span>
<span class="cp">			    : &quot;q&quot; (pxo_new__)				\</span>
<span class="cp">			    : &quot;memory&quot;);				\</span>
<span class="cp">		break;							\</span>
<span class="cp">	case 2:								\</span>
<span class="cp">		asm(&quot;\n\tmov &quot;__percpu_arg(1)&quot;,%%ax&quot;			\</span>
<span class="cp">		    &quot;\n1:\tcmpxchgw %2, &quot;__percpu_arg(1)		\</span>
<span class="cp">		    &quot;\n\tjnz 1b&quot;					\</span>
<span class="cp">			    : &quot;=&amp;a&quot; (pxo_ret__), &quot;+m&quot; (var)		\</span>
<span class="cp">			    : &quot;r&quot; (pxo_new__)				\</span>
<span class="cp">			    : &quot;memory&quot;);				\</span>
<span class="cp">		break;							\</span>
<span class="cp">	case 4:								\</span>
<span class="cp">		asm(&quot;\n\tmov &quot;__percpu_arg(1)&quot;,%%eax&quot;			\</span>
<span class="cp">		    &quot;\n1:\tcmpxchgl %2, &quot;__percpu_arg(1)		\</span>
<span class="cp">		    &quot;\n\tjnz 1b&quot;					\</span>
<span class="cp">			    : &quot;=&amp;a&quot; (pxo_ret__), &quot;+m&quot; (var)		\</span>
<span class="cp">			    : &quot;r&quot; (pxo_new__)				\</span>
<span class="cp">			    : &quot;memory&quot;);				\</span>
<span class="cp">		break;							\</span>
<span class="cp">	case 8:								\</span>
<span class="cp">		asm(&quot;\n\tmov &quot;__percpu_arg(1)&quot;,%%rax&quot;			\</span>
<span class="cp">		    &quot;\n1:\tcmpxchgq %2, &quot;__percpu_arg(1)		\</span>
<span class="cp">		    &quot;\n\tjnz 1b&quot;					\</span>
<span class="cp">			    : &quot;=&amp;a&quot; (pxo_ret__), &quot;+m&quot; (var)		\</span>
<span class="cp">			    : &quot;r&quot; (pxo_new__)				\</span>
<span class="cp">			    : &quot;memory&quot;);				\</span>
<span class="cp">		break;							\</span>
<span class="cp">	default: __bad_percpu_size();					\</span>
<span class="cp">	}								\</span>
<span class="cp">	pxo_ret__;							\</span>
<span class="cp">})</span>

<span class="cm">/*</span>
<span class="cm"> * cmpxchg has no such implied lock semantics as a result it is much</span>
<span class="cm"> * more efficient for cpu local operations.</span>
<span class="cm"> */</span>
<span class="cp">#define percpu_cmpxchg_op(var, oval, nval)				\</span>
<span class="cp">({									\</span>
<span class="cp">	typeof(var) pco_ret__;						\</span>
<span class="cp">	typeof(var) pco_old__ = (oval);					\</span>
<span class="cp">	typeof(var) pco_new__ = (nval);					\</span>
<span class="cp">	switch (sizeof(var)) {						\</span>
<span class="cp">	case 1:								\</span>
<span class="cp">		asm(&quot;cmpxchgb %2, &quot;__percpu_arg(1)			\</span>
<span class="cp">			    : &quot;=a&quot; (pco_ret__), &quot;+m&quot; (var)		\</span>
<span class="cp">			    : &quot;q&quot; (pco_new__), &quot;0&quot; (pco_old__)		\</span>
<span class="cp">			    : &quot;memory&quot;);				\</span>
<span class="cp">		break;							\</span>
<span class="cp">	case 2:								\</span>
<span class="cp">		asm(&quot;cmpxchgw %2, &quot;__percpu_arg(1)			\</span>
<span class="cp">			    : &quot;=a&quot; (pco_ret__), &quot;+m&quot; (var)		\</span>
<span class="cp">			    : &quot;r&quot; (pco_new__), &quot;0&quot; (pco_old__)		\</span>
<span class="cp">			    : &quot;memory&quot;);				\</span>
<span class="cp">		break;							\</span>
<span class="cp">	case 4:								\</span>
<span class="cp">		asm(&quot;cmpxchgl %2, &quot;__percpu_arg(1)			\</span>
<span class="cp">			    : &quot;=a&quot; (pco_ret__), &quot;+m&quot; (var)		\</span>
<span class="cp">			    : &quot;r&quot; (pco_new__), &quot;0&quot; (pco_old__)		\</span>
<span class="cp">			    : &quot;memory&quot;);				\</span>
<span class="cp">		break;							\</span>
<span class="cp">	case 8:								\</span>
<span class="cp">		asm(&quot;cmpxchgq %2, &quot;__percpu_arg(1)			\</span>
<span class="cp">			    : &quot;=a&quot; (pco_ret__), &quot;+m&quot; (var)		\</span>
<span class="cp">			    : &quot;r&quot; (pco_new__), &quot;0&quot; (pco_old__)		\</span>
<span class="cp">			    : &quot;memory&quot;);				\</span>
<span class="cp">		break;							\</span>
<span class="cp">	default: __bad_percpu_size();					\</span>
<span class="cp">	}								\</span>
<span class="cp">	pco_ret__;							\</span>
<span class="cp">})</span>

<span class="cm">/*</span>
<span class="cm"> * this_cpu_read() makes gcc load the percpu variable every time it is</span>
<span class="cm"> * accessed while this_cpu_read_stable() allows the value to be cached.</span>
<span class="cm"> * this_cpu_read_stable() is more efficient and can be used if its value</span>
<span class="cm"> * is guaranteed to be valid across cpus.  The current users include</span>
<span class="cm"> * get_current() and get_thread_info() both of which are actually</span>
<span class="cm"> * per-thread variables implemented as per-cpu variables and thus</span>
<span class="cm"> * stable for the duration of the respective task.</span>
<span class="cm"> */</span>
<span class="cp">#define this_cpu_read_stable(var)	percpu_from_op(&quot;mov&quot;, var, &quot;p&quot; (&amp;(var)))</span>

<span class="cp">#define __this_cpu_read_1(pcp)		percpu_from_op(&quot;mov&quot;, (pcp), &quot;m&quot;(pcp))</span>
<span class="cp">#define __this_cpu_read_2(pcp)		percpu_from_op(&quot;mov&quot;, (pcp), &quot;m&quot;(pcp))</span>
<span class="cp">#define __this_cpu_read_4(pcp)		percpu_from_op(&quot;mov&quot;, (pcp), &quot;m&quot;(pcp))</span>

<span class="cp">#define __this_cpu_write_1(pcp, val)	percpu_to_op(&quot;mov&quot;, (pcp), val)</span>
<span class="cp">#define __this_cpu_write_2(pcp, val)	percpu_to_op(&quot;mov&quot;, (pcp), val)</span>
<span class="cp">#define __this_cpu_write_4(pcp, val)	percpu_to_op(&quot;mov&quot;, (pcp), val)</span>
<span class="cp">#define __this_cpu_add_1(pcp, val)	percpu_add_op((pcp), val)</span>
<span class="cp">#define __this_cpu_add_2(pcp, val)	percpu_add_op((pcp), val)</span>
<span class="cp">#define __this_cpu_add_4(pcp, val)	percpu_add_op((pcp), val)</span>
<span class="cp">#define __this_cpu_and_1(pcp, val)	percpu_to_op(&quot;and&quot;, (pcp), val)</span>
<span class="cp">#define __this_cpu_and_2(pcp, val)	percpu_to_op(&quot;and&quot;, (pcp), val)</span>
<span class="cp">#define __this_cpu_and_4(pcp, val)	percpu_to_op(&quot;and&quot;, (pcp), val)</span>
<span class="cp">#define __this_cpu_or_1(pcp, val)	percpu_to_op(&quot;or&quot;, (pcp), val)</span>
<span class="cp">#define __this_cpu_or_2(pcp, val)	percpu_to_op(&quot;or&quot;, (pcp), val)</span>
<span class="cp">#define __this_cpu_or_4(pcp, val)	percpu_to_op(&quot;or&quot;, (pcp), val)</span>
<span class="cp">#define __this_cpu_xor_1(pcp, val)	percpu_to_op(&quot;xor&quot;, (pcp), val)</span>
<span class="cp">#define __this_cpu_xor_2(pcp, val)	percpu_to_op(&quot;xor&quot;, (pcp), val)</span>
<span class="cp">#define __this_cpu_xor_4(pcp, val)	percpu_to_op(&quot;xor&quot;, (pcp), val)</span>
<span class="cp">#define __this_cpu_xchg_1(pcp, val)	percpu_xchg_op(pcp, val)</span>
<span class="cp">#define __this_cpu_xchg_2(pcp, val)	percpu_xchg_op(pcp, val)</span>
<span class="cp">#define __this_cpu_xchg_4(pcp, val)	percpu_xchg_op(pcp, val)</span>

<span class="cp">#define this_cpu_read_1(pcp)		percpu_from_op(&quot;mov&quot;, (pcp), &quot;m&quot;(pcp))</span>
<span class="cp">#define this_cpu_read_2(pcp)		percpu_from_op(&quot;mov&quot;, (pcp), &quot;m&quot;(pcp))</span>
<span class="cp">#define this_cpu_read_4(pcp)		percpu_from_op(&quot;mov&quot;, (pcp), &quot;m&quot;(pcp))</span>
<span class="cp">#define this_cpu_write_1(pcp, val)	percpu_to_op(&quot;mov&quot;, (pcp), val)</span>
<span class="cp">#define this_cpu_write_2(pcp, val)	percpu_to_op(&quot;mov&quot;, (pcp), val)</span>
<span class="cp">#define this_cpu_write_4(pcp, val)	percpu_to_op(&quot;mov&quot;, (pcp), val)</span>
<span class="cp">#define this_cpu_add_1(pcp, val)	percpu_add_op((pcp), val)</span>
<span class="cp">#define this_cpu_add_2(pcp, val)	percpu_add_op((pcp), val)</span>
<span class="cp">#define this_cpu_add_4(pcp, val)	percpu_add_op((pcp), val)</span>
<span class="cp">#define this_cpu_and_1(pcp, val)	percpu_to_op(&quot;and&quot;, (pcp), val)</span>
<span class="cp">#define this_cpu_and_2(pcp, val)	percpu_to_op(&quot;and&quot;, (pcp), val)</span>
<span class="cp">#define this_cpu_and_4(pcp, val)	percpu_to_op(&quot;and&quot;, (pcp), val)</span>
<span class="cp">#define this_cpu_or_1(pcp, val)		percpu_to_op(&quot;or&quot;, (pcp), val)</span>
<span class="cp">#define this_cpu_or_2(pcp, val)		percpu_to_op(&quot;or&quot;, (pcp), val)</span>
<span class="cp">#define this_cpu_or_4(pcp, val)		percpu_to_op(&quot;or&quot;, (pcp), val)</span>
<span class="cp">#define this_cpu_xor_1(pcp, val)	percpu_to_op(&quot;xor&quot;, (pcp), val)</span>
<span class="cp">#define this_cpu_xor_2(pcp, val)	percpu_to_op(&quot;xor&quot;, (pcp), val)</span>
<span class="cp">#define this_cpu_xor_4(pcp, val)	percpu_to_op(&quot;xor&quot;, (pcp), val)</span>
<span class="cp">#define this_cpu_xchg_1(pcp, nval)	percpu_xchg_op(pcp, nval)</span>
<span class="cp">#define this_cpu_xchg_2(pcp, nval)	percpu_xchg_op(pcp, nval)</span>
<span class="cp">#define this_cpu_xchg_4(pcp, nval)	percpu_xchg_op(pcp, nval)</span>

<span class="cp">#ifndef CONFIG_M386</span>
<span class="cp">#define __this_cpu_add_return_1(pcp, val) percpu_add_return_op(pcp, val)</span>
<span class="cp">#define __this_cpu_add_return_2(pcp, val) percpu_add_return_op(pcp, val)</span>
<span class="cp">#define __this_cpu_add_return_4(pcp, val) percpu_add_return_op(pcp, val)</span>
<span class="cp">#define __this_cpu_cmpxchg_1(pcp, oval, nval)	percpu_cmpxchg_op(pcp, oval, nval)</span>
<span class="cp">#define __this_cpu_cmpxchg_2(pcp, oval, nval)	percpu_cmpxchg_op(pcp, oval, nval)</span>
<span class="cp">#define __this_cpu_cmpxchg_4(pcp, oval, nval)	percpu_cmpxchg_op(pcp, oval, nval)</span>

<span class="cp">#define this_cpu_add_return_1(pcp, val)	percpu_add_return_op(pcp, val)</span>
<span class="cp">#define this_cpu_add_return_2(pcp, val)	percpu_add_return_op(pcp, val)</span>
<span class="cp">#define this_cpu_add_return_4(pcp, val)	percpu_add_return_op(pcp, val)</span>
<span class="cp">#define this_cpu_cmpxchg_1(pcp, oval, nval)	percpu_cmpxchg_op(pcp, oval, nval)</span>
<span class="cp">#define this_cpu_cmpxchg_2(pcp, oval, nval)	percpu_cmpxchg_op(pcp, oval, nval)</span>
<span class="cp">#define this_cpu_cmpxchg_4(pcp, oval, nval)	percpu_cmpxchg_op(pcp, oval, nval)</span>

<span class="cp">#endif </span><span class="cm">/* !CONFIG_M386 */</span><span class="cp"></span>

<span class="cp">#ifdef CONFIG_X86_CMPXCHG64</span>
<span class="cp">#define percpu_cmpxchg8b_double(pcp1, pcp2, o1, o2, n1, n2)		\</span>
<span class="cp">({									\</span>
<span class="cp">	bool __ret;							\</span>
<span class="cp">	typeof(pcp1) __o1 = (o1), __n1 = (n1);				\</span>
<span class="cp">	typeof(pcp2) __o2 = (o2), __n2 = (n2);				\</span>
<span class="cp">	asm volatile(&quot;cmpxchg8b &quot;__percpu_arg(1)&quot;\n\tsetz %0\n\t&quot;	\</span>
<span class="cp">		    : &quot;=a&quot; (__ret), &quot;+m&quot; (pcp1), &quot;+m&quot; (pcp2), &quot;+d&quot; (__o2) \</span>
<span class="cp">		    :  &quot;b&quot; (__n1), &quot;c&quot; (__n2), &quot;a&quot; (__o1));		\</span>
<span class="cp">	__ret;								\</span>
<span class="cp">})</span>

<span class="cp">#define __this_cpu_cmpxchg_double_4	percpu_cmpxchg8b_double</span>
<span class="cp">#define this_cpu_cmpxchg_double_4	percpu_cmpxchg8b_double</span>
<span class="cp">#endif </span><span class="cm">/* CONFIG_X86_CMPXCHG64 */</span><span class="cp"></span>

<span class="cm">/*</span>
<span class="cm"> * Per cpu atomic 64 bit operations are only available under 64 bit.</span>
<span class="cm"> * 32 bit must fall back to generic operations.</span>
<span class="cm"> */</span>
<span class="cp">#ifdef CONFIG_X86_64</span>
<span class="cp">#define __this_cpu_read_8(pcp)		percpu_from_op(&quot;mov&quot;, (pcp), &quot;m&quot;(pcp))</span>
<span class="cp">#define __this_cpu_write_8(pcp, val)	percpu_to_op(&quot;mov&quot;, (pcp), val)</span>
<span class="cp">#define __this_cpu_add_8(pcp, val)	percpu_add_op((pcp), val)</span>
<span class="cp">#define __this_cpu_and_8(pcp, val)	percpu_to_op(&quot;and&quot;, (pcp), val)</span>
<span class="cp">#define __this_cpu_or_8(pcp, val)	percpu_to_op(&quot;or&quot;, (pcp), val)</span>
<span class="cp">#define __this_cpu_xor_8(pcp, val)	percpu_to_op(&quot;xor&quot;, (pcp), val)</span>
<span class="cp">#define __this_cpu_add_return_8(pcp, val) percpu_add_return_op(pcp, val)</span>
<span class="cp">#define __this_cpu_xchg_8(pcp, nval)	percpu_xchg_op(pcp, nval)</span>
<span class="cp">#define __this_cpu_cmpxchg_8(pcp, oval, nval)	percpu_cmpxchg_op(pcp, oval, nval)</span>

<span class="cp">#define this_cpu_read_8(pcp)		percpu_from_op(&quot;mov&quot;, (pcp), &quot;m&quot;(pcp))</span>
<span class="cp">#define this_cpu_write_8(pcp, val)	percpu_to_op(&quot;mov&quot;, (pcp), val)</span>
<span class="cp">#define this_cpu_add_8(pcp, val)	percpu_add_op((pcp), val)</span>
<span class="cp">#define this_cpu_and_8(pcp, val)	percpu_to_op(&quot;and&quot;, (pcp), val)</span>
<span class="cp">#define this_cpu_or_8(pcp, val)		percpu_to_op(&quot;or&quot;, (pcp), val)</span>
<span class="cp">#define this_cpu_xor_8(pcp, val)	percpu_to_op(&quot;xor&quot;, (pcp), val)</span>
<span class="cp">#define this_cpu_add_return_8(pcp, val)	percpu_add_return_op(pcp, val)</span>
<span class="cp">#define this_cpu_xchg_8(pcp, nval)	percpu_xchg_op(pcp, nval)</span>
<span class="cp">#define this_cpu_cmpxchg_8(pcp, oval, nval)	percpu_cmpxchg_op(pcp, oval, nval)</span>

<span class="cm">/*</span>
<span class="cm"> * Pretty complex macro to generate cmpxchg16 instruction.  The instruction</span>
<span class="cm"> * is not supported on early AMD64 processors so we must be able to emulate</span>
<span class="cm"> * it in software.  The address used in the cmpxchg16 instruction must be</span>
<span class="cm"> * aligned to a 16 byte boundary.</span>
<span class="cm"> */</span>
<span class="cp">#define percpu_cmpxchg16b_double(pcp1, pcp2, o1, o2, n1, n2)		\</span>
<span class="cp">({									\</span>
<span class="cp">	bool __ret;							\</span>
<span class="cp">	typeof(pcp1) __o1 = (o1), __n1 = (n1);				\</span>
<span class="cp">	typeof(pcp2) __o2 = (o2), __n2 = (n2);				\</span>
<span class="cp">	alternative_io(&quot;leaq %P1,%%rsi\n\tcall this_cpu_cmpxchg16b_emu\n\t&quot;, \</span>
<span class="cp">		       &quot;cmpxchg16b &quot; __percpu_arg(1) &quot;\n\tsetz %0\n\t&quot;,	\</span>
<span class="cp">		       X86_FEATURE_CX16,				\</span>
<span class="cp">		       ASM_OUTPUT2(&quot;=a&quot; (__ret), &quot;+m&quot; (pcp1),		\</span>
<span class="cp">				   &quot;+m&quot; (pcp2), &quot;+d&quot; (__o2)),		\</span>
<span class="cp">		       &quot;b&quot; (__n1), &quot;c&quot; (__n2), &quot;a&quot; (__o1) : &quot;rsi&quot;);	\</span>
<span class="cp">	__ret;								\</span>
<span class="cp">})</span>

<span class="cp">#define __this_cpu_cmpxchg_double_8	percpu_cmpxchg16b_double</span>
<span class="cp">#define this_cpu_cmpxchg_double_8	percpu_cmpxchg16b_double</span>

<span class="cp">#endif</span>

<span class="cm">/* This is not atomic against other CPUs -- CPU preemption needs to be off */</span>
<span class="cp">#define x86_test_and_clear_bit_percpu(bit, var)				\</span>
<span class="cp">({									\</span>
<span class="cp">	int old__;							\</span>
<span class="cp">	asm volatile(&quot;btr %2,&quot;__percpu_arg(1)&quot;\n\tsbbl %0,%0&quot;		\</span>
<span class="cp">		     : &quot;=r&quot; (old__), &quot;+m&quot; (var)				\</span>
<span class="cp">		     : &quot;dIr&quot; (bit));					\</span>
<span class="cp">	old__;								\</span>
<span class="cp">})</span>

<span class="k">static</span> <span class="n">__always_inline</span> <span class="kt">int</span> <span class="nf">x86_this_cpu_constant_test_bit</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">nr</span><span class="p">,</span>
                        <span class="k">const</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">__percpu</span> <span class="o">*</span><span class="n">addr</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">__percpu</span> <span class="o">*</span><span class="n">a</span> <span class="o">=</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span> <span class="o">*</span><span class="p">)</span><span class="n">addr</span> <span class="o">+</span> <span class="n">nr</span> <span class="o">/</span> <span class="n">BITS_PER_LONG</span><span class="p">;</span>

<span class="cp">#ifdef CONFIG_X86_64</span>
	<span class="k">return</span> <span class="p">((</span><span class="mi">1UL</span> <span class="o">&lt;&lt;</span> <span class="p">(</span><span class="n">nr</span> <span class="o">%</span> <span class="n">BITS_PER_LONG</span><span class="p">))</span> <span class="o">&amp;</span> <span class="n">__this_cpu_read_8</span><span class="p">(</span><span class="o">*</span><span class="n">a</span><span class="p">))</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">;</span>
<span class="cp">#else</span>
	<span class="k">return</span> <span class="p">((</span><span class="mi">1UL</span> <span class="o">&lt;&lt;</span> <span class="p">(</span><span class="n">nr</span> <span class="o">%</span> <span class="n">BITS_PER_LONG</span><span class="p">))</span> <span class="o">&amp;</span> <span class="n">__this_cpu_read_4</span><span class="p">(</span><span class="o">*</span><span class="n">a</span><span class="p">))</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">;</span>
<span class="cp">#endif</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">int</span> <span class="nf">x86_this_cpu_variable_test_bit</span><span class="p">(</span><span class="kt">int</span> <span class="n">nr</span><span class="p">,</span>
                        <span class="k">const</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">__percpu</span> <span class="o">*</span><span class="n">addr</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">int</span> <span class="n">oldbit</span><span class="p">;</span>

	<span class="n">asm</span> <span class="k">volatile</span><span class="p">(</span><span class="s">&quot;bt &quot;</span><span class="n">__percpu_arg</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="s">&quot;,%1</span><span class="se">\n\t</span><span class="s">&quot;</span>
			<span class="s">&quot;sbb %0,%0&quot;</span>
			<span class="o">:</span> <span class="s">&quot;=r&quot;</span> <span class="p">(</span><span class="n">oldbit</span><span class="p">)</span>
			<span class="o">:</span> <span class="s">&quot;m&quot;</span> <span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span> <span class="o">*</span><span class="p">)</span><span class="n">addr</span><span class="p">),</span> <span class="s">&quot;Ir&quot;</span> <span class="p">(</span><span class="n">nr</span><span class="p">));</span>

	<span class="k">return</span> <span class="n">oldbit</span><span class="p">;</span>
<span class="p">}</span>

<span class="cp">#define x86_this_cpu_test_bit(nr, addr)			\</span>
<span class="cp">	(__builtin_constant_p((nr))			\</span>
<span class="cp">	 ? x86_this_cpu_constant_test_bit((nr), (addr))	\</span>
<span class="cp">	 : x86_this_cpu_variable_test_bit((nr), (addr)))</span>


<span class="cp">#include &lt;asm-generic/percpu.h&gt;</span>

<span class="cm">/* We can use this directly for local CPU (faster). */</span>
<span class="n">DECLARE_PER_CPU</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span><span class="p">,</span> <span class="n">this_cpu_off</span><span class="p">);</span>

<span class="cp">#endif </span><span class="cm">/* !__ASSEMBLY__ */</span><span class="cp"></span>

<span class="cp">#ifdef CONFIG_SMP</span>

<span class="cm">/*</span>
<span class="cm"> * Define the &quot;EARLY_PER_CPU&quot; macros.  These are used for some per_cpu</span>
<span class="cm"> * variables that are initialized and accessed before there are per_cpu</span>
<span class="cm"> * areas allocated.</span>
<span class="cm"> */</span>

<span class="cp">#define	DEFINE_EARLY_PER_CPU(_type, _name, _initvalue)			\</span>
<span class="cp">	DEFINE_PER_CPU(_type, _name) = _initvalue;			\</span>
<span class="cp">	__typeof__(_type) _name##_early_map[NR_CPUS] __initdata =	\</span>
<span class="cp">				{ [0 ... NR_CPUS-1] = _initvalue };	\</span>
<span class="cp">	__typeof__(_type) *_name##_early_ptr __refdata = _name##_early_map</span>

<span class="cp">#define EXPORT_EARLY_PER_CPU_SYMBOL(_name)			\</span>
<span class="cp">	EXPORT_PER_CPU_SYMBOL(_name)</span>

<span class="cp">#define DECLARE_EARLY_PER_CPU(_type, _name)			\</span>
<span class="cp">	DECLARE_PER_CPU(_type, _name);				\</span>
<span class="cp">	extern __typeof__(_type) *_name##_early_ptr;		\</span>
<span class="cp">	extern __typeof__(_type)  _name##_early_map[]</span>

<span class="cp">#define	early_per_cpu_ptr(_name) (_name##_early_ptr)</span>
<span class="cp">#define	early_per_cpu_map(_name, _idx) (_name##_early_map[_idx])</span>
<span class="cp">#define	early_per_cpu(_name, _cpu) 				\</span>
<span class="cp">	*(early_per_cpu_ptr(_name) ?				\</span>
<span class="cp">		&amp;early_per_cpu_ptr(_name)[_cpu] :		\</span>
<span class="cp">		&amp;per_cpu(_name, _cpu))</span>

<span class="cp">#else	</span><span class="cm">/* !CONFIG_SMP */</span><span class="cp"></span>
<span class="cp">#define	DEFINE_EARLY_PER_CPU(_type, _name, _initvalue)		\</span>
<span class="cp">	DEFINE_PER_CPU(_type, _name) = _initvalue</span>

<span class="cp">#define EXPORT_EARLY_PER_CPU_SYMBOL(_name)			\</span>
<span class="cp">	EXPORT_PER_CPU_SYMBOL(_name)</span>

<span class="cp">#define DECLARE_EARLY_PER_CPU(_type, _name)			\</span>
<span class="cp">	DECLARE_PER_CPU(_type, _name)</span>

<span class="cp">#define	early_per_cpu(_name, _cpu) per_cpu(_name, _cpu)</span>
<span class="cp">#define	early_per_cpu_ptr(_name) NULL</span>
<span class="cm">/* no early_per_cpu_map() */</span>

<span class="cp">#endif	</span><span class="cm">/* !CONFIG_SMP */</span><span class="cp"></span>

<span class="cp">#endif </span><span class="cm">/* _ASM_X86_PERCPU_H */</span><span class="cp"></span>

</pre></div></td></tr>

</tbody>
</table>
</div>

</body>
<script>docas={repo:"joekychen/linux",depth:4}</script>
<script>document.write('<script src=' + ('__proto__' in {} ? 'http://cdnjs.cloudflare.com/ajax/libs/zepto/1.0rc1/zepto.min.js' : 'https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js')+'><\\/script>')</script>
<script src="http://baoshan.github.com/moment/min/moment.min.js"></script>
<script src="../../../../javascript/docco.min.js"></script>
</html>
