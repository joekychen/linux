<!DOCTYPE html>
<html><head><title>joekychen/linux » arch › x86 › include › asm › cmpxchg.h

</title>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta name="generator" content="Docco">
<link rel="stylesheet" media="all" href="../../../../stylesheets/docco.min.css" />


</head>
<body>
<div id="container">
<div id="background"></div>
<table cellpadding="0" cellspacing="0">
<thead><tr><th class="docs"><a id="home" href="../../../../index.html"></a><h1>cmpxchg.h</h1></th><th class="code"></th></tr></thead>
<tbody>


<tr id="section-1"><td class="docs"><div class="pilwrap"><a class="pilcrow" href="#section-1">&#182;</a></div></td><td class="code"><div class="highlight"><pre><span class="cp">#ifndef ASM_X86_CMPXCHG_H</span>
<span class="cp">#define ASM_X86_CMPXCHG_H</span>

<span class="cp">#include &lt;linux/compiler.h&gt;</span>
<span class="cp">#include &lt;asm/alternative.h&gt; </span><span class="cm">/* Provides LOCK_PREFIX */</span><span class="cp"></span>

<span class="cm">/*</span>
<span class="cm"> * Non-existant functions to indicate usage errors at link time</span>
<span class="cm"> * (or compile-time if the compiler implements __compiletime_error().</span>
<span class="cm"> */</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">__xchg_wrong_size</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
	<span class="n">__compiletime_error</span><span class="p">(</span><span class="s">&quot;Bad argument size for xchg&quot;</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">__cmpxchg_wrong_size</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
	<span class="n">__compiletime_error</span><span class="p">(</span><span class="s">&quot;Bad argument size for cmpxchg&quot;</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">__xadd_wrong_size</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
	<span class="n">__compiletime_error</span><span class="p">(</span><span class="s">&quot;Bad argument size for xadd&quot;</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">__add_wrong_size</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
	<span class="n">__compiletime_error</span><span class="p">(</span><span class="s">&quot;Bad argument size for add&quot;</span><span class="p">);</span>

<span class="cm">/*</span>
<span class="cm"> * Constants for operation sizes. On 32-bit, the 64-bit size it set to</span>
<span class="cm"> * -1 because sizeof will never return -1, thereby making those switch</span>
<span class="cm"> * case statements guaranteeed dead code which the compiler will</span>
<span class="cm"> * eliminate, and allowing the &quot;missing symbol in the default case&quot; to</span>
<span class="cm"> * indicate a usage error.</span>
<span class="cm"> */</span>
<span class="cp">#define __X86_CASE_B	1</span>
<span class="cp">#define __X86_CASE_W	2</span>
<span class="cp">#define __X86_CASE_L	4</span>
<span class="cp">#ifdef CONFIG_64BIT</span>
<span class="cp">#define __X86_CASE_Q	8</span>
<span class="cp">#else</span>
<span class="cp">#define	__X86_CASE_Q	-1		</span><span class="cm">/* sizeof will never return -1 */</span><span class="cp"></span>
<span class="cp">#endif</span>

<span class="cm">/* </span>
<span class="cm"> * An exchange-type operation, which takes a value and a pointer, and</span>
<span class="cm"> * returns a the old value.</span>
<span class="cm"> */</span>
<span class="cp">#define __xchg_op(ptr, arg, op, lock)					\</span>
<span class="cp">	({								\</span>
<span class="cp">	        __typeof__ (*(ptr)) __ret = (arg);			\</span>
<span class="cp">		switch (sizeof(*(ptr))) {				\</span>
<span class="cp">		case __X86_CASE_B:					\</span>
<span class="cp">			asm volatile (lock #op &quot;b %b0, %1\n&quot;		\</span>
<span class="cp">				      : &quot;+q&quot; (__ret), &quot;+m&quot; (*(ptr))	\</span>
<span class="cp">				      : : &quot;memory&quot;, &quot;cc&quot;);		\</span>
<span class="cp">			break;						\</span>
<span class="cp">		case __X86_CASE_W:					\</span>
<span class="cp">			asm volatile (lock #op &quot;w %w0, %1\n&quot;		\</span>
<span class="cp">				      : &quot;+r&quot; (__ret), &quot;+m&quot; (*(ptr))	\</span>
<span class="cp">				      : : &quot;memory&quot;, &quot;cc&quot;);		\</span>
<span class="cp">			break;						\</span>
<span class="cp">		case __X86_CASE_L:					\</span>
<span class="cp">			asm volatile (lock #op &quot;l %0, %1\n&quot;		\</span>
<span class="cp">				      : &quot;+r&quot; (__ret), &quot;+m&quot; (*(ptr))	\</span>
<span class="cp">				      : : &quot;memory&quot;, &quot;cc&quot;);		\</span>
<span class="cp">			break;						\</span>
<span class="cp">		case __X86_CASE_Q:					\</span>
<span class="cp">			asm volatile (lock #op &quot;q %q0, %1\n&quot;		\</span>
<span class="cp">				      : &quot;+r&quot; (__ret), &quot;+m&quot; (*(ptr))	\</span>
<span class="cp">				      : : &quot;memory&quot;, &quot;cc&quot;);		\</span>
<span class="cp">			break;						\</span>
<span class="cp">		default:						\</span>
<span class="cp">			__ ## op ## _wrong_size();			\</span>
<span class="cp">		}							\</span>
<span class="cp">		__ret;							\</span>
<span class="cp">	})</span>

<span class="cm">/*</span>
<span class="cm"> * Note: no &quot;lock&quot; prefix even on SMP: xchg always implies lock anyway.</span>
<span class="cm"> * Since this is generally used to protect other memory information, we</span>
<span class="cm"> * use &quot;asm volatile&quot; and &quot;memory&quot; clobbers to prevent gcc from moving</span>
<span class="cm"> * information around.</span>
<span class="cm"> */</span>
<span class="cp">#define xchg(ptr, v)	__xchg_op((ptr), (v), xchg, &quot;&quot;)</span>

<span class="cm">/*</span>
<span class="cm"> * Atomic compare and exchange.  Compare OLD with MEM, if identical,</span>
<span class="cm"> * store NEW in MEM.  Return the initial value in MEM.  Success is</span>
<span class="cm"> * indicated by comparing RETURN with OLD.</span>
<span class="cm"> */</span>
<span class="cp">#define __raw_cmpxchg(ptr, old, new, size, lock)			\</span>
<span class="cp">({									\</span>
<span class="cp">	__typeof__(*(ptr)) __ret;					\</span>
<span class="cp">	__typeof__(*(ptr)) __old = (old);				\</span>
<span class="cp">	__typeof__(*(ptr)) __new = (new);				\</span>
<span class="cp">	switch (size) {							\</span>
<span class="cp">	case __X86_CASE_B:						\</span>
<span class="cp">	{								\</span>
<span class="cp">		volatile u8 *__ptr = (volatile u8 *)(ptr);		\</span>
<span class="cp">		asm volatile(lock &quot;cmpxchgb %2,%1&quot;			\</span>
<span class="cp">			     : &quot;=a&quot; (__ret), &quot;+m&quot; (*__ptr)		\</span>
<span class="cp">			     : &quot;q&quot; (__new), &quot;0&quot; (__old)			\</span>
<span class="cp">			     : &quot;memory&quot;);				\</span>
<span class="cp">		break;							\</span>
<span class="cp">	}								\</span>
<span class="cp">	case __X86_CASE_W:						\</span>
<span class="cp">	{								\</span>
<span class="cp">		volatile u16 *__ptr = (volatile u16 *)(ptr);		\</span>
<span class="cp">		asm volatile(lock &quot;cmpxchgw %2,%1&quot;			\</span>
<span class="cp">			     : &quot;=a&quot; (__ret), &quot;+m&quot; (*__ptr)		\</span>
<span class="cp">			     : &quot;r&quot; (__new), &quot;0&quot; (__old)			\</span>
<span class="cp">			     : &quot;memory&quot;);				\</span>
<span class="cp">		break;							\</span>
<span class="cp">	}								\</span>
<span class="cp">	case __X86_CASE_L:						\</span>
<span class="cp">	{								\</span>
<span class="cp">		volatile u32 *__ptr = (volatile u32 *)(ptr);		\</span>
<span class="cp">		asm volatile(lock &quot;cmpxchgl %2,%1&quot;			\</span>
<span class="cp">			     : &quot;=a&quot; (__ret), &quot;+m&quot; (*__ptr)		\</span>
<span class="cp">			     : &quot;r&quot; (__new), &quot;0&quot; (__old)			\</span>
<span class="cp">			     : &quot;memory&quot;);				\</span>
<span class="cp">		break;							\</span>
<span class="cp">	}								\</span>
<span class="cp">	case __X86_CASE_Q:						\</span>
<span class="cp">	{								\</span>
<span class="cp">		volatile u64 *__ptr = (volatile u64 *)(ptr);		\</span>
<span class="cp">		asm volatile(lock &quot;cmpxchgq %2,%1&quot;			\</span>
<span class="cp">			     : &quot;=a&quot; (__ret), &quot;+m&quot; (*__ptr)		\</span>
<span class="cp">			     : &quot;r&quot; (__new), &quot;0&quot; (__old)			\</span>
<span class="cp">			     : &quot;memory&quot;);				\</span>
<span class="cp">		break;							\</span>
<span class="cp">	}								\</span>
<span class="cp">	default:							\</span>
<span class="cp">		__cmpxchg_wrong_size();					\</span>
<span class="cp">	}								\</span>
<span class="cp">	__ret;								\</span>
<span class="cp">})</span>

<span class="cp">#define __cmpxchg(ptr, old, new, size)					\</span>
<span class="cp">	__raw_cmpxchg((ptr), (old), (new), (size), LOCK_PREFIX)</span>

<span class="cp">#define __sync_cmpxchg(ptr, old, new, size)				\</span>
<span class="cp">	__raw_cmpxchg((ptr), (old), (new), (size), &quot;lock; &quot;)</span>

<span class="cp">#define __cmpxchg_local(ptr, old, new, size)				\</span>
<span class="cp">	__raw_cmpxchg((ptr), (old), (new), (size), &quot;&quot;)</span>

<span class="cp">#ifdef CONFIG_X86_32</span>
<span class="cp"># include &quot;cmpxchg_32.h&quot;</span>
<span class="cp">#else</span>
<span class="cp"># include &quot;cmpxchg_64.h&quot;</span>
<span class="cp">#endif</span>

<span class="cp">#ifdef __HAVE_ARCH_CMPXCHG</span>
<span class="cp">#define cmpxchg(ptr, old, new)						\</span>
<span class="cp">	__cmpxchg(ptr, old, new, sizeof(*(ptr)))</span>

<span class="cp">#define sync_cmpxchg(ptr, old, new)					\</span>
<span class="cp">	__sync_cmpxchg(ptr, old, new, sizeof(*(ptr)))</span>

<span class="cp">#define cmpxchg_local(ptr, old, new)					\</span>
<span class="cp">	__cmpxchg_local(ptr, old, new, sizeof(*(ptr)))</span>
<span class="cp">#endif</span>

<span class="cm">/*</span>
<span class="cm"> * xadd() adds &quot;inc&quot; to &quot;*ptr&quot; and atomically returns the previous</span>
<span class="cm"> * value of &quot;*ptr&quot;.</span>
<span class="cm"> *</span>
<span class="cm"> * xadd() is locked when multiple CPUs are online</span>
<span class="cm"> * xadd_sync() is always locked</span>
<span class="cm"> * xadd_local() is never locked</span>
<span class="cm"> */</span>
<span class="cp">#define __xadd(ptr, inc, lock)	__xchg_op((ptr), (inc), xadd, lock)</span>
<span class="cp">#define xadd(ptr, inc)		__xadd((ptr), (inc), LOCK_PREFIX)</span>
<span class="cp">#define xadd_sync(ptr, inc)	__xadd((ptr), (inc), &quot;lock; &quot;)</span>
<span class="cp">#define xadd_local(ptr, inc)	__xadd((ptr), (inc), &quot;&quot;)</span>

<span class="cp">#define __add(ptr, inc, lock)						\</span>
<span class="cp">	({								\</span>
<span class="cp">	        __typeof__ (*(ptr)) __ret = (inc);			\</span>
<span class="cp">		switch (sizeof(*(ptr))) {				\</span>
<span class="cp">		case __X86_CASE_B:					\</span>
<span class="cp">			asm volatile (lock &quot;addb %b1, %0\n&quot;		\</span>
<span class="cp">				      : &quot;+m&quot; (*(ptr)) : &quot;qi&quot; (inc)	\</span>
<span class="cp">				      : &quot;memory&quot;, &quot;cc&quot;);		\</span>
<span class="cp">			break;						\</span>
<span class="cp">		case __X86_CASE_W:					\</span>
<span class="cp">			asm volatile (lock &quot;addw %w1, %0\n&quot;		\</span>
<span class="cp">				      : &quot;+m&quot; (*(ptr)) : &quot;ri&quot; (inc)	\</span>
<span class="cp">				      : &quot;memory&quot;, &quot;cc&quot;);		\</span>
<span class="cp">			break;						\</span>
<span class="cp">		case __X86_CASE_L:					\</span>
<span class="cp">			asm volatile (lock &quot;addl %1, %0\n&quot;		\</span>
<span class="cp">				      : &quot;+m&quot; (*(ptr)) : &quot;ri&quot; (inc)	\</span>
<span class="cp">				      : &quot;memory&quot;, &quot;cc&quot;);		\</span>
<span class="cp">			break;						\</span>
<span class="cp">		case __X86_CASE_Q:					\</span>
<span class="cp">			asm volatile (lock &quot;addq %1, %0\n&quot;		\</span>
<span class="cp">				      : &quot;+m&quot; (*(ptr)) : &quot;ri&quot; (inc)	\</span>
<span class="cp">				      : &quot;memory&quot;, &quot;cc&quot;);		\</span>
<span class="cp">			break;						\</span>
<span class="cp">		default:						\</span>
<span class="cp">			__add_wrong_size();				\</span>
<span class="cp">		}							\</span>
<span class="cp">		__ret;							\</span>
<span class="cp">	})</span>

<span class="cm">/*</span>
<span class="cm"> * add_*() adds &quot;inc&quot; to &quot;*ptr&quot;</span>
<span class="cm"> *</span>
<span class="cm"> * __add() takes a lock prefix</span>
<span class="cm"> * add_smp() is locked when multiple CPUs are online</span>
<span class="cm"> * add_sync() is always locked</span>
<span class="cm"> */</span>
<span class="cp">#define add_smp(ptr, inc)	__add((ptr), (inc), LOCK_PREFIX)</span>
<span class="cp">#define add_sync(ptr, inc)	__add((ptr), (inc), &quot;lock; &quot;)</span>

<span class="cp">#define __cmpxchg_double(pfx, p1, p2, o1, o2, n1, n2)			\</span>
<span class="cp">({									\</span>
<span class="cp">	bool __ret;							\</span>
<span class="cp">	__typeof__(*(p1)) __old1 = (o1), __new1 = (n1);			\</span>
<span class="cp">	__typeof__(*(p2)) __old2 = (o2), __new2 = (n2);			\</span>
<span class="cp">	BUILD_BUG_ON(sizeof(*(p1)) != sizeof(long));			\</span>
<span class="cp">	BUILD_BUG_ON(sizeof(*(p2)) != sizeof(long));			\</span>
<span class="cp">	VM_BUG_ON((unsigned long)(p1) % (2 * sizeof(long)));		\</span>
<span class="cp">	VM_BUG_ON((unsigned long)((p1) + 1) != (unsigned long)(p2));	\</span>
<span class="cp">	asm volatile(pfx &quot;cmpxchg%c4b %2; sete %0&quot;			\</span>
<span class="cp">		     : &quot;=a&quot; (__ret), &quot;+d&quot; (__old2),			\</span>
<span class="cp">		       &quot;+m&quot; (*(p1)), &quot;+m&quot; (*(p2))			\</span>
<span class="cp">		     : &quot;i&quot; (2 * sizeof(long)), &quot;a&quot; (__old1),		\</span>
<span class="cp">		       &quot;b&quot; (__new1), &quot;c&quot; (__new2));			\</span>
<span class="cp">	__ret;								\</span>
<span class="cp">})</span>

<span class="cp">#define cmpxchg_double(p1, p2, o1, o2, n1, n2) \</span>
<span class="cp">	__cmpxchg_double(LOCK_PREFIX, p1, p2, o1, o2, n1, n2)</span>

<span class="cp">#define cmpxchg_double_local(p1, p2, o1, o2, n1, n2) \</span>
<span class="cp">	__cmpxchg_double(, p1, p2, o1, o2, n1, n2)</span>

<span class="cp">#endif	</span><span class="cm">/* ASM_X86_CMPXCHG_H */</span><span class="cp"></span>

</pre></div></td></tr>

</tbody>
</table>
</div>

</body>
<script>docas={repo:"joekychen/linux",depth:4}</script>
<script>document.write('<script src=' + ('__proto__' in {} ? 'http://cdnjs.cloudflare.com/ajax/libs/zepto/1.0rc1/zepto.min.js' : 'https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js')+'><\\/script>')</script>
<script src="http://baoshan.github.com/moment/min/moment.min.js"></script>
<script src="../../../../javascript/docco.min.js"></script>
</html>
