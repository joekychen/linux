<!DOCTYPE html>
<html><head><title>joekychen/linux » arch › x86 › include › asm › barrier.h

</title>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta name="generator" content="Docco">
<link rel="stylesheet" media="all" href="../../../../stylesheets/docco.min.css" />


</head>
<body>
<div id="container">
<div id="background"></div>
<table cellpadding="0" cellspacing="0">
<thead><tr><th class="docs"><a id="home" href="../../../../index.html"></a><h1>barrier.h</h1></th><th class="code"></th></tr></thead>
<tbody>


<tr id="section-1"><td class="docs"><div class="pilwrap"><a class="pilcrow" href="#section-1">&#182;</a></div></td><td class="code"><div class="highlight"><pre><span class="cp">#ifndef _ASM_X86_BARRIER_H</span>
<span class="cp">#define _ASM_X86_BARRIER_H</span>

<span class="cp">#include &lt;asm/alternative.h&gt;</span>
<span class="cp">#include &lt;asm/nops.h&gt;</span>

<span class="cm">/*</span>
<span class="cm"> * Force strict CPU ordering.</span>
<span class="cm"> * And yes, this is required on UP too when we&#39;re talking</span>
<span class="cm"> * to devices.</span>
<span class="cm"> */</span>

<span class="cp">#ifdef CONFIG_X86_32</span>
<span class="cm">/*</span>
<span class="cm"> * Some non-Intel clones support out of order store. wmb() ceases to be a</span>
<span class="cm"> * nop for these.</span>
<span class="cm"> */</span>
<span class="cp">#define mb() alternative(&quot;lock; addl $0,0(%%esp)&quot;, &quot;mfence&quot;, X86_FEATURE_XMM2)</span>
<span class="cp">#define rmb() alternative(&quot;lock; addl $0,0(%%esp)&quot;, &quot;lfence&quot;, X86_FEATURE_XMM2)</span>
<span class="cp">#define wmb() alternative(&quot;lock; addl $0,0(%%esp)&quot;, &quot;sfence&quot;, X86_FEATURE_XMM)</span>
<span class="cp">#else</span>
<span class="cp">#define mb() 	asm volatile(&quot;mfence&quot;:::&quot;memory&quot;)</span>
<span class="cp">#define rmb()	asm volatile(&quot;lfence&quot;:::&quot;memory&quot;)</span>
<span class="cp">#define wmb()	asm volatile(&quot;sfence&quot; ::: &quot;memory&quot;)</span>
<span class="cp">#endif</span>

<span class="cm">/**</span>
<span class="cm"> * read_barrier_depends - Flush all pending reads that subsequents reads</span>
<span class="cm"> * depend on.</span>
<span class="cm"> *</span>
<span class="cm"> * No data-dependent reads from memory-like regions are ever reordered</span>
<span class="cm"> * over this barrier.  All reads preceding this primitive are guaranteed</span>
<span class="cm"> * to access memory (but not necessarily other CPUs&#39; caches) before any</span>
<span class="cm"> * reads following this primitive that depend on the data return by</span>
<span class="cm"> * any of the preceding reads.  This primitive is much lighter weight than</span>
<span class="cm"> * rmb() on most CPUs, and is never heavier weight than is</span>
<span class="cm"> * rmb().</span>
<span class="cm"> *</span>
<span class="cm"> * These ordering constraints are respected by both the local CPU</span>
<span class="cm"> * and the compiler.</span>
<span class="cm"> *</span>
<span class="cm"> * Ordering is not guaranteed by anything other than these primitives,</span>
<span class="cm"> * not even by data dependencies.  See the documentation for</span>
<span class="cm"> * memory_barrier() for examples and URLs to more information.</span>
<span class="cm"> *</span>
<span class="cm"> * For example, the following code would force ordering (the initial</span>
<span class="cm"> * value of &quot;a&quot; is zero, &quot;b&quot; is one, and &quot;p&quot; is &quot;&amp;a&quot;):</span>
<span class="cm"> *</span>
<span class="cm"> * &lt;programlisting&gt;</span>
<span class="cm"> *	CPU 0				CPU 1</span>
<span class="cm"> *</span>
<span class="cm"> *	b = 2;</span>
<span class="cm"> *	memory_barrier();</span>
<span class="cm"> *	p = &amp;b;				q = p;</span>
<span class="cm"> *					read_barrier_depends();</span>
<span class="cm"> *					d = *q;</span>
<span class="cm"> * &lt;/programlisting&gt;</span>
<span class="cm"> *</span>
<span class="cm"> * because the read of &quot;*q&quot; depends on the read of &quot;p&quot; and these</span>
<span class="cm"> * two reads are separated by a read_barrier_depends().  However,</span>
<span class="cm"> * the following code, with the same initial values for &quot;a&quot; and &quot;b&quot;:</span>
<span class="cm"> *</span>
<span class="cm"> * &lt;programlisting&gt;</span>
<span class="cm"> *	CPU 0				CPU 1</span>
<span class="cm"> *</span>
<span class="cm"> *	a = 2;</span>
<span class="cm"> *	memory_barrier();</span>
<span class="cm"> *	b = 3;				y = b;</span>
<span class="cm"> *					read_barrier_depends();</span>
<span class="cm"> *					x = a;</span>
<span class="cm"> * &lt;/programlisting&gt;</span>
<span class="cm"> *</span>
<span class="cm"> * does not enforce ordering, since there is no data dependency between</span>
<span class="cm"> * the read of &quot;a&quot; and the read of &quot;b&quot;.  Therefore, on some CPUs, such</span>
<span class="cm"> * as Alpha, &quot;y&quot; could be set to 3 and &quot;x&quot; to 0.  Use rmb()</span>
<span class="cm"> * in cases like this where there are no data dependencies.</span>
<span class="cm"> **/</span>

<span class="cp">#define read_barrier_depends()	do { } while (0)</span>

<span class="cp">#ifdef CONFIG_SMP</span>
<span class="cp">#define smp_mb()	mb()</span>
<span class="cp">#ifdef CONFIG_X86_PPRO_FENCE</span>
<span class="cp"># define smp_rmb()	rmb()</span>
<span class="cp">#else</span>
<span class="cp"># define smp_rmb()	barrier()</span>
<span class="cp">#endif</span>
<span class="cp">#ifdef CONFIG_X86_OOSTORE</span>
<span class="cp"># define smp_wmb() 	wmb()</span>
<span class="cp">#else</span>
<span class="cp"># define smp_wmb()	barrier()</span>
<span class="cp">#endif</span>
<span class="cp">#define smp_read_barrier_depends()	read_barrier_depends()</span>
<span class="cp">#define set_mb(var, value) do { (void)xchg(&amp;var, value); } while (0)</span>
<span class="cp">#else</span>
<span class="cp">#define smp_mb()	barrier()</span>
<span class="cp">#define smp_rmb()	barrier()</span>
<span class="cp">#define smp_wmb()	barrier()</span>
<span class="cp">#define smp_read_barrier_depends()	do { } while (0)</span>
<span class="cp">#define set_mb(var, value) do { var = value; barrier(); } while (0)</span>
<span class="cp">#endif</span>

<span class="cm">/*</span>
<span class="cm"> * Stop RDTSC speculation. This is needed when you need to use RDTSC</span>
<span class="cm"> * (or get_cycles or vread that possibly accesses the TSC) in a defined</span>
<span class="cm"> * code region.</span>
<span class="cm"> *</span>
<span class="cm"> * (Could use an alternative three way for this if there was one.)</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="n">__always_inline</span> <span class="kt">void</span> <span class="nf">rdtsc_barrier</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">alternative</span><span class="p">(</span><span class="n">ASM_NOP3</span><span class="p">,</span> <span class="s">&quot;mfence&quot;</span><span class="p">,</span> <span class="n">X86_FEATURE_MFENCE_RDTSC</span><span class="p">);</span>
	<span class="n">alternative</span><span class="p">(</span><span class="n">ASM_NOP3</span><span class="p">,</span> <span class="s">&quot;lfence&quot;</span><span class="p">,</span> <span class="n">X86_FEATURE_LFENCE_RDTSC</span><span class="p">);</span>
<span class="p">}</span>

<span class="cp">#endif </span><span class="cm">/* _ASM_X86_BARRIER_H */</span><span class="cp"></span>

</pre></div></td></tr>

</tbody>
</table>
</div>

</body>
<script>docas={repo:"joekychen/linux",depth:4}</script>
<script>document.write('<script src=' + ('__proto__' in {} ? 'http://cdnjs.cloudflare.com/ajax/libs/zepto/1.0rc1/zepto.min.js' : 'https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js')+'><\\/script>')</script>
<script src="http://baoshan.github.com/moment/min/moment.min.js"></script>
<script src="../../../../javascript/docco.min.js"></script>
</html>
