f | aes_glue.c | s | 1.7K | 60 | Linus Torvalds | torvalds@linux-foundation.org | 1320637487 |  | Merge branch 'modsplit-Oct31_2011' of git://git.kernel.org/pub/scm/linux/kernel/git/paulg/linux  * 'modsplit-Oct31_2011' of git://git.kernel.org/pub/scm/linux/kernel/git/paulg/linux: (230 commits)   Revert "tracing: Include module.h in define_trace.h"   irq: don't put module.h into irq.h for tracking irqgen modules.   bluetooth: macroize two small inlines to avoid module.h   ip_vs.h: fix implicit use of module_get/module_put from module.h   nf_conntrack.h: fix up fallout from implicit moduleparam.h presence   include: replace linux/module.h with "struct module" wherever possible   include: convert various register fcns to macros to avoid include chaining   crypto.h: remove unused crypto_tfm_alg_modname() inline   uwb.h: fix implicit use of asm/page.h for PAGE_SIZE   pm_runtime.h: explicitly requires notifier.h   linux/dmaengine.h: fix implicit use of bitmap.h and asm/page.h   miscdevice.h: fix up implicit use of lists and types   stop_machine.h: fix implicit use of smp.h for smp_processor_id   of: fix implicit use of errno.h in include/linux/of.h   of_platform.h: delete needless include <linux/module.h>   acpi: remove module.h include from platform/aclinux.h   miscdevice.h: delete unnecessary inclusion of module.h   device_cgroup.h: delete needless include <linux/module.h>   net: sch_generic remove redundant use of <linux/module.h>   net: inet_timewait_sock doesnt need <linux/module.h>   ...  Fix up trivial conflicts (other header files, and  removal of the ab3550 mfd driver) in  - drivers/media/dvb/frontends/dibx000_common.c  - drivers/media/video/{mt9m111.c,ov6650.c}  - drivers/mfd/ab3550-core.c  - include/linux/dmaengine.h
f | Makefile | g | 1.9K |  | Jussi Kivilinna | jussi.kivilinna@mbnet.fi | 1331717156 |  | crypto: camellia - add assembler implementation for x86_64  Patch adds x86_64 assembler implementation of Camellia block cipher. Two set of functions are provided. First set is regular 'one-block at time' encrypt/decrypt functions. Second is 'two-block at time' functions that gain performance increase on out-of-order CPUs. Performance of 2-way functions should be equal to 1-way functions with in-order CPUs.  Patch has been tested with tcrypt and automated filesystem tests.  Tcrypt benchmark results:  AMD Phenom II 1055T (fam:16, model:10):  camellia-asm vs camellia_generic: 128bit key:                                             (lrw:256bit)    (xts:256bit) size    ecb-enc ecb-dec cbc-enc cbc-dec ctr-enc ctr-dec lrw-enc lrw-dec xts-enc xts-dec 16B     1.27x   1.22x   1.30x   1.42x   1.30x   1.34x   1.19x   1.05x   1.23x   1.24x 64B     1.74x   1.79x   1.43x   1.87x   1.81x   1.87x   1.48x   1.38x   1.55x   1.62x 256B    1.90x   1.87x   1.43x   1.94x   1.94x   1.95x   1.63x   1.62x   1.67x   1.70x 1024B   1.96x   1.93x   1.43x   1.95x   1.98x   2.01x   1.67x   1.69x   1.74x   1.80x 8192B   1.96x   1.96x   1.39x   1.93x   2.01x   2.03x   1.72x   1.64x   1.71x   1.76x  256bit key:                                             (lrw:384bit)    (xts:512bit) size    ecb-enc ecb-dec cbc-enc cbc-dec ctr-enc ctr-dec lrw-enc lrw-dec xts-enc xts-dec 16B     1.23x   1.23x   1.33x   1.39x   1.34x   1.38x   1.04x   1.18x   1.21x   1.29x 64B     1.72x   1.69x   1.42x   1.78x   1.81x   1.89x   1.57x   1.52x   1.56x   1.65x 256B    1.85x   1.88x   1.42x   1.86x   1.93x   1.96x   1.69x   1.65x   1.70x   1.75x 1024B   1.88x   1.86x   1.45x   1.95x   1.96x   1.95x   1.77x   1.71x   1.77x   1.78x 8192B   1.91x   1.86x   1.42x   1.91x   2.03x   1.98x   1.73x   1.71x   1.78x   1.76x  camellia-asm vs aes-asm (8kB block):          128bit  256bit ecb-enc  1.15x   1.22x ecb-dec  1.16x   1.16x cbc-enc  0.85x   0.90x cbc-dec  1.20x   1.23x ctr-enc  1.28x   1.30x ctr-dec  1.27x   1.28x lrw-enc  1.12x   1.16x lrw-dec  1.08x   1.10x xts-enc  1.11x   1.15x xts-dec  1.14x   1.15x  Intel Core2 T8100 (fam:6, model:23, step:6):  camellia-asm vs camellia_generic: 128bit key:                                             (lrw:256bit)    (xts:256bit) size    ecb-enc ecb-dec cbc-enc cbc-dec ctr-enc ctr-dec lrw-enc lrw-dec xts-enc xts-dec 16B     1.10x   1.12x   1.14x   1.16x   1.16x   1.15x   1.02x   1.02x   1.08x   1.08x 64B     1.61x   1.60x   1.17x   1.68x   1.67x   1.66x   1.43x   1.42x   1.44x   1.42x 256B    1.65x   1.73x   1.17x   1.77x   1.81x   1.80x   1.54x   1.53x   1.58x   1.54x 1024B   1.76x   1.74x   1.18x   1.80x   1.85x   1.85x   1.60x   1.59x   1.65x   1.60x 8192B   1.77x   1.75x   1.19x   1.81x   1.85x   1.86x   1.63x   1.61x   1.66x   1.62x  256bit key:                                             (lrw:384bit)    (xts:512bit) size    ecb-enc ecb-dec cbc-enc cbc-dec ctr-enc ctr-dec lrw-enc lrw-dec xts-enc xts-dec 16B     1.10x   1.07x   1.13x   1.16x   1.11x   1.16x   1.03x   1.02x   1.08x   1.07x 64B     1.61x   1.62x   1.15x   1.66x   1.63x   1.68x   1.47x   1.46x   1.47x   1.44x 256B    1.71x   1.70x   1.16x   1.75x   1.69x   1.79x   1.58x   1.57x   1.59x   1.55x 1024B   1.78x   1.72x   1.17x   1.75x   1.80x   1.80x   1.63x   1.62x   1.65x   1.62x 8192B   1.76x   1.73x   1.17x   1.78x   1.80x   1.81x   1.64x   1.62x   1.68x   1.64x  camellia-asm vs aes-asm (8kB block):          128bit  256bit ecb-enc  1.17x   1.21x ecb-dec  1.17x   1.20x cbc-enc  0.80x   0.82x cbc-dec  1.22x   1.24x ctr-enc  1.25x   1.26x ctr-dec  1.25x   1.26x lrw-enc  1.14x   1.18x lrw-dec  1.13x   1.17x xts-enc  1.14x   1.18x xts-dec  1.14x   1.17x  Signed-off-by: Jussi Kivilinna <jussi.kivilinna@mbnet.fi> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | crc32c-intel.c | s | 5.0K | 171 | Andi Kleen | ak@linux.intel.com | 1327625290 |  | crypto: Add support for x86 cpuid auto loading for x86 crypto drivers  Add support for auto-loading of crypto drivers based on cpuid features. This enables auto-loading of the VIA and Intel specific drivers for AES, hashing and CRCs.  Requires the earlier infrastructure patch to add x86 modinfo. I kept it all in a single patch for now.  I dropped the printks when the driver cpuid doesn't match (imho drivers never should print anything in such a case)  One drawback is that udev doesn't know if the drivers are used or not, so they will be unconditionally loaded at boot up. That's better than not loading them at all, like it often happens.  Cc: Dave Jones <davej@redhat.com> Cc: Kay Sievers <kay.sievers@vrfy.org> Cc: Jen Axboe <axboe@kernel.dk> Cc: Herbert Xu <herbert@gondor.apana.org.au> Cc: Huang Ying <ying.huang@intel.com> Signed-off-by: Andi Kleen <ak@linux.intel.com> Signed-off-by: Thomas Renninger <trenn@suse.de> Acked-by: H. Peter Anvin <hpa@zytor.com> Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>
f | sha1_ssse3_asm.S | g | 11K |  | Mathias Krause | minipli@googlemail.com | 1312974029 |  | crypto: sha1 - SSSE3 based SHA1 implementation for x86-64  This is an assembler implementation of the SHA1 algorithm using the Supplemental SSE3 (SSSE3) instructions or, when available, the Advanced Vector Extensions (AVX).  Testing with the tcrypt module shows the raw hash performance is up to 2.3 times faster than the C implementation, using 8k data blocks on a Core 2 Duo T5500. For the smalest data set (16 byte) it is still 25% faster.  Since this implementation uses SSE/YMM registers it cannot safely be used in every situation, e.g. while an IRQ interrupts a kernel thread. The implementation falls back to the generic SHA1 variant, if using the SSE/YMM registers is not possible.  With this algorithm I was able to increase the throughput of a single IPsec link from 344 Mbit/s to 464 Mbit/s on a Core 2 Quad CPU using the SSSE3 variant -- a speedup of +34.8%.  Saving and restoring SSE/YMM state might make the actual throughput fluctuate when there are FPU intensive userland applications running. For example, meassuring the performance using iperf2 directly on the machine under test gives wobbling numbers because iperf2 uses the FPU for each packet to check if the reporting interval has expired (in the above test I got min/max/avg: 402/484/464 MBit/s).  Using this algorithm on a IPsec gateway gives much more reasonable and stable numbers, albeit not as high as in the directly connected case. Here is the result from an RFC 2544 test run with a EXFO Packet Blazer FTB-8510:   frame size    sha1-generic     sha1-ssse3    delta     64 byte     37.5 MBit/s    37.5 MBit/s     0.0%    128 byte     56.3 MBit/s    62.5 MBit/s   +11.0%    256 byte     87.5 MBit/s   100.0 MBit/s   +14.3%    512 byte    131.3 MBit/s   150.0 MBit/s   +14.2%   1024 byte    162.5 MBit/s   193.8 MBit/s   +19.3%   1280 byte    175.0 MBit/s   212.5 MBit/s   +21.4%   1420 byte    175.0 MBit/s   218.7 MBit/s   +25.0%   1518 byte    150.0 MBit/s   181.2 MBit/s   +20.8%  The throughput for the largest frame size is lower than for the previous size because the IP packets need to be fragmented in this case to make there way through the IPsec tunnel.  Signed-off-by: Mathias Krause <minipli@googlemail.com> Cc: Maxim Locktyukhin <maxim.locktyukhin@intel.com> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | blowfish_glue.c | s | 11K | 410 | Jussi Kivilinna | jussi.kivilinna@mbnet.fi | 1330161624 |  | crypto: blowfish-x86_64 - set alignmask to zero  x86 has fast unaligned accesses, so blowfish-x86_64 does not need to enforce alignment.  Signed-off-by: Jussi Kivilinna <jussi.kivilinna@mbnet.fi> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | aesni-intel_asm.S | g | 73K |  | Mathias Krause | minipli@googlemail.com | 1338461602 |  | crypto: aesni-intel - fix unaligned cbc decrypt for x86-32  The 32 bit variant of cbc(aes) decrypt is using instructions requiring 128 bit aligned memory locations but fails to ensure this constraint in the code. Fix this by loading the data into intermediate registers with load unaligned instructions.  This fixes reported general protection faults related to aesni.  References: https://bugzilla.kernel.org/show_bug.cgi?id=43223 Reported-by: Daniel <garkein@mailueberfall.de> Cc: stable@kernel.org [v2.6.39+] Signed-off-by: Mathias Krause <minipli@googlemail.com> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | twofish-x86_64-asm_64.S | g | 8.3K |  | Jussi Kivilinna | jussi.kivilinna@mbnet.fi | 1319199788 |  | crypto: twofish-x86-asm - make assembler functions use twofish_ctx instead of crypto_tfm  This needed by 3-way twofish patch to be able to easily use one block assembler functions. As glue code is shared between i586/x86_64 apply change to i586 assembler too. Also export assembler functions for 3-way parallel twofish module.  CC: Joachim Fritschi <jfritschi@freenet.de> Signed-off-by: Jussi Kivilinna <jussi.kivilinna@mbnet.fi> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | sha1_ssse3_glue.c | s | 5.8K | 192 | Mathias Krause | minipli@googlemail.com | 1312974029 |  | crypto: sha1 - SSSE3 based SHA1 implementation for x86-64  This is an assembler implementation of the SHA1 algorithm using the Supplemental SSE3 (SSSE3) instructions or, when available, the Advanced Vector Extensions (AVX).  Testing with the tcrypt module shows the raw hash performance is up to 2.3 times faster than the C implementation, using 8k data blocks on a Core 2 Duo T5500. For the smalest data set (16 byte) it is still 25% faster.  Since this implementation uses SSE/YMM registers it cannot safely be used in every situation, e.g. while an IRQ interrupts a kernel thread. The implementation falls back to the generic SHA1 variant, if using the SSE/YMM registers is not possible.  With this algorithm I was able to increase the throughput of a single IPsec link from 344 Mbit/s to 464 Mbit/s on a Core 2 Quad CPU using the SSSE3 variant -- a speedup of +34.8%.  Saving and restoring SSE/YMM state might make the actual throughput fluctuate when there are FPU intensive userland applications running. For example, meassuring the performance using iperf2 directly on the machine under test gives wobbling numbers because iperf2 uses the FPU for each packet to check if the reporting interval has expired (in the above test I got min/max/avg: 402/484/464 MBit/s).  Using this algorithm on a IPsec gateway gives much more reasonable and stable numbers, albeit not as high as in the directly connected case. Here is the result from an RFC 2544 test run with a EXFO Packet Blazer FTB-8510:   frame size    sha1-generic     sha1-ssse3    delta     64 byte     37.5 MBit/s    37.5 MBit/s     0.0%    128 byte     56.3 MBit/s    62.5 MBit/s   +11.0%    256 byte     87.5 MBit/s   100.0 MBit/s   +14.3%    512 byte    131.3 MBit/s   150.0 MBit/s   +14.2%   1024 byte    162.5 MBit/s   193.8 MBit/s   +19.3%   1280 byte    175.0 MBit/s   212.5 MBit/s   +21.4%   1420 byte    175.0 MBit/s   218.7 MBit/s   +25.0%   1518 byte    150.0 MBit/s   181.2 MBit/s   +20.8%  The throughput for the largest frame size is lower than for the previous size because the IP packets need to be fragmented in this case to make there way through the IPsec tunnel.  Signed-off-by: Mathias Krause <minipli@googlemail.com> Cc: Maxim Locktyukhin <maxim.locktyukhin@intel.com> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | serpent_sse2_glue.c | s | 24K | 808 | Jussi Kivilinna | jussi.kivilinna@mbnet.fi | 1330161623 |  | crypto: serpent-sse2 - combine ablk_*_init functions  Driver name in ablk_*_init functions can be constructed runtime. Therefore use single function ablk_init to reduce object size.  Signed-off-by: Jussi Kivilinna <jussi.kivilinna@mbnet.fi> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | twofish-i586-asm_32.S | g | 9.1K |  | Jussi Kivilinna | jussi.kivilinna@mbnet.fi | 1319199788 |  | crypto: twofish-x86-asm - make assembler functions use twofish_ctx instead of crypto_tfm  This needed by 3-way twofish patch to be able to easily use one block assembler functions. As glue code is shared between i586/x86_64 apply change to i586 assembler too. Also export assembler functions for 3-way parallel twofish module.  CC: Joachim Fritschi <jfritschi@freenet.de> Signed-off-by: Jussi Kivilinna <jussi.kivilinna@mbnet.fi> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | aes-i586-asm_32.S | g | 10K |  | Huang Ying | ying.huang@intel.com | 1234946885 |  | crypto: aes - Export x86 AES encrypt/decrypt functions  Intel AES-NI AES acceleration instructions touch XMM state, to use that in soft_irq context, general x86 AES implementation is used as fallback. The first parameter is changed from struct crypto_tfm * to struct crypto_aes_ctx * to make it easier to deal with 16 bytes alignment requirement of AES-NI implementation.  Signed-off-by: Huang Ying <ying.huang@intel.com> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | salsa20-x86_64-asm_64.S | g | 17K |  | Tan Swee Heng | thesweeheng@gmail.com | 1199999817 |  | [CRYPTO] salsa20: Add x86-64 assembly version  This is the x86-64 version of the Salsa20 stream cipher algorithm. The original assembly code came from <http://cr.yp.to/snuffle/salsa20/amd64-3/salsa20.s>. It has been reformatted for clarity.  Signed-off-by: Tan Swee Heng <thesweeheng@gmail.com> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | twofish_glue.c | s | 3.2K | 92 | Jussi Kivilinna | jussi.kivilinna@mbnet.fi | 1330161624 |  | crypto: twofish-x86_64/i586 - set alignmask to zero  x86 has fast unaligned accesses, so twofish-x86_64/i586 does not need to enforce alignment.  Signed-off-by: Jussi Kivilinna <jussi.kivilinna@mbnet.fi> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | serpent-sse2-x86_64-asm_64.S | g | 18K |  | Jussi Kivilinna | jussi.kivilinna@mbnet.fi | 1326433120 |  | crypto: serpent-sse2 - change transpose_4x4 to only use integer instructions  Matrix transpose macro in serpent-sse2 uses mix of SSE2 integer and SSE floating point instructions, which might cause performance penality on some CPUs.  This patch replaces transpose_4x4 macro with version that uses only SSE2 integer instructions.  Signed-off-by: Jussi Kivilinna <jussi.kivilinna@mbnet.fi> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | blowfish-x86_64-asm_64.S | g | 6.5K |  | Jussi Kivilinna | jussi.kivilinna@mbnet.fi | 1319199787 |  | crypto: blowfish-x86_64 - improve x86_64 blowfish 4-way performance  This patch adds improved F-macro for 4-way parallel functions. With new F-macro for 4-way parallel functions, blowfish sees ~15% improvement in speed tests on AMD Phenom II (~5% on Intel Xeon E7330).  However when used in 1-way blowfish function new macro would be ~10% slower than original, so old F-macro is kept for 1-way functions. Patch cleans up old F-macro as it is no longer needed in 4-way part.  Patch also does register macro renaming to reduce stack usage.  Signed-off-by: Jussi Kivilinna <jussi.kivilinna@mbnet.fi> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | salsa20_glue.c | s | 3.7K | 111 | Tan Swee Heng | thesweeheng@gmail.com | 1199999817 |  | [CRYPTO] salsa20: Add x86-64 assembly version  This is the x86-64 version of the Salsa20 stream cipher algorithm. The original assembly code came from <http://cr.yp.to/snuffle/salsa20/amd64-3/salsa20.s>. It has been reformatted for clarity.  Signed-off-by: Tan Swee Heng <thesweeheng@gmail.com> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | serpent-sse2-i586-asm_32.S | g | 14K |  | Jussi Kivilinna | jussi.kivilinna@mbnet.fi | 1326433120 |  | crypto: serpent-sse2 - change transpose_4x4 to only use integer instructions  Matrix transpose macro in serpent-sse2 uses mix of SSE2 integer and SSE floating point instructions, which might cause performance penality on some CPUs.  This patch replaces transpose_4x4 macro with version that uses only SSE2 integer instructions.  Signed-off-by: Jussi Kivilinna <jussi.kivilinna@mbnet.fi> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | twofish_glue_3way.c | s | 17K | 586 | Jussi Kivilinna | jussi.kivilinna@mbnet.fi | 1332379065 |  | crypto: twofish-x86_64-3way - module init/exit functions should be static  This caused conflict with camellia-x86_64 when compiled into kernel, same function names and not static.  Reported-by: Randy Dunlap <rdunlap@xenotime.net> Signed-off-by: Jussi Kivilinna <jussi.kivilinna@mbnet.fi> Acked-by: Randy Dunlap <rdunlap@xenotime.net> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | camellia_glue.c | s | 70K | 1762 | Jussi Kivilinna | jussi.kivilinna@mbnet.fi | 1332379064 |  | crypto: camellia-x86_64 - module init/exit functions should be static  This caused conflict with twofish-x86_64-3way when compiled into kernel, same function names and not static.  Reported-by: Randy Dunlap <rdunlap@xenotime.net> Signed-off-by: Jussi Kivilinna <jussi.kivilinna@mbnet.fi> Acked-by: Randy Dunlap <rdunlap@xenotime.net> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | salsa20-i586-asm_32.S | g | 20K |  | Tan Swee Heng | thesweeheng@gmail.com | 1199999817 |  | [CRYPTO] salsa20_i586: Salsa20 stream cipher algorithm (i586 version)  This patch contains the salsa20-i586 implementation. The original assembly code came from <http://cr.yp.to/snuffle/salsa20/x86-pm/salsa20.s>. I have reformatted it (added indents) so that it matches the other algorithms in arch/x86/crypto.  Signed-off-by: Tan Swee Heng <thesweeheng@gmail.com> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | aesni-intel_glue.c | s | 34K | 1106 | Jussi Kivilinna | jussi.kivilinna@mbnet.fi | 1337066733 |  | crypto: aesni-intel - move more common code to ablk_init_common  ablk_*_init functions share more common code than what is currently in ablk_init_common. Move all of the common code to ablk_init_common.  Cc: Huang Ying <ying.huang@intel.com> Signed-off-by: Jussi Kivilinna <jussi.kivilinna@mbnet.fi> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | ghash-clmulni-intel_glue.c | s | 8.4K | 276 | Andi Kleen | ak@linux.intel.com | 1327625290 |  | crypto: Add support for x86 cpuid auto loading for x86 crypto drivers  Add support for auto-loading of crypto drivers based on cpuid features. This enables auto-loading of the VIA and Intel specific drivers for AES, hashing and CRCs.  Requires the earlier infrastructure patch to add x86 modinfo. I kept it all in a single patch for now.  I dropped the printks when the driver cpuid doesn't match (imho drivers never should print anything in such a case)  One drawback is that udev doesn't know if the drivers are used or not, so they will be unconditionally loaded at boot up. That's better than not loading them at all, like it often happens.  Cc: Dave Jones <davej@redhat.com> Cc: Kay Sievers <kay.sievers@vrfy.org> Cc: Jen Axboe <axboe@kernel.dk> Cc: Herbert Xu <herbert@gondor.apana.org.au> Cc: Huang Ying <ying.huang@intel.com> Signed-off-by: Andi Kleen <ak@linux.intel.com> Signed-off-by: Thomas Renninger <trenn@suse.de> Acked-by: H. Peter Anvin <hpa@zytor.com> Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>
f | ghash-clmulni-intel_asm.S | g | 3.2K |  | Jiri Kosina | jkosina@suse.cz | 1258978787 |  | crypto: ghash-clmulni-intel - Put proper .data section in place  Lbswap_mask, Lpoly and Ltwo_one should clearly belong to .data section, not .text.  Signed-off-by: Jiri Kosina <jkosina@suse.cz> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | twofish-x86_64-asm_64-3way.S | g | 6.9K |  | Jussi Kivilinna | jussi.kivilinna@mbnet.fi | 1319199788 |  | crypto: twofish - add 3-way parallel x86_64 assembler implemention  Patch adds 3-way parallel x86_64 assembly implementation of twofish as new module. New assembler functions crypt data in three blocks chunks, improving cipher performance on out-of-order CPUs.  Patch has been tested with tcrypt and automated filesystem tests.  Summary of the tcrypt benchmarks:  Twofish 3-way-asm vs twofish asm (128bit 8kb block ECB)  encrypt: 1.3x speed  decrypt: 1.3x speed  Twofish 3-way-asm vs twofish asm (128bit 8kb block CBC)  encrypt: 1.07x speed  decrypt: 1.4x speed  Twofish 3-way-asm vs twofish asm (128bit 8kb block CTR)  encrypt: 1.4x speed  Twofish 3-way-asm vs AES asm (128bit 8kb block ECB)  encrypt: 1.0x speed  decrypt: 1.0x speed  Twofish 3-way-asm vs AES asm (128bit 8kb block CBC)  encrypt: 0.84x speed  decrypt: 1.09x speed  Twofish 3-way-asm vs AES asm (128bit 8kb block CTR)  encrypt: 1.15x speed  Full output:  http://koti.mbnet.fi/axh/kernel/crypto/tcrypt-speed-twofish-3way-asm-x86_64.txt  http://koti.mbnet.fi/axh/kernel/crypto/tcrypt-speed-twofish-asm-x86_64.txt  http://koti.mbnet.fi/axh/kernel/crypto/tcrypt-speed-aes-asm-x86_64.txt  Tests were run on:  vendor_id  : AuthenticAMD  cpu family : 16  model      : 10  model name : AMD Phenom(tm) II X6 1055T Processor  Also userspace test were run on:  vendor_id  : GenuineIntel  cpu family : 6  model      : 15  model name : Intel(R) Xeon(R) CPU           E7330  @ 2.40GHz  stepping   : 11  Userspace test results:  Encryption/decryption of twofish 3-way vs x86_64-asm on AMD Phenom II:  encrypt: 1.27x  decrypt: 1.25x  Encryption/decryption of twofish 3-way vs x86_64-asm on Intel Xeon E7330:  encrypt: 1.36x  decrypt: 1.36x  Signed-off-by: Jussi Kivilinna <jussi.kivilinna@mbnet.fi> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | fpu.c | s | 4.3K | 139 | Andy Lutomirski | luto@mit.edu | 1305522767 |  | crypto: aesni-intel - Merge with fpu.ko  Loading fpu without aesni-intel does nothing.  Loading aesni-intel without fpu causes modes like xts to fail.  (Unloading aesni-intel will restore those modes.)  One solution would be to make aesni-intel depend on fpu, but it seems cleaner to just combine the modules.  This is probably responsible for bugs like: https://bugzilla.redhat.com/show_bug.cgi?id=589390  Signed-off-by: Andy Lutomirski <luto@mit.edu> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | aes-x86_64-asm_64.S | g | 4.7K |  | Huang Ying | ying.huang@intel.com | 1234946885 |  | crypto: aes - Export x86 AES encrypt/decrypt functions  Intel AES-NI AES acceleration instructions touch XMM state, to use that in soft_irq context, general x86 AES implementation is used as fallback. The first parameter is changed from struct crypto_tfm * to struct crypto_aes_ctx * to make it easier to deal with 16 bytes alignment requirement of AES-NI implementation.  Signed-off-by: Huang Ying <ying.huang@intel.com> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
f | camellia-x86_64-asm_64.S | g | 10K |  | Jussi Kivilinna | jussi.kivilinna@mbnet.fi | 1331717156 |  | crypto: camellia - add assembler implementation for x86_64  Patch adds x86_64 assembler implementation of Camellia block cipher. Two set of functions are provided. First set is regular 'one-block at time' encrypt/decrypt functions. Second is 'two-block at time' functions that gain performance increase on out-of-order CPUs. Performance of 2-way functions should be equal to 1-way functions with in-order CPUs.  Patch has been tested with tcrypt and automated filesystem tests.  Tcrypt benchmark results:  AMD Phenom II 1055T (fam:16, model:10):  camellia-asm vs camellia_generic: 128bit key:                                             (lrw:256bit)    (xts:256bit) size    ecb-enc ecb-dec cbc-enc cbc-dec ctr-enc ctr-dec lrw-enc lrw-dec xts-enc xts-dec 16B     1.27x   1.22x   1.30x   1.42x   1.30x   1.34x   1.19x   1.05x   1.23x   1.24x 64B     1.74x   1.79x   1.43x   1.87x   1.81x   1.87x   1.48x   1.38x   1.55x   1.62x 256B    1.90x   1.87x   1.43x   1.94x   1.94x   1.95x   1.63x   1.62x   1.67x   1.70x 1024B   1.96x   1.93x   1.43x   1.95x   1.98x   2.01x   1.67x   1.69x   1.74x   1.80x 8192B   1.96x   1.96x   1.39x   1.93x   2.01x   2.03x   1.72x   1.64x   1.71x   1.76x  256bit key:                                             (lrw:384bit)    (xts:512bit) size    ecb-enc ecb-dec cbc-enc cbc-dec ctr-enc ctr-dec lrw-enc lrw-dec xts-enc xts-dec 16B     1.23x   1.23x   1.33x   1.39x   1.34x   1.38x   1.04x   1.18x   1.21x   1.29x 64B     1.72x   1.69x   1.42x   1.78x   1.81x   1.89x   1.57x   1.52x   1.56x   1.65x 256B    1.85x   1.88x   1.42x   1.86x   1.93x   1.96x   1.69x   1.65x   1.70x   1.75x 1024B   1.88x   1.86x   1.45x   1.95x   1.96x   1.95x   1.77x   1.71x   1.77x   1.78x 8192B   1.91x   1.86x   1.42x   1.91x   2.03x   1.98x   1.73x   1.71x   1.78x   1.76x  camellia-asm vs aes-asm (8kB block):          128bit  256bit ecb-enc  1.15x   1.22x ecb-dec  1.16x   1.16x cbc-enc  0.85x   0.90x cbc-dec  1.20x   1.23x ctr-enc  1.28x   1.30x ctr-dec  1.27x   1.28x lrw-enc  1.12x   1.16x lrw-dec  1.08x   1.10x xts-enc  1.11x   1.15x xts-dec  1.14x   1.15x  Intel Core2 T8100 (fam:6, model:23, step:6):  camellia-asm vs camellia_generic: 128bit key:                                             (lrw:256bit)    (xts:256bit) size    ecb-enc ecb-dec cbc-enc cbc-dec ctr-enc ctr-dec lrw-enc lrw-dec xts-enc xts-dec 16B     1.10x   1.12x   1.14x   1.16x   1.16x   1.15x   1.02x   1.02x   1.08x   1.08x 64B     1.61x   1.60x   1.17x   1.68x   1.67x   1.66x   1.43x   1.42x   1.44x   1.42x 256B    1.65x   1.73x   1.17x   1.77x   1.81x   1.80x   1.54x   1.53x   1.58x   1.54x 1024B   1.76x   1.74x   1.18x   1.80x   1.85x   1.85x   1.60x   1.59x   1.65x   1.60x 8192B   1.77x   1.75x   1.19x   1.81x   1.85x   1.86x   1.63x   1.61x   1.66x   1.62x  256bit key:                                             (lrw:384bit)    (xts:512bit) size    ecb-enc ecb-dec cbc-enc cbc-dec ctr-enc ctr-dec lrw-enc lrw-dec xts-enc xts-dec 16B     1.10x   1.07x   1.13x   1.16x   1.11x   1.16x   1.03x   1.02x   1.08x   1.07x 64B     1.61x   1.62x   1.15x   1.66x   1.63x   1.68x   1.47x   1.46x   1.47x   1.44x 256B    1.71x   1.70x   1.16x   1.75x   1.69x   1.79x   1.58x   1.57x   1.59x   1.55x 1024B   1.78x   1.72x   1.17x   1.75x   1.80x   1.80x   1.63x   1.62x   1.65x   1.62x 8192B   1.76x   1.73x   1.17x   1.78x   1.80x   1.81x   1.64x   1.62x   1.68x   1.64x  camellia-asm vs aes-asm (8kB block):          128bit  256bit ecb-enc  1.17x   1.21x ecb-dec  1.17x   1.20x cbc-enc  0.80x   0.82x cbc-dec  1.22x   1.24x ctr-enc  1.25x   1.26x ctr-dec  1.25x   1.26x lrw-enc  1.14x   1.18x lrw-dec  1.13x   1.17x xts-enc  1.14x   1.18x xts-dec  1.14x   1.17x  Signed-off-by: Jussi Kivilinna <jussi.kivilinna@mbnet.fi> Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
