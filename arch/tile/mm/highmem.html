<!DOCTYPE html>
<html><head><title>joekychen/linux » arch › tile › mm › highmem.c

</title>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta name="generator" content="Docco">
<link rel="stylesheet" media="all" href="../../../stylesheets/docco.min.css" />


</head>
<body>
<div id="container">
<div id="background"></div>
<table cellpadding="0" cellspacing="0">
<thead><tr><th class="docs"><a id="home" href="../../../index.html"></a><h1>highmem.c</h1></th><th class="code"></th></tr></thead>
<tbody>


<tr id="section-1"><td class="docs"><div class="pilwrap"><a class="pilcrow" href="#section-1">&#182;</a></div></td><td class="code"><div class="highlight"><pre><span class="cm">/*</span>
<span class="cm"> * Copyright 2010 Tilera Corporation. All Rights Reserved.</span>
<span class="cm"> *</span>
<span class="cm"> *   This program is free software; you can redistribute it and/or</span>
<span class="cm"> *   modify it under the terms of the GNU General Public License</span>
<span class="cm"> *   as published by the Free Software Foundation, version 2.</span>
<span class="cm"> *</span>
<span class="cm"> *   This program is distributed in the hope that it will be useful, but</span>
<span class="cm"> *   WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="cm"> *   MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or</span>
<span class="cm"> *   NON INFRINGEMENT.  See the GNU General Public License for</span>
<span class="cm"> *   more details.</span>
<span class="cm"> */</span>

<span class="cp">#include &lt;linux/highmem.h&gt;</span>
<span class="cp">#include &lt;linux/module.h&gt;</span>
<span class="cp">#include &lt;linux/pagemap.h&gt;</span>
<span class="cp">#include &lt;asm/homecache.h&gt;</span>

<span class="cp">#define kmap_get_pte(vaddr) \</span>
<span class="cp">	pte_offset_kernel(pmd_offset(pud_offset(pgd_offset_k(vaddr), (vaddr)),\</span>
<span class="cp">		(vaddr)), (vaddr))</span>


<span class="kt">void</span> <span class="o">*</span><span class="nf">kmap</span><span class="p">(</span><span class="k">struct</span> <span class="n">page</span> <span class="o">*</span><span class="n">page</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">void</span> <span class="o">*</span><span class="n">kva</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">;</span>
	<span class="n">pte_t</span> <span class="o">*</span><span class="n">ptep</span><span class="p">;</span>

	<span class="n">might_sleep</span><span class="p">();</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">PageHighMem</span><span class="p">(</span><span class="n">page</span><span class="p">))</span>
		<span class="k">return</span> <span class="n">page_address</span><span class="p">(</span><span class="n">page</span><span class="p">);</span>
	<span class="n">kva</span> <span class="o">=</span> <span class="n">kmap_high</span><span class="p">(</span><span class="n">page</span><span class="p">);</span>

	<span class="cm">/*</span>
<span class="cm">	 * Rewrite the PTE under the lock.  This ensures that the page</span>
<span class="cm">	 * is not currently migrating.</span>
<span class="cm">	 */</span>
	<span class="n">ptep</span> <span class="o">=</span> <span class="n">kmap_get_pte</span><span class="p">((</span><span class="kt">unsigned</span> <span class="kt">long</span><span class="p">)</span><span class="n">kva</span><span class="p">);</span>
	<span class="n">flags</span> <span class="o">=</span> <span class="n">homecache_kpte_lock</span><span class="p">();</span>
	<span class="n">set_pte_at</span><span class="p">(</span><span class="o">&amp;</span><span class="n">init_mm</span><span class="p">,</span> <span class="n">kva</span><span class="p">,</span> <span class="n">ptep</span><span class="p">,</span> <span class="n">mk_pte</span><span class="p">(</span><span class="n">page</span><span class="p">,</span> <span class="n">page_to_kpgprot</span><span class="p">(</span><span class="n">page</span><span class="p">)));</span>
	<span class="n">homecache_kpte_unlock</span><span class="p">(</span><span class="n">flags</span><span class="p">);</span>

	<span class="k">return</span> <span class="n">kva</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">EXPORT_SYMBOL</span><span class="p">(</span><span class="n">kmap</span><span class="p">);</span>

<span class="kt">void</span> <span class="nf">kunmap</span><span class="p">(</span><span class="k">struct</span> <span class="n">page</span> <span class="o">*</span><span class="n">page</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">in_interrupt</span><span class="p">())</span>
		<span class="n">BUG</span><span class="p">();</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">PageHighMem</span><span class="p">(</span><span class="n">page</span><span class="p">))</span>
		<span class="k">return</span><span class="p">;</span>
	<span class="n">kunmap_high</span><span class="p">(</span><span class="n">page</span><span class="p">);</span>
<span class="p">}</span>
<span class="n">EXPORT_SYMBOL</span><span class="p">(</span><span class="n">kunmap</span><span class="p">);</span>

<span class="cm">/*</span>
<span class="cm"> * Describe a single atomic mapping of a page on a given cpu at a</span>
<span class="cm"> * given address, and allow it to be linked into a list.</span>
<span class="cm"> */</span>
<span class="k">struct</span> <span class="n">atomic_mapped_page</span> <span class="p">{</span>
	<span class="k">struct</span> <span class="n">list_head</span> <span class="n">list</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">page</span> <span class="o">*</span><span class="n">page</span><span class="p">;</span>
	<span class="kt">int</span> <span class="n">cpu</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">va</span><span class="p">;</span>
<span class="p">};</span>

<span class="k">static</span> <span class="n">spinlock_t</span> <span class="n">amp_lock</span> <span class="o">=</span> <span class="n">__SPIN_LOCK_UNLOCKED</span><span class="p">(</span><span class="o">&amp;</span><span class="n">amp_lock</span><span class="p">);</span>
<span class="k">static</span> <span class="k">struct</span> <span class="n">list_head</span> <span class="n">amp_list</span> <span class="o">=</span> <span class="n">LIST_HEAD_INIT</span><span class="p">(</span><span class="n">amp_list</span><span class="p">);</span>

<span class="cm">/*</span>
<span class="cm"> * Combining this structure with a per-cpu declaration lets us give</span>
<span class="cm"> * each cpu an atomic_mapped_page structure per type.</span>
<span class="cm"> */</span>
<span class="k">struct</span> <span class="n">kmap_amps</span> <span class="p">{</span>
	<span class="k">struct</span> <span class="n">atomic_mapped_page</span> <span class="n">per_type</span><span class="p">[</span><span class="n">KM_TYPE_NR</span><span class="p">];</span>
<span class="p">};</span>
<span class="k">static</span> <span class="n">DEFINE_PER_CPU</span><span class="p">(</span><span class="k">struct</span> <span class="n">kmap_amps</span><span class="p">,</span> <span class="n">amps</span><span class="p">);</span>

<span class="cm">/*</span>
<span class="cm"> * Add a page and va, on this cpu, to the list of kmap_atomic pages,</span>
<span class="cm"> * and write the new pte to memory.  Writing the new PTE under the</span>
<span class="cm"> * lock guarantees that it is either on the list before migration starts</span>
<span class="cm"> * (if we won the race), or set_pte() sets the migrating bit in the PTE</span>
<span class="cm"> * (if we lost the race).  And doing it under the lock guarantees</span>
<span class="cm"> * that when kmap_atomic_fix_one_pte() comes along, it finds a valid</span>
<span class="cm"> * PTE in memory, iff the mapping is still on the amp_list.</span>
<span class="cm"> *</span>
<span class="cm"> * Finally, doing it under the lock lets us safely examine the page</span>
<span class="cm"> * to see if it is immutable or not, for the generic kmap_atomic() case.</span>
<span class="cm"> * If we examine it earlier we are exposed to a race where it looks</span>
<span class="cm"> * writable earlier, but becomes immutable before we write the PTE.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kt">void</span> <span class="nf">kmap_atomic_register</span><span class="p">(</span><span class="k">struct</span> <span class="n">page</span> <span class="o">*</span><span class="n">page</span><span class="p">,</span> <span class="k">enum</span> <span class="n">km_type</span> <span class="n">type</span><span class="p">,</span>
				 <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">va</span><span class="p">,</span> <span class="n">pte_t</span> <span class="o">*</span><span class="n">ptep</span><span class="p">,</span> <span class="n">pte_t</span> <span class="n">pteval</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">atomic_mapped_page</span> <span class="o">*</span><span class="n">amp</span><span class="p">;</span>

	<span class="n">flags</span> <span class="o">=</span> <span class="n">homecache_kpte_lock</span><span class="p">();</span>
	<span class="n">spin_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">amp_lock</span><span class="p">);</span>

	<span class="cm">/* With interrupts disabled, now fill in the per-cpu info. */</span>
	<span class="n">amp</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">__get_cpu_var</span><span class="p">(</span><span class="n">amps</span><span class="p">).</span><span class="n">per_type</span><span class="p">[</span><span class="n">type</span><span class="p">];</span>
	<span class="n">amp</span><span class="o">-&gt;</span><span class="n">page</span> <span class="o">=</span> <span class="n">page</span><span class="p">;</span>
	<span class="n">amp</span><span class="o">-&gt;</span><span class="n">cpu</span> <span class="o">=</span> <span class="n">smp_processor_id</span><span class="p">();</span>
	<span class="n">amp</span><span class="o">-&gt;</span><span class="n">va</span> <span class="o">=</span> <span class="n">va</span><span class="p">;</span>

	<span class="cm">/* For generic kmap_atomic(), choose the PTE writability now. */</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">pte_read</span><span class="p">(</span><span class="n">pteval</span><span class="p">))</span>
		<span class="n">pteval</span> <span class="o">=</span> <span class="n">mk_pte</span><span class="p">(</span><span class="n">page</span><span class="p">,</span> <span class="n">page_to_kpgprot</span><span class="p">(</span><span class="n">page</span><span class="p">));</span>

	<span class="n">list_add</span><span class="p">(</span><span class="o">&amp;</span><span class="n">amp</span><span class="o">-&gt;</span><span class="n">list</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">amp_list</span><span class="p">);</span>
	<span class="n">set_pte</span><span class="p">(</span><span class="n">ptep</span><span class="p">,</span> <span class="n">pteval</span><span class="p">);</span>
	<span class="n">arch_flush_lazy_mmu_mode</span><span class="p">();</span>

	<span class="n">spin_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">amp_lock</span><span class="p">);</span>
	<span class="n">homecache_kpte_unlock</span><span class="p">(</span><span class="n">flags</span><span class="p">);</span>
<span class="p">}</span>

<span class="cm">/*</span>
<span class="cm"> * Remove a page and va, on this cpu, from the list of kmap_atomic pages.</span>
<span class="cm"> * Linear-time search, but we count on the lists being short.</span>
<span class="cm"> * We don&#39;t need to adjust the PTE under the lock (as opposed to the</span>
<span class="cm"> * kmap_atomic_register() case), since we&#39;re just unconditionally</span>
<span class="cm"> * zeroing the PTE after it&#39;s off the list.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kt">void</span> <span class="nf">kmap_atomic_unregister</span><span class="p">(</span><span class="k">struct</span> <span class="n">page</span> <span class="o">*</span><span class="n">page</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">va</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">atomic_mapped_page</span> <span class="o">*</span><span class="n">amp</span><span class="p">;</span>
	<span class="kt">int</span> <span class="n">cpu</span> <span class="o">=</span> <span class="n">smp_processor_id</span><span class="p">();</span>
	<span class="n">spin_lock_irqsave</span><span class="p">(</span><span class="o">&amp;</span><span class="n">amp_lock</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>
	<span class="n">list_for_each_entry</span><span class="p">(</span><span class="n">amp</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">amp_list</span><span class="p">,</span> <span class="n">list</span><span class="p">)</span> <span class="p">{</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">amp</span><span class="o">-&gt;</span><span class="n">page</span> <span class="o">==</span> <span class="n">page</span> <span class="o">&amp;&amp;</span> <span class="n">amp</span><span class="o">-&gt;</span><span class="n">cpu</span> <span class="o">==</span> <span class="n">cpu</span> <span class="o">&amp;&amp;</span> <span class="n">amp</span><span class="o">-&gt;</span><span class="n">va</span> <span class="o">==</span> <span class="n">va</span><span class="p">)</span>
			<span class="k">break</span><span class="p">;</span>
	<span class="p">}</span>
	<span class="n">BUG_ON</span><span class="p">(</span><span class="o">&amp;</span><span class="n">amp</span><span class="o">-&gt;</span><span class="n">list</span> <span class="o">==</span> <span class="o">&amp;</span><span class="n">amp_list</span><span class="p">);</span>
	<span class="n">list_del</span><span class="p">(</span><span class="o">&amp;</span><span class="n">amp</span><span class="o">-&gt;</span><span class="n">list</span><span class="p">);</span>
	<span class="n">spin_unlock_irqrestore</span><span class="p">(</span><span class="o">&amp;</span><span class="n">amp_lock</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>
<span class="p">}</span>

<span class="cm">/* Helper routine for kmap_atomic_fix_kpte(), below. */</span>
<span class="k">static</span> <span class="kt">void</span> <span class="nf">kmap_atomic_fix_one_kpte</span><span class="p">(</span><span class="k">struct</span> <span class="n">atomic_mapped_page</span> <span class="o">*</span><span class="n">amp</span><span class="p">,</span>
				     <span class="kt">int</span> <span class="n">finished</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">pte_t</span> <span class="o">*</span><span class="n">ptep</span> <span class="o">=</span> <span class="n">kmap_get_pte</span><span class="p">(</span><span class="n">amp</span><span class="o">-&gt;</span><span class="n">va</span><span class="p">);</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">finished</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">set_pte</span><span class="p">(</span><span class="n">ptep</span><span class="p">,</span> <span class="n">pte_mkmigrate</span><span class="p">(</span><span class="o">*</span><span class="n">ptep</span><span class="p">));</span>
		<span class="n">flush_remote</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">,</span> <span class="n">amp</span><span class="o">-&gt;</span><span class="n">va</span><span class="p">,</span> <span class="n">PAGE_SIZE</span><span class="p">,</span> <span class="n">PAGE_SIZE</span><span class="p">,</span>
			     <span class="n">cpumask_of</span><span class="p">(</span><span class="n">amp</span><span class="o">-&gt;</span><span class="n">cpu</span><span class="p">),</span> <span class="nb">NULL</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
		<span class="cm">/*</span>
<span class="cm">		 * Rewrite a default kernel PTE for this page.</span>
<span class="cm">		 * We rely on the fact that set_pte() writes the</span>
<span class="cm">		 * present+migrating bits last.</span>
<span class="cm">		 */</span>
		<span class="n">pte_t</span> <span class="n">pte</span> <span class="o">=</span> <span class="n">mk_pte</span><span class="p">(</span><span class="n">amp</span><span class="o">-&gt;</span><span class="n">page</span><span class="p">,</span> <span class="n">page_to_kpgprot</span><span class="p">(</span><span class="n">amp</span><span class="o">-&gt;</span><span class="n">page</span><span class="p">));</span>
		<span class="n">set_pte</span><span class="p">(</span><span class="n">ptep</span><span class="p">,</span> <span class="n">pte</span><span class="p">);</span>
	<span class="p">}</span>
<span class="p">}</span>

<span class="cm">/*</span>
<span class="cm"> * This routine is a helper function for homecache_fix_kpte(); see</span>
<span class="cm"> * its comments for more information on the &quot;finished&quot; argument here.</span>
<span class="cm"> *</span>
<span class="cm"> * Note that we hold the lock while doing the remote flushes, which</span>
<span class="cm"> * will stall any unrelated cpus trying to do kmap_atomic operations.</span>
<span class="cm"> * We could just update the PTEs under the lock, and save away copies</span>
<span class="cm"> * of the structs (or just the va+cpu), then flush them after we</span>
<span class="cm"> * release the lock, but it seems easier just to do it all under the lock.</span>
<span class="cm"> */</span>
<span class="kt">void</span> <span class="nf">kmap_atomic_fix_kpte</span><span class="p">(</span><span class="k">struct</span> <span class="n">page</span> <span class="o">*</span><span class="n">page</span><span class="p">,</span> <span class="kt">int</span> <span class="n">finished</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">struct</span> <span class="n">atomic_mapped_page</span> <span class="o">*</span><span class="n">amp</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">;</span>
	<span class="n">spin_lock_irqsave</span><span class="p">(</span><span class="o">&amp;</span><span class="n">amp_lock</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>
	<span class="n">list_for_each_entry</span><span class="p">(</span><span class="n">amp</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">amp_list</span><span class="p">,</span> <span class="n">list</span><span class="p">)</span> <span class="p">{</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">amp</span><span class="o">-&gt;</span><span class="n">page</span> <span class="o">==</span> <span class="n">page</span><span class="p">)</span>
			<span class="n">kmap_atomic_fix_one_kpte</span><span class="p">(</span><span class="n">amp</span><span class="p">,</span> <span class="n">finished</span><span class="p">);</span>
	<span class="p">}</span>
	<span class="n">spin_unlock_irqrestore</span><span class="p">(</span><span class="o">&amp;</span><span class="n">amp_lock</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>
<span class="p">}</span>

<span class="cm">/*</span>
<span class="cm"> * kmap_atomic/kunmap_atomic is significantly faster than kmap/kunmap</span>
<span class="cm"> * because the kmap code must perform a global TLB invalidation when</span>
<span class="cm"> * the kmap pool wraps.</span>
<span class="cm"> *</span>
<span class="cm"> * Note that they may be slower than on x86 (etc.) because unlike on</span>
<span class="cm"> * those platforms, we do have to take a global lock to map and unmap</span>
<span class="cm"> * pages on Tile (see above).</span>
<span class="cm"> *</span>
<span class="cm"> * When holding an atomic kmap is is not legal to sleep, so atomic</span>
<span class="cm"> * kmaps are appropriate for short, tight code paths only.</span>
<span class="cm"> */</span>
<span class="kt">void</span> <span class="o">*</span><span class="nf">kmap_atomic_prot</span><span class="p">(</span><span class="k">struct</span> <span class="n">page</span> <span class="o">*</span><span class="n">page</span><span class="p">,</span> <span class="n">pgprot_t</span> <span class="n">prot</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">vaddr</span><span class="p">;</span>
	<span class="kt">int</span> <span class="n">idx</span><span class="p">,</span> <span class="n">type</span><span class="p">;</span>
	<span class="n">pte_t</span> <span class="o">*</span><span class="n">pte</span><span class="p">;</span>

	<span class="cm">/* even !CONFIG_PREEMPT needs this, for in_atomic in do_page_fault */</span>
	<span class="n">pagefault_disable</span><span class="p">();</span>

	<span class="cm">/* Avoid icache flushes by disallowing atomic executable mappings. */</span>
	<span class="n">BUG_ON</span><span class="p">(</span><span class="n">pte_exec</span><span class="p">(</span><span class="n">prot</span><span class="p">));</span>

	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">PageHighMem</span><span class="p">(</span><span class="n">page</span><span class="p">))</span>
		<span class="k">return</span> <span class="n">page_address</span><span class="p">(</span><span class="n">page</span><span class="p">);</span>

	<span class="n">type</span> <span class="o">=</span> <span class="n">kmap_atomic_idx_push</span><span class="p">();</span>
	<span class="n">idx</span> <span class="o">=</span> <span class="n">type</span> <span class="o">+</span> <span class="n">KM_TYPE_NR</span><span class="o">*</span><span class="n">smp_processor_id</span><span class="p">();</span>
	<span class="n">vaddr</span> <span class="o">=</span> <span class="n">__fix_to_virt</span><span class="p">(</span><span class="n">FIX_KMAP_BEGIN</span> <span class="o">+</span> <span class="n">idx</span><span class="p">);</span>
	<span class="n">pte</span> <span class="o">=</span> <span class="n">kmap_get_pte</span><span class="p">(</span><span class="n">vaddr</span><span class="p">);</span>
	<span class="n">BUG_ON</span><span class="p">(</span><span class="o">!</span><span class="n">pte_none</span><span class="p">(</span><span class="o">*</span><span class="n">pte</span><span class="p">));</span>

	<span class="cm">/* Register that this page is mapped atomically on this cpu. */</span>
	<span class="n">kmap_atomic_register</span><span class="p">(</span><span class="n">page</span><span class="p">,</span> <span class="n">type</span><span class="p">,</span> <span class="n">vaddr</span><span class="p">,</span> <span class="n">pte</span><span class="p">,</span> <span class="n">mk_pte</span><span class="p">(</span><span class="n">page</span><span class="p">,</span> <span class="n">prot</span><span class="p">));</span>

	<span class="k">return</span> <span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="p">)</span><span class="n">vaddr</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">EXPORT_SYMBOL</span><span class="p">(</span><span class="n">kmap_atomic_prot</span><span class="p">);</span>

<span class="kt">void</span> <span class="o">*</span><span class="nf">kmap_atomic</span><span class="p">(</span><span class="k">struct</span> <span class="n">page</span> <span class="o">*</span><span class="n">page</span><span class="p">)</span>
<span class="p">{</span>
	<span class="cm">/* PAGE_NONE is a magic value that tells us to check immutability. */</span>
	<span class="k">return</span> <span class="n">kmap_atomic_prot</span><span class="p">(</span><span class="n">page</span><span class="p">,</span> <span class="n">PAGE_NONE</span><span class="p">);</span>
<span class="p">}</span>
<span class="n">EXPORT_SYMBOL</span><span class="p">(</span><span class="n">kmap_atomic</span><span class="p">);</span>

<span class="kt">void</span> <span class="nf">__kunmap_atomic</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">kvaddr</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">vaddr</span> <span class="o">=</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span><span class="p">)</span> <span class="n">kvaddr</span> <span class="o">&amp;</span> <span class="n">PAGE_MASK</span><span class="p">;</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">vaddr</span> <span class="o">&gt;=</span> <span class="n">__fix_to_virt</span><span class="p">(</span><span class="n">FIX_KMAP_END</span><span class="p">)</span> <span class="o">&amp;&amp;</span>
	    <span class="n">vaddr</span> <span class="o">&lt;=</span> <span class="n">__fix_to_virt</span><span class="p">(</span><span class="n">FIX_KMAP_BEGIN</span><span class="p">))</span> <span class="p">{</span>
		<span class="n">pte_t</span> <span class="o">*</span><span class="n">pte</span> <span class="o">=</span> <span class="n">kmap_get_pte</span><span class="p">(</span><span class="n">vaddr</span><span class="p">);</span>
		<span class="n">pte_t</span> <span class="n">pteval</span> <span class="o">=</span> <span class="o">*</span><span class="n">pte</span><span class="p">;</span>
		<span class="kt">int</span> <span class="n">idx</span><span class="p">,</span> <span class="n">type</span><span class="p">;</span>

		<span class="n">type</span> <span class="o">=</span> <span class="n">kmap_atomic_idx</span><span class="p">();</span>
		<span class="n">idx</span> <span class="o">=</span> <span class="n">type</span> <span class="o">+</span> <span class="n">KM_TYPE_NR</span><span class="o">*</span><span class="n">smp_processor_id</span><span class="p">();</span>

		<span class="cm">/*</span>
<span class="cm">		 * Force other mappings to Oops if they try to access this pte</span>
<span class="cm">		 * without first remapping it.  Keeping stale mappings around</span>
<span class="cm">		 * is a bad idea.</span>
<span class="cm">		 */</span>
		<span class="n">BUG_ON</span><span class="p">(</span><span class="o">!</span><span class="n">pte_present</span><span class="p">(</span><span class="n">pteval</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">pte_migrating</span><span class="p">(</span><span class="n">pteval</span><span class="p">));</span>
		<span class="n">kmap_atomic_unregister</span><span class="p">(</span><span class="n">pte_page</span><span class="p">(</span><span class="n">pteval</span><span class="p">),</span> <span class="n">vaddr</span><span class="p">);</span>
		<span class="n">kpte_clear_flush</span><span class="p">(</span><span class="n">pte</span><span class="p">,</span> <span class="n">vaddr</span><span class="p">);</span>
		<span class="n">kmap_atomic_idx_pop</span><span class="p">();</span>
	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
		<span class="cm">/* Must be a lowmem page */</span>
		<span class="n">BUG_ON</span><span class="p">(</span><span class="n">vaddr</span> <span class="o">&lt;</span> <span class="n">PAGE_OFFSET</span><span class="p">);</span>
		<span class="n">BUG_ON</span><span class="p">(</span><span class="n">vaddr</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span><span class="p">)</span><span class="n">high_memory</span><span class="p">);</span>
	<span class="p">}</span>

	<span class="n">arch_flush_lazy_mmu_mode</span><span class="p">();</span>
	<span class="n">pagefault_enable</span><span class="p">();</span>
<span class="p">}</span>
<span class="n">EXPORT_SYMBOL</span><span class="p">(</span><span class="n">__kunmap_atomic</span><span class="p">);</span>

<span class="cm">/*</span>
<span class="cm"> * This API is supposed to allow us to map memory without a &quot;struct page&quot;.</span>
<span class="cm"> * Currently we don&#39;t support this, though this may change in the future.</span>
<span class="cm"> */</span>
<span class="kt">void</span> <span class="o">*</span><span class="nf">kmap_atomic_pfn</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">pfn</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="n">kmap_atomic</span><span class="p">(</span><span class="n">pfn_to_page</span><span class="p">(</span><span class="n">pfn</span><span class="p">));</span>
<span class="p">}</span>
<span class="kt">void</span> <span class="o">*</span><span class="nf">kmap_atomic_prot_pfn</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">pfn</span><span class="p">,</span> <span class="n">pgprot_t</span> <span class="n">prot</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="n">kmap_atomic_prot</span><span class="p">(</span><span class="n">pfn_to_page</span><span class="p">(</span><span class="n">pfn</span><span class="p">),</span> <span class="n">prot</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">struct</span> <span class="n">page</span> <span class="o">*</span><span class="nf">kmap_atomic_to_page</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">ptr</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">pte_t</span> <span class="o">*</span><span class="n">pte</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">vaddr</span> <span class="o">=</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span><span class="p">)</span><span class="n">ptr</span><span class="p">;</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">vaddr</span> <span class="o">&lt;</span> <span class="n">FIXADDR_START</span><span class="p">)</span>
		<span class="k">return</span> <span class="n">virt_to_page</span><span class="p">(</span><span class="n">ptr</span><span class="p">);</span>

	<span class="n">pte</span> <span class="o">=</span> <span class="n">kmap_get_pte</span><span class="p">(</span><span class="n">vaddr</span><span class="p">);</span>
	<span class="k">return</span> <span class="n">pte_page</span><span class="p">(</span><span class="o">*</span><span class="n">pte</span><span class="p">);</span>
<span class="p">}</span>

</pre></div></td></tr>

</tbody>
</table>
</div>

</body>
<script>docas={repo:"joekychen/linux",depth:3}</script>
<script>document.write('<script src=' + ('__proto__' in {} ? 'http://cdnjs.cloudflare.com/ajax/libs/zepto/1.0rc1/zepto.min.js' : 'https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js')+'><\\/script>')</script>
<script src="http://baoshan.github.com/moment/min/moment.min.js"></script>
<script src="../../../javascript/docco.min.js"></script>
</html>
