<!DOCTYPE html>
<html><head><title>joekychen/linux » arch › sh › mm › cache-sh5.c

</title>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta name="generator" content="Docco">
<link rel="stylesheet" media="all" href="../../../stylesheets/docco.min.css" />


</head>
<body>
<div id="container">
<div id="background"></div>
<table cellpadding="0" cellspacing="0">
<thead><tr><th class="docs"><a id="home" href="../../../index.html"></a><h1>cache-sh5.c</h1></th><th class="code"></th></tr></thead>
<tbody>


<tr id="section-1"><td class="docs"><div class="pilwrap"><a class="pilcrow" href="#section-1">&#182;</a></div></td><td class="code"><div class="highlight"><pre><span class="cm">/*</span>
<span class="cm"> * arch/sh/mm/cache-sh5.c</span>
<span class="cm"> *</span>
<span class="cm"> * Copyright (C) 2000, 2001  Paolo Alberelli</span>
<span class="cm"> * Copyright (C) 2002  Benedict Gaster</span>
<span class="cm"> * Copyright (C) 2003  Richard Curnow</span>
<span class="cm"> * Copyright (C) 2003 - 2008  Paul Mundt</span>
<span class="cm"> *</span>
<span class="cm"> * This file is subject to the terms and conditions of the GNU General Public</span>
<span class="cm"> * License.  See the file &quot;COPYING&quot; in the main directory of this archive</span>
<span class="cm"> * for more details.</span>
<span class="cm"> */</span>
<span class="cp">#include &lt;linux/init.h&gt;</span>
<span class="cp">#include &lt;linux/mman.h&gt;</span>
<span class="cp">#include &lt;linux/mm.h&gt;</span>
<span class="cp">#include &lt;asm/tlb.h&gt;</span>
<span class="cp">#include &lt;asm/processor.h&gt;</span>
<span class="cp">#include &lt;asm/cache.h&gt;</span>
<span class="cp">#include &lt;asm/pgalloc.h&gt;</span>
<span class="cp">#include &lt;asm/uaccess.h&gt;</span>
<span class="cp">#include &lt;asm/mmu_context.h&gt;</span>

<span class="k">extern</span> <span class="kt">void</span> <span class="n">__weak</span> <span class="n">sh4__flush_region_init</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span>

<span class="cm">/* Wired TLB entry for the D-cache */</span>
<span class="k">static</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="kt">long</span> <span class="n">dtlb_cache_slot</span><span class="p">;</span>

<span class="cm">/*</span>
<span class="cm"> * The following group of functions deal with mapping and unmapping a</span>
<span class="cm"> * temporary page into a DTLB slot that has been set aside for exclusive</span>
<span class="cm"> * use.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span>
<span class="nf">sh64_setup_dtlb_cache_slot</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">eaddr</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">asid</span><span class="p">,</span>
			   <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">paddr</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">local_irq_disable</span><span class="p">();</span>
	<span class="n">sh64_setup_tlb_slot</span><span class="p">(</span><span class="n">dtlb_cache_slot</span><span class="p">,</span> <span class="n">eaddr</span><span class="p">,</span> <span class="n">asid</span><span class="p">,</span> <span class="n">paddr</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">sh64_teardown_dtlb_cache_slot</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">sh64_teardown_tlb_slot</span><span class="p">(</span><span class="n">dtlb_cache_slot</span><span class="p">);</span>
	<span class="n">local_irq_enable</span><span class="p">();</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">sh64_icache_inv_all</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="kt">long</span> <span class="n">addr</span><span class="p">,</span> <span class="n">flag</span><span class="p">,</span> <span class="n">data</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">;</span>

	<span class="n">addr</span> <span class="o">=</span> <span class="n">ICCR0</span><span class="p">;</span>
	<span class="n">flag</span> <span class="o">=</span> <span class="n">ICCR0_ICI</span><span class="p">;</span>
	<span class="n">data</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

	<span class="cm">/* Make this a critical section for safety (probably not strictly necessary.) */</span>
	<span class="n">local_irq_save</span><span class="p">(</span><span class="n">flags</span><span class="p">);</span>

	<span class="cm">/* Without %1 it gets unexplicably wrong */</span>
	<span class="n">__asm__</span> <span class="n">__volatile__</span> <span class="p">(</span>
		<span class="s">&quot;getcfg	%3, 0, %0</span><span class="se">\n\t</span><span class="s">&quot;</span>
		<span class="s">&quot;or	%0, %2, %0</span><span class="se">\n\t</span><span class="s">&quot;</span>
		<span class="s">&quot;putcfg	%3, 0, %0</span><span class="se">\n\t</span><span class="s">&quot;</span>
		<span class="s">&quot;synci&quot;</span>
		<span class="o">:</span> <span class="s">&quot;=&amp;r&quot;</span> <span class="p">(</span><span class="n">data</span><span class="p">)</span>
		<span class="o">:</span> <span class="s">&quot;0&quot;</span> <span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="s">&quot;r&quot;</span> <span class="p">(</span><span class="n">flag</span><span class="p">),</span> <span class="s">&quot;r&quot;</span> <span class="p">(</span><span class="n">addr</span><span class="p">));</span>

	<span class="n">local_irq_restore</span><span class="p">(</span><span class="n">flags</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kt">void</span> <span class="nf">sh64_icache_inv_kernel_range</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">start</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">end</span><span class="p">)</span>
<span class="p">{</span>
	<span class="cm">/* Invalidate range of addresses [start,end] from the I-cache, where</span>
<span class="cm">	 * the addresses lie in the kernel superpage. */</span>

	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="kt">long</span> <span class="n">ullend</span><span class="p">,</span> <span class="n">addr</span><span class="p">,</span> <span class="n">aligned_start</span><span class="p">;</span>
	<span class="n">aligned_start</span> <span class="o">=</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span> <span class="kt">long</span><span class="p">)(</span><span class="kt">signed</span> <span class="kt">long</span> <span class="kt">long</span><span class="p">)(</span><span class="kt">signed</span> <span class="kt">long</span><span class="p">)</span> <span class="n">start</span><span class="p">;</span>
	<span class="n">addr</span> <span class="o">=</span> <span class="n">L1_CACHE_ALIGN</span><span class="p">(</span><span class="n">aligned_start</span><span class="p">);</span>
	<span class="n">ullend</span> <span class="o">=</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span> <span class="kt">long</span><span class="p">)</span> <span class="p">(</span><span class="kt">signed</span> <span class="kt">long</span> <span class="kt">long</span><span class="p">)</span> <span class="p">(</span><span class="kt">signed</span> <span class="kt">long</span><span class="p">)</span> <span class="n">end</span><span class="p">;</span>

	<span class="k">while</span> <span class="p">(</span><span class="n">addr</span> <span class="o">&lt;=</span> <span class="n">ullend</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">__asm__</span> <span class="n">__volatile__</span> <span class="p">(</span><span class="s">&quot;icbi %0, 0&quot;</span> <span class="o">:</span> <span class="o">:</span> <span class="s">&quot;r&quot;</span> <span class="p">(</span><span class="n">addr</span><span class="p">));</span>
		<span class="n">addr</span> <span class="o">+=</span> <span class="n">L1_CACHE_BYTES</span><span class="p">;</span>
	<span class="p">}</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kt">void</span> <span class="nf">sh64_icache_inv_user_page</span><span class="p">(</span><span class="k">struct</span> <span class="n">vm_area_struct</span> <span class="o">*</span><span class="n">vma</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">eaddr</span><span class="p">)</span>
<span class="p">{</span>
	<span class="cm">/* If we get called, we know that vma-&gt;vm_flags contains VM_EXEC.</span>
<span class="cm">	   Also, eaddr is page-aligned. */</span>
	<span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">cpu</span> <span class="o">=</span> <span class="n">smp_processor_id</span><span class="p">();</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="kt">long</span> <span class="n">addr</span><span class="p">,</span> <span class="n">end_addr</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">running_asid</span><span class="p">,</span> <span class="n">vma_asid</span><span class="p">;</span>
	<span class="n">addr</span> <span class="o">=</span> <span class="n">eaddr</span><span class="p">;</span>
	<span class="n">end_addr</span> <span class="o">=</span> <span class="n">addr</span> <span class="o">+</span> <span class="n">PAGE_SIZE</span><span class="p">;</span>

	<span class="cm">/* Check whether we can use the current ASID for the I-cache</span>
<span class="cm">	   invalidation.  For example, if we&#39;re called via</span>
<span class="cm">	   access_process_vm-&gt;flush_cache_page-&gt;here, (e.g. when reading from</span>
<span class="cm">	   /proc), &#39;running_asid&#39; will be that of the reader, not of the</span>
<span class="cm">	   victim.</span>

<span class="cm">	   Also, note the risk that we might get pre-empted between the ASID</span>
<span class="cm">	   compare and blocking IRQs, and before we regain control, the</span>
<span class="cm">	   pid-&gt;ASID mapping changes.  However, the whole cache will get</span>
<span class="cm">	   invalidated when the mapping is renewed, so the worst that can</span>
<span class="cm">	   happen is that the loop below ends up invalidating somebody else&#39;s</span>
<span class="cm">	   cache entries.</span>
<span class="cm">	*/</span>

	<span class="n">running_asid</span> <span class="o">=</span> <span class="n">get_asid</span><span class="p">();</span>
	<span class="n">vma_asid</span> <span class="o">=</span> <span class="n">cpu_asid</span><span class="p">(</span><span class="n">cpu</span><span class="p">,</span> <span class="n">vma</span><span class="o">-&gt;</span><span class="n">vm_mm</span><span class="p">);</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">running_asid</span> <span class="o">!=</span> <span class="n">vma_asid</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">local_irq_save</span><span class="p">(</span><span class="n">flags</span><span class="p">);</span>
		<span class="n">switch_and_save_asid</span><span class="p">(</span><span class="n">vma_asid</span><span class="p">);</span>
	<span class="p">}</span>
	<span class="k">while</span> <span class="p">(</span><span class="n">addr</span> <span class="o">&lt;</span> <span class="n">end_addr</span><span class="p">)</span> <span class="p">{</span>
		<span class="cm">/* Worth unrolling a little */</span>
		<span class="n">__asm__</span> <span class="n">__volatile__</span><span class="p">(</span><span class="s">&quot;icbi %0,  0&quot;</span> <span class="o">:</span> <span class="o">:</span> <span class="s">&quot;r&quot;</span> <span class="p">(</span><span class="n">addr</span><span class="p">));</span>
		<span class="n">__asm__</span> <span class="n">__volatile__</span><span class="p">(</span><span class="s">&quot;icbi %0, 32&quot;</span> <span class="o">:</span> <span class="o">:</span> <span class="s">&quot;r&quot;</span> <span class="p">(</span><span class="n">addr</span><span class="p">));</span>
		<span class="n">__asm__</span> <span class="n">__volatile__</span><span class="p">(</span><span class="s">&quot;icbi %0, 64&quot;</span> <span class="o">:</span> <span class="o">:</span> <span class="s">&quot;r&quot;</span> <span class="p">(</span><span class="n">addr</span><span class="p">));</span>
		<span class="n">__asm__</span> <span class="n">__volatile__</span><span class="p">(</span><span class="s">&quot;icbi %0, 96&quot;</span> <span class="o">:</span> <span class="o">:</span> <span class="s">&quot;r&quot;</span> <span class="p">(</span><span class="n">addr</span><span class="p">));</span>
		<span class="n">addr</span> <span class="o">+=</span> <span class="mi">128</span><span class="p">;</span>
	<span class="p">}</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">running_asid</span> <span class="o">!=</span> <span class="n">vma_asid</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">switch_and_save_asid</span><span class="p">(</span><span class="n">running_asid</span><span class="p">);</span>
		<span class="n">local_irq_restore</span><span class="p">(</span><span class="n">flags</span><span class="p">);</span>
	<span class="p">}</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kt">void</span> <span class="nf">sh64_icache_inv_user_page_range</span><span class="p">(</span><span class="k">struct</span> <span class="n">mm_struct</span> <span class="o">*</span><span class="n">mm</span><span class="p">,</span>
			  <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">start</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">end</span><span class="p">)</span>
<span class="p">{</span>
	<span class="cm">/* Used for invalidating big chunks of I-cache, i.e. assume the range</span>
<span class="cm">	   is whole pages.  If &#39;start&#39; or &#39;end&#39; is not page aligned, the code</span>
<span class="cm">	   is conservative and invalidates to the ends of the enclosing pages.</span>
<span class="cm">	   This is functionally OK, just a performance loss. */</span>

	<span class="cm">/* See the comments below in sh64_dcache_purge_user_range() regarding</span>
<span class="cm">	   the choice of algorithm.  However, for the I-cache option (2) isn&#39;t</span>
<span class="cm">	   available because there are no physical tags so aliases can&#39;t be</span>
<span class="cm">	   resolved.  The icbi instruction has to be used through the user</span>
<span class="cm">	   mapping.   Because icbi is cheaper than ocbp on a cache hit, it</span>
<span class="cm">	   would be cheaper to use the selective code for a large range than is</span>
<span class="cm">	   possible with the D-cache.  Just assume 64 for now as a working</span>
<span class="cm">	   figure.</span>
<span class="cm">	   */</span>
	<span class="kt">int</span> <span class="n">n_pages</span><span class="p">;</span>

	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">mm</span><span class="p">)</span>
		<span class="k">return</span><span class="p">;</span>

	<span class="n">n_pages</span> <span class="o">=</span> <span class="p">((</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">&gt;&gt;</span> <span class="n">PAGE_SHIFT</span><span class="p">);</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">n_pages</span> <span class="o">&gt;=</span> <span class="mi">64</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">sh64_icache_inv_all</span><span class="p">();</span>
	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">aligned_start</span><span class="p">;</span>
		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">eaddr</span><span class="p">;</span>
		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">after_last_page_start</span><span class="p">;</span>
		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">mm_asid</span><span class="p">,</span> <span class="n">current_asid</span><span class="p">;</span>
		<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

		<span class="n">mm_asid</span> <span class="o">=</span> <span class="n">cpu_asid</span><span class="p">(</span><span class="n">smp_processor_id</span><span class="p">(),</span> <span class="n">mm</span><span class="p">);</span>
		<span class="n">current_asid</span> <span class="o">=</span> <span class="n">get_asid</span><span class="p">();</span>

		<span class="k">if</span> <span class="p">(</span><span class="n">mm_asid</span> <span class="o">!=</span> <span class="n">current_asid</span><span class="p">)</span> <span class="p">{</span>
			<span class="cm">/* Switch ASID and run the invalidate loop under cli */</span>
			<span class="n">local_irq_save</span><span class="p">(</span><span class="n">flags</span><span class="p">);</span>
			<span class="n">switch_and_save_asid</span><span class="p">(</span><span class="n">mm_asid</span><span class="p">);</span>
		<span class="p">}</span>

		<span class="n">aligned_start</span> <span class="o">=</span> <span class="n">start</span> <span class="o">&amp;</span> <span class="n">PAGE_MASK</span><span class="p">;</span>
		<span class="n">after_last_page_start</span> <span class="o">=</span> <span class="n">PAGE_SIZE</span> <span class="o">+</span> <span class="p">((</span><span class="n">end</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">PAGE_MASK</span><span class="p">);</span>

		<span class="k">while</span> <span class="p">(</span><span class="n">aligned_start</span> <span class="o">&lt;</span> <span class="n">after_last_page_start</span><span class="p">)</span> <span class="p">{</span>
			<span class="k">struct</span> <span class="n">vm_area_struct</span> <span class="o">*</span><span class="n">vma</span><span class="p">;</span>
			<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">vma_end</span><span class="p">;</span>
			<span class="n">vma</span> <span class="o">=</span> <span class="n">find_vma</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span> <span class="n">aligned_start</span><span class="p">);</span>
			<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">vma</span> <span class="o">||</span> <span class="p">(</span><span class="n">aligned_start</span> <span class="o">&lt;=</span> <span class="n">vma</span><span class="o">-&gt;</span><span class="n">vm_end</span><span class="p">))</span> <span class="p">{</span>
				<span class="cm">/* Avoid getting stuck in an error condition */</span>
				<span class="n">aligned_start</span> <span class="o">+=</span> <span class="n">PAGE_SIZE</span><span class="p">;</span>
				<span class="k">continue</span><span class="p">;</span>
			<span class="p">}</span>
			<span class="n">vma_end</span> <span class="o">=</span> <span class="n">vma</span><span class="o">-&gt;</span><span class="n">vm_end</span><span class="p">;</span>
			<span class="k">if</span> <span class="p">(</span><span class="n">vma</span><span class="o">-&gt;</span><span class="n">vm_flags</span> <span class="o">&amp;</span> <span class="n">VM_EXEC</span><span class="p">)</span> <span class="p">{</span>
				<span class="cm">/* Executable */</span>
				<span class="n">eaddr</span> <span class="o">=</span> <span class="n">aligned_start</span><span class="p">;</span>
				<span class="k">while</span> <span class="p">(</span><span class="n">eaddr</span> <span class="o">&lt;</span> <span class="n">vma_end</span><span class="p">)</span> <span class="p">{</span>
					<span class="n">sh64_icache_inv_user_page</span><span class="p">(</span><span class="n">vma</span><span class="p">,</span> <span class="n">eaddr</span><span class="p">);</span>
					<span class="n">eaddr</span> <span class="o">+=</span> <span class="n">PAGE_SIZE</span><span class="p">;</span>
				<span class="p">}</span>
			<span class="p">}</span>
			<span class="n">aligned_start</span> <span class="o">=</span> <span class="n">vma</span><span class="o">-&gt;</span><span class="n">vm_end</span><span class="p">;</span> <span class="cm">/* Skip to start of next region */</span>
		<span class="p">}</span>

		<span class="k">if</span> <span class="p">(</span><span class="n">mm_asid</span> <span class="o">!=</span> <span class="n">current_asid</span><span class="p">)</span> <span class="p">{</span>
			<span class="n">switch_and_save_asid</span><span class="p">(</span><span class="n">current_asid</span><span class="p">);</span>
			<span class="n">local_irq_restore</span><span class="p">(</span><span class="n">flags</span><span class="p">);</span>
		<span class="p">}</span>
	<span class="p">}</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kt">void</span> <span class="nf">sh64_icache_inv_current_user_range</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">start</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">end</span><span class="p">)</span>
<span class="p">{</span>
	<span class="cm">/* The icbi instruction never raises ITLBMISS.  i.e. if there&#39;s not a</span>
<span class="cm">	   cache hit on the virtual tag the instruction ends there, without a</span>
<span class="cm">	   TLB lookup. */</span>

	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="kt">long</span> <span class="n">aligned_start</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="kt">long</span> <span class="n">ull_end</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="kt">long</span> <span class="n">addr</span><span class="p">;</span>

	<span class="n">ull_end</span> <span class="o">=</span> <span class="n">end</span><span class="p">;</span>

	<span class="cm">/* Just invalidate over the range using the natural addresses.  TLB</span>
<span class="cm">	   miss handling will be OK (TBC).  Since it&#39;s for the current process,</span>
<span class="cm">	   either we&#39;re already in the right ASID context, or the ASIDs have</span>
<span class="cm">	   been recycled since we were last active in which case we might just</span>
<span class="cm">	   invalidate another processes I-cache entries : no worries, just a</span>
<span class="cm">	   performance drop for him. */</span>
	<span class="n">aligned_start</span> <span class="o">=</span> <span class="n">L1_CACHE_ALIGN</span><span class="p">(</span><span class="n">start</span><span class="p">);</span>
	<span class="n">addr</span> <span class="o">=</span> <span class="n">aligned_start</span><span class="p">;</span>
	<span class="k">while</span> <span class="p">(</span><span class="n">addr</span> <span class="o">&lt;</span> <span class="n">ull_end</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">__asm__</span> <span class="n">__volatile__</span> <span class="p">(</span><span class="s">&quot;icbi %0, 0&quot;</span> <span class="o">:</span> <span class="o">:</span> <span class="s">&quot;r&quot;</span> <span class="p">(</span><span class="n">addr</span><span class="p">));</span>
		<span class="n">__asm__</span> <span class="n">__volatile__</span> <span class="p">(</span><span class="s">&quot;nop&quot;</span><span class="p">);</span>
		<span class="n">__asm__</span> <span class="n">__volatile__</span> <span class="p">(</span><span class="s">&quot;nop&quot;</span><span class="p">);</span>
		<span class="n">addr</span> <span class="o">+=</span> <span class="n">L1_CACHE_BYTES</span><span class="p">;</span>
	<span class="p">}</span>
<span class="p">}</span>

<span class="cm">/* Buffer used as the target of alloco instructions to purge data from cache</span>
<span class="cm">   sets by natural eviction. -- RPC */</span>
<span class="cp">#define DUMMY_ALLOCO_AREA_SIZE ((L1_CACHE_BYTES &lt;&lt; 10) + (1024 * 4))</span>
<span class="k">static</span> <span class="kt">unsigned</span> <span class="kt">char</span> <span class="n">dummy_alloco_area</span><span class="p">[</span><span class="n">DUMMY_ALLOCO_AREA_SIZE</span><span class="p">]</span> <span class="n">__cacheline_aligned</span> <span class="o">=</span> <span class="p">{</span> <span class="mi">0</span><span class="p">,</span> <span class="p">};</span>

<span class="k">static</span> <span class="kt">void</span> <span class="kr">inline</span> <span class="nf">sh64_dcache_purge_sets</span><span class="p">(</span><span class="kt">int</span> <span class="n">sets_to_purge_base</span><span class="p">,</span> <span class="kt">int</span> <span class="n">n_sets</span><span class="p">)</span>
<span class="p">{</span>
	<span class="cm">/* Purge all ways in a particular block of sets, specified by the base</span>
<span class="cm">	   set number and number of sets.  Can handle wrap-around, if that&#39;s</span>
<span class="cm">	   needed.  */</span>

	<span class="kt">int</span> <span class="n">dummy_buffer_base_set</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="kt">long</span> <span class="n">eaddr</span><span class="p">,</span> <span class="n">eaddr0</span><span class="p">,</span> <span class="n">eaddr1</span><span class="p">;</span>
	<span class="kt">int</span> <span class="n">j</span><span class="p">;</span>
	<span class="kt">int</span> <span class="n">set_offset</span><span class="p">;</span>

	<span class="n">dummy_buffer_base_set</span> <span class="o">=</span> <span class="p">((</span><span class="kt">int</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dummy_alloco_area</span> <span class="o">&amp;</span>
				 <span class="n">cpu_data</span><span class="o">-&gt;</span><span class="n">dcache</span><span class="p">.</span><span class="n">entry_mask</span><span class="p">)</span> <span class="o">&gt;&gt;</span>
				 <span class="n">cpu_data</span><span class="o">-&gt;</span><span class="n">dcache</span><span class="p">.</span><span class="n">entry_shift</span><span class="p">;</span>
	<span class="n">set_offset</span> <span class="o">=</span> <span class="n">sets_to_purge_base</span> <span class="o">-</span> <span class="n">dummy_buffer_base_set</span><span class="p">;</span>

	<span class="k">for</span> <span class="p">(</span><span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">n_sets</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">,</span> <span class="n">set_offset</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">set_offset</span> <span class="o">&amp;=</span> <span class="p">(</span><span class="n">cpu_data</span><span class="o">-&gt;</span><span class="n">dcache</span><span class="p">.</span><span class="n">sets</span> <span class="o">-</span> <span class="mi">1</span><span class="p">);</span>
		<span class="n">eaddr0</span> <span class="o">=</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span> <span class="kt">long</span><span class="p">)</span><span class="n">dummy_alloco_area</span> <span class="o">+</span>
			<span class="p">(</span><span class="n">set_offset</span> <span class="o">&lt;&lt;</span> <span class="n">cpu_data</span><span class="o">-&gt;</span><span class="n">dcache</span><span class="p">.</span><span class="n">entry_shift</span><span class="p">);</span>

		<span class="cm">/*</span>
<span class="cm">		 * Do one alloco which hits the required set per cache</span>
<span class="cm">		 * way.  For write-back mode, this will purge the #ways</span>
<span class="cm">		 * resident lines.  There&#39;s little point unrolling this</span>
<span class="cm">		 * loop because the allocos stall more if they&#39;re too</span>
<span class="cm">		 * close together.</span>
<span class="cm">		 */</span>
		<span class="n">eaddr1</span> <span class="o">=</span> <span class="n">eaddr0</span> <span class="o">+</span> <span class="n">cpu_data</span><span class="o">-&gt;</span><span class="n">dcache</span><span class="p">.</span><span class="n">way_size</span> <span class="o">*</span>
				  <span class="n">cpu_data</span><span class="o">-&gt;</span><span class="n">dcache</span><span class="p">.</span><span class="n">ways</span><span class="p">;</span>

		<span class="k">for</span> <span class="p">(</span><span class="n">eaddr</span> <span class="o">=</span> <span class="n">eaddr0</span><span class="p">;</span> <span class="n">eaddr</span> <span class="o">&lt;</span> <span class="n">eaddr1</span><span class="p">;</span>
		     <span class="n">eaddr</span> <span class="o">+=</span> <span class="n">cpu_data</span><span class="o">-&gt;</span><span class="n">dcache</span><span class="p">.</span><span class="n">way_size</span><span class="p">)</span> <span class="p">{</span>
			<span class="n">__asm__</span> <span class="n">__volatile__</span> <span class="p">(</span><span class="s">&quot;alloco %0, 0&quot;</span> <span class="o">:</span> <span class="o">:</span> <span class="s">&quot;r&quot;</span> <span class="p">(</span><span class="n">eaddr</span><span class="p">));</span>
			<span class="n">__asm__</span> <span class="n">__volatile__</span> <span class="p">(</span><span class="s">&quot;synco&quot;</span><span class="p">);</span> <span class="cm">/* TAKum03020 */</span>
		<span class="p">}</span>

		<span class="n">eaddr1</span> <span class="o">=</span> <span class="n">eaddr0</span> <span class="o">+</span> <span class="n">cpu_data</span><span class="o">-&gt;</span><span class="n">dcache</span><span class="p">.</span><span class="n">way_size</span> <span class="o">*</span>
				  <span class="n">cpu_data</span><span class="o">-&gt;</span><span class="n">dcache</span><span class="p">.</span><span class="n">ways</span><span class="p">;</span>

		<span class="k">for</span> <span class="p">(</span><span class="n">eaddr</span> <span class="o">=</span> <span class="n">eaddr0</span><span class="p">;</span> <span class="n">eaddr</span> <span class="o">&lt;</span> <span class="n">eaddr1</span><span class="p">;</span>
		     <span class="n">eaddr</span> <span class="o">+=</span> <span class="n">cpu_data</span><span class="o">-&gt;</span><span class="n">dcache</span><span class="p">.</span><span class="n">way_size</span><span class="p">)</span> <span class="p">{</span>
			<span class="cm">/*</span>
<span class="cm">			 * Load from each address.  Required because</span>
<span class="cm">			 * alloco is a NOP if the cache is write-through.</span>
<span class="cm">			 */</span>
			<span class="k">if</span> <span class="p">(</span><span class="n">test_bit</span><span class="p">(</span><span class="n">SH_CACHE_MODE_WT</span><span class="p">,</span> <span class="o">&amp;</span><span class="p">(</span><span class="n">cpu_data</span><span class="o">-&gt;</span><span class="n">dcache</span><span class="p">.</span><span class="n">flags</span><span class="p">)))</span>
				<span class="n">__raw_readb</span><span class="p">((</span><span class="kt">unsigned</span> <span class="kt">long</span><span class="p">)</span><span class="n">eaddr</span><span class="p">);</span>
		<span class="p">}</span>
	<span class="p">}</span>

	<span class="cm">/*</span>
<span class="cm">	 * Don&#39;t use OCBI to invalidate the lines.  That costs cycles</span>
<span class="cm">	 * directly.  If the dummy block is just left resident, it will</span>
<span class="cm">	 * naturally get evicted as required.</span>
<span class="cm">	 */</span>
<span class="p">}</span>

<span class="cm">/*</span>
<span class="cm"> * Purge the entire contents of the dcache.  The most efficient way to</span>
<span class="cm"> * achieve this is to use alloco instructions on a region of unused</span>
<span class="cm"> * memory equal in size to the cache, thereby causing the current</span>
<span class="cm"> * contents to be discarded by natural eviction.  The alternative, namely</span>
<span class="cm"> * reading every tag, setting up a mapping for the corresponding page and</span>
<span class="cm"> * doing an OCBP for the line, would be much more expensive.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kt">void</span> <span class="nf">sh64_dcache_purge_all</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>

	<span class="n">sh64_dcache_purge_sets</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">cpu_data</span><span class="o">-&gt;</span><span class="n">dcache</span><span class="p">.</span><span class="n">sets</span><span class="p">);</span>
<span class="p">}</span>


<span class="cm">/* Assumes this address (+ (2**n_synbits) pages up from it) aren&#39;t used for</span>
<span class="cm">   anything else in the kernel */</span>
<span class="cp">#define MAGIC_PAGE0_START 0xffffffffec000000ULL</span>

<span class="cm">/* Purge the physical page &#39;paddr&#39; from the cache.  It&#39;s known that any</span>
<span class="cm"> * cache lines requiring attention have the same page colour as the the</span>
<span class="cm"> * address &#39;eaddr&#39;.</span>
<span class="cm"> *</span>
<span class="cm"> * This relies on the fact that the D-cache matches on physical tags when</span>
<span class="cm"> * no virtual tag matches.  So we create an alias for the original page</span>
<span class="cm"> * and purge through that.  (Alternatively, we could have done this by</span>
<span class="cm"> * switching ASID to match the original mapping and purged through that,</span>
<span class="cm"> * but that involves ASID switching cost + probably a TLBMISS + refill</span>
<span class="cm"> * anyway.)</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kt">void</span> <span class="nf">sh64_dcache_purge_coloured_phy_page</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">paddr</span><span class="p">,</span>
					        <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">eaddr</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="kt">long</span> <span class="n">magic_page_start</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="kt">long</span> <span class="n">magic_eaddr</span><span class="p">,</span> <span class="n">magic_eaddr_end</span><span class="p">;</span>

	<span class="n">magic_page_start</span> <span class="o">=</span> <span class="n">MAGIC_PAGE0_START</span> <span class="o">+</span> <span class="p">(</span><span class="n">eaddr</span> <span class="o">&amp;</span> <span class="n">CACHE_OC_SYN_MASK</span><span class="p">);</span>

	<span class="cm">/* As long as the kernel is not pre-emptible, this doesn&#39;t need to be</span>
<span class="cm">	   under cli/sti. */</span>
	<span class="n">sh64_setup_dtlb_cache_slot</span><span class="p">(</span><span class="n">magic_page_start</span><span class="p">,</span> <span class="n">get_asid</span><span class="p">(),</span> <span class="n">paddr</span><span class="p">);</span>

	<span class="n">magic_eaddr</span> <span class="o">=</span> <span class="n">magic_page_start</span><span class="p">;</span>
	<span class="n">magic_eaddr_end</span> <span class="o">=</span> <span class="n">magic_eaddr</span> <span class="o">+</span> <span class="n">PAGE_SIZE</span><span class="p">;</span>

	<span class="k">while</span> <span class="p">(</span><span class="n">magic_eaddr</span> <span class="o">&lt;</span> <span class="n">magic_eaddr_end</span><span class="p">)</span> <span class="p">{</span>
		<span class="cm">/* Little point in unrolling this loop - the OCBPs are blocking</span>
<span class="cm">		   and won&#39;t go any quicker (i.e. the loop overhead is parallel</span>
<span class="cm">		   to part of the OCBP execution.) */</span>
		<span class="n">__asm__</span> <span class="n">__volatile__</span> <span class="p">(</span><span class="s">&quot;ocbp %0, 0&quot;</span> <span class="o">:</span> <span class="o">:</span> <span class="s">&quot;r&quot;</span> <span class="p">(</span><span class="n">magic_eaddr</span><span class="p">));</span>
		<span class="n">magic_eaddr</span> <span class="o">+=</span> <span class="n">L1_CACHE_BYTES</span><span class="p">;</span>
	<span class="p">}</span>

	<span class="n">sh64_teardown_dtlb_cache_slot</span><span class="p">();</span>
<span class="p">}</span>

<span class="cm">/*</span>
<span class="cm"> * Purge a page given its physical start address, by creating a temporary</span>
<span class="cm"> * 1 page mapping and purging across that.  Even if we know the virtual</span>
<span class="cm"> * address (&amp; vma or mm) of the page, the method here is more elegant</span>
<span class="cm"> * because it avoids issues of coping with page faults on the purge</span>
<span class="cm"> * instructions (i.e. no special-case code required in the critical path</span>
<span class="cm"> * in the TLB miss handling).</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kt">void</span> <span class="nf">sh64_dcache_purge_phy_page</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">paddr</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="kt">long</span> <span class="n">eaddr_start</span><span class="p">,</span> <span class="n">eaddr</span><span class="p">,</span> <span class="n">eaddr_end</span><span class="p">;</span>
	<span class="kt">int</span> <span class="n">i</span><span class="p">;</span>

	<span class="cm">/* As long as the kernel is not pre-emptible, this doesn&#39;t need to be</span>
<span class="cm">	   under cli/sti. */</span>
	<span class="n">eaddr_start</span> <span class="o">=</span> <span class="n">MAGIC_PAGE0_START</span><span class="p">;</span>
	<span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="p">(</span><span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="n">CACHE_OC_N_SYNBITS</span><span class="p">);</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">sh64_setup_dtlb_cache_slot</span><span class="p">(</span><span class="n">eaddr_start</span><span class="p">,</span> <span class="n">get_asid</span><span class="p">(),</span> <span class="n">paddr</span><span class="p">);</span>

		<span class="n">eaddr</span> <span class="o">=</span> <span class="n">eaddr_start</span><span class="p">;</span>
		<span class="n">eaddr_end</span> <span class="o">=</span> <span class="n">eaddr</span> <span class="o">+</span> <span class="n">PAGE_SIZE</span><span class="p">;</span>
		<span class="k">while</span> <span class="p">(</span><span class="n">eaddr</span> <span class="o">&lt;</span> <span class="n">eaddr_end</span><span class="p">)</span> <span class="p">{</span>
			<span class="n">__asm__</span> <span class="n">__volatile__</span> <span class="p">(</span><span class="s">&quot;ocbp %0, 0&quot;</span> <span class="o">:</span> <span class="o">:</span> <span class="s">&quot;r&quot;</span> <span class="p">(</span><span class="n">eaddr</span><span class="p">));</span>
			<span class="n">eaddr</span> <span class="o">+=</span> <span class="n">L1_CACHE_BYTES</span><span class="p">;</span>
		<span class="p">}</span>

		<span class="n">sh64_teardown_dtlb_cache_slot</span><span class="p">();</span>
		<span class="n">eaddr_start</span> <span class="o">+=</span> <span class="n">PAGE_SIZE</span><span class="p">;</span>
	<span class="p">}</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kt">void</span> <span class="nf">sh64_dcache_purge_user_pages</span><span class="p">(</span><span class="k">struct</span> <span class="n">mm_struct</span> <span class="o">*</span><span class="n">mm</span><span class="p">,</span>
				<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">addr</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">end</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">pgd_t</span> <span class="o">*</span><span class="n">pgd</span><span class="p">;</span>
	<span class="n">pud_t</span> <span class="o">*</span><span class="n">pud</span><span class="p">;</span>
	<span class="n">pmd_t</span> <span class="o">*</span><span class="n">pmd</span><span class="p">;</span>
	<span class="n">pte_t</span> <span class="o">*</span><span class="n">pte</span><span class="p">;</span>
	<span class="n">pte_t</span> <span class="n">entry</span><span class="p">;</span>
	<span class="n">spinlock_t</span> <span class="o">*</span><span class="n">ptl</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">paddr</span><span class="p">;</span>

	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">mm</span><span class="p">)</span>
		<span class="k">return</span><span class="p">;</span> <span class="cm">/* No way to find physical address of page */</span>

	<span class="n">pgd</span> <span class="o">=</span> <span class="n">pgd_offset</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span> <span class="n">addr</span><span class="p">);</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">pgd_bad</span><span class="p">(</span><span class="o">*</span><span class="n">pgd</span><span class="p">))</span>
		<span class="k">return</span><span class="p">;</span>

	<span class="n">pud</span> <span class="o">=</span> <span class="n">pud_offset</span><span class="p">(</span><span class="n">pgd</span><span class="p">,</span> <span class="n">addr</span><span class="p">);</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">pud_none</span><span class="p">(</span><span class="o">*</span><span class="n">pud</span><span class="p">)</span> <span class="o">||</span> <span class="n">pud_bad</span><span class="p">(</span><span class="o">*</span><span class="n">pud</span><span class="p">))</span>
		<span class="k">return</span><span class="p">;</span>

	<span class="n">pmd</span> <span class="o">=</span> <span class="n">pmd_offset</span><span class="p">(</span><span class="n">pud</span><span class="p">,</span> <span class="n">addr</span><span class="p">);</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">pmd_none</span><span class="p">(</span><span class="o">*</span><span class="n">pmd</span><span class="p">)</span> <span class="o">||</span> <span class="n">pmd_bad</span><span class="p">(</span><span class="o">*</span><span class="n">pmd</span><span class="p">))</span>
		<span class="k">return</span><span class="p">;</span>

	<span class="n">pte</span> <span class="o">=</span> <span class="n">pte_offset_map_lock</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span> <span class="n">pmd</span><span class="p">,</span> <span class="n">addr</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">ptl</span><span class="p">);</span>
	<span class="k">do</span> <span class="p">{</span>
		<span class="n">entry</span> <span class="o">=</span> <span class="o">*</span><span class="n">pte</span><span class="p">;</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">pte_none</span><span class="p">(</span><span class="n">entry</span><span class="p">)</span> <span class="o">||</span> <span class="o">!</span><span class="n">pte_present</span><span class="p">(</span><span class="n">entry</span><span class="p">))</span>
			<span class="k">continue</span><span class="p">;</span>
		<span class="n">paddr</span> <span class="o">=</span> <span class="n">pte_val</span><span class="p">(</span><span class="n">entry</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">PAGE_MASK</span><span class="p">;</span>
		<span class="n">sh64_dcache_purge_coloured_phy_page</span><span class="p">(</span><span class="n">paddr</span><span class="p">,</span> <span class="n">addr</span><span class="p">);</span>
	<span class="p">}</span> <span class="k">while</span> <span class="p">(</span><span class="n">pte</span><span class="o">++</span><span class="p">,</span> <span class="n">addr</span> <span class="o">+=</span> <span class="n">PAGE_SIZE</span><span class="p">,</span> <span class="n">addr</span> <span class="o">!=</span> <span class="n">end</span><span class="p">);</span>
	<span class="n">pte_unmap_unlock</span><span class="p">(</span><span class="n">pte</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">ptl</span><span class="p">);</span>
<span class="p">}</span>

<span class="cm">/*</span>
<span class="cm"> * There are at least 5 choices for the implementation of this, with</span>
<span class="cm"> * pros (+), cons(-), comments(*):</span>
<span class="cm"> *</span>
<span class="cm"> * 1. ocbp each line in the range through the original user&#39;s ASID</span>
<span class="cm"> *    + no lines spuriously evicted</span>
<span class="cm"> *    - tlbmiss handling (must either handle faults on demand =&gt; extra</span>
<span class="cm"> *	special-case code in tlbmiss critical path), or map the page in</span>
<span class="cm"> *	advance (=&gt; flush_tlb_range in advance to avoid multiple hits)</span>
<span class="cm"> *    - ASID switching</span>
<span class="cm"> *    - expensive for large ranges</span>
<span class="cm"> *</span>
<span class="cm"> * 2. temporarily map each page in the range to a special effective</span>
<span class="cm"> *    address and ocbp through the temporary mapping; relies on the</span>
<span class="cm"> *    fact that SH-5 OCB* always do TLB lookup and match on ptags (they</span>
<span class="cm"> *    never look at the etags)</span>
<span class="cm"> *    + no spurious evictions</span>
<span class="cm"> *    - expensive for large ranges</span>
<span class="cm"> *    * surely cheaper than (1)</span>
<span class="cm"> *</span>
<span class="cm"> * 3. walk all the lines in the cache, check the tags, if a match</span>
<span class="cm"> *    occurs create a page mapping to ocbp the line through</span>
<span class="cm"> *    + no spurious evictions</span>
<span class="cm"> *    - tag inspection overhead</span>
<span class="cm"> *    - (especially for small ranges)</span>
<span class="cm"> *    - potential cost of setting up/tearing down page mapping for</span>
<span class="cm"> *	every line that matches the range</span>
<span class="cm"> *    * cost partly independent of range size</span>
<span class="cm"> *</span>
<span class="cm"> * 4. walk all the lines in the cache, check the tags, if a match</span>
<span class="cm"> *    occurs use 4 * alloco to purge the line (+3 other probably</span>
<span class="cm"> *    innocent victims) by natural eviction</span>
<span class="cm"> *    + no tlb mapping overheads</span>
<span class="cm"> *    - spurious evictions</span>
<span class="cm"> *    - tag inspection overhead</span>
<span class="cm"> *</span>
<span class="cm"> * 5. implement like flush_cache_all</span>
<span class="cm"> *    + no tag inspection overhead</span>
<span class="cm"> *    - spurious evictions</span>
<span class="cm"> *    - bad for small ranges</span>
<span class="cm"> *</span>
<span class="cm"> * (1) can be ruled out as more expensive than (2).  (2) appears best</span>
<span class="cm"> * for small ranges.  The choice between (3), (4) and (5) for large</span>
<span class="cm"> * ranges and the range size for the large/small boundary need</span>
<span class="cm"> * benchmarking to determine.</span>
<span class="cm"> *</span>
<span class="cm"> * For now use approach (2) for small ranges and (5) for large ones.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kt">void</span> <span class="nf">sh64_dcache_purge_user_range</span><span class="p">(</span><span class="k">struct</span> <span class="n">mm_struct</span> <span class="o">*</span><span class="n">mm</span><span class="p">,</span>
			  <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">start</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">end</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">int</span> <span class="n">n_pages</span> <span class="o">=</span> <span class="p">((</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">&gt;&gt;</span> <span class="n">PAGE_SHIFT</span><span class="p">);</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">n_pages</span> <span class="o">&gt;=</span> <span class="mi">64</span> <span class="o">||</span> <span class="p">((</span><span class="n">start</span> <span class="o">^</span> <span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">&amp;</span> <span class="n">PMD_MASK</span><span class="p">))</span> <span class="p">{</span>
		<span class="n">sh64_dcache_purge_all</span><span class="p">();</span>
	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
		<span class="cm">/* Small range, covered by a single page table page */</span>
		<span class="n">start</span> <span class="o">&amp;=</span> <span class="n">PAGE_MASK</span><span class="p">;</span>	<span class="cm">/* should already be so */</span>
		<span class="n">end</span> <span class="o">=</span> <span class="n">PAGE_ALIGN</span><span class="p">(</span><span class="n">end</span><span class="p">);</span>	<span class="cm">/* should already be so */</span>
		<span class="n">sh64_dcache_purge_user_pages</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">);</span>
	<span class="p">}</span>
<span class="p">}</span>

<span class="cm">/*</span>
<span class="cm"> * Invalidate the entire contents of both caches, after writing back to</span>
<span class="cm"> * memory any dirty data from the D-cache.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kt">void</span> <span class="nf">sh5_flush_cache_all</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">unused</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">sh64_dcache_purge_all</span><span class="p">();</span>
	<span class="n">sh64_icache_inv_all</span><span class="p">();</span>
<span class="p">}</span>

<span class="cm">/*</span>
<span class="cm"> * Invalidate an entire user-address space from both caches, after</span>
<span class="cm"> * writing back dirty data (e.g. for shared mmap etc).</span>
<span class="cm"> *</span>
<span class="cm"> * This could be coded selectively by inspecting all the tags then</span>
<span class="cm"> * doing 4*alloco on any set containing a match (as for</span>
<span class="cm"> * flush_cache_range), but fork/exit/execve (where this is called from)</span>
<span class="cm"> * are expensive anyway.</span>
<span class="cm"> *</span>
<span class="cm"> * Have to do a purge here, despite the comments re I-cache below.</span>
<span class="cm"> * There could be odd-coloured dirty data associated with the mm still</span>
<span class="cm"> * in the cache - if this gets written out through natural eviction</span>
<span class="cm"> * after the kernel has reused the page there will be chaos.</span>
<span class="cm"> *</span>
<span class="cm"> * The mm being torn down won&#39;t ever be active again, so any Icache</span>
<span class="cm"> * lines tagged with its ASID won&#39;t be visible for the rest of the</span>
<span class="cm"> * lifetime of this ASID cycle.  Before the ASID gets reused, there</span>
<span class="cm"> * will be a flush_cache_all.  Hence we don&#39;t need to touch the</span>
<span class="cm"> * I-cache.  This is similar to the lack of action needed in</span>
<span class="cm"> * flush_tlb_mm - see fault.c.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kt">void</span> <span class="nf">sh5_flush_cache_mm</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">unused</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">sh64_dcache_purge_all</span><span class="p">();</span>
<span class="p">}</span>

<span class="cm">/*</span>
<span class="cm"> * Invalidate (from both caches) the range [start,end) of virtual</span>
<span class="cm"> * addresses from the user address space specified by mm, after writing</span>
<span class="cm"> * back any dirty data.</span>
<span class="cm"> *</span>
<span class="cm"> * Note, &#39;end&#39; is 1 byte beyond the end of the range to flush.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kt">void</span> <span class="nf">sh5_flush_cache_range</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">struct</span> <span class="n">flusher_data</span> <span class="o">*</span><span class="n">data</span> <span class="o">=</span> <span class="n">args</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">vm_area_struct</span> <span class="o">*</span><span class="n">vma</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">;</span>

	<span class="n">vma</span> <span class="o">=</span> <span class="n">data</span><span class="o">-&gt;</span><span class="n">vma</span><span class="p">;</span>
	<span class="n">start</span> <span class="o">=</span> <span class="n">data</span><span class="o">-&gt;</span><span class="n">addr1</span><span class="p">;</span>
	<span class="n">end</span> <span class="o">=</span> <span class="n">data</span><span class="o">-&gt;</span><span class="n">addr2</span><span class="p">;</span>

	<span class="n">sh64_dcache_purge_user_range</span><span class="p">(</span><span class="n">vma</span><span class="o">-&gt;</span><span class="n">vm_mm</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">);</span>
	<span class="n">sh64_icache_inv_user_page_range</span><span class="p">(</span><span class="n">vma</span><span class="o">-&gt;</span><span class="n">vm_mm</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">);</span>
<span class="p">}</span>

<span class="cm">/*</span>
<span class="cm"> * Invalidate any entries in either cache for the vma within the user</span>
<span class="cm"> * address space vma-&gt;vm_mm for the page starting at virtual address</span>
<span class="cm"> * &#39;eaddr&#39;.   This seems to be used primarily in breaking COW.  Note,</span>
<span class="cm"> * the I-cache must be searched too in case the page in question is</span>
<span class="cm"> * both writable and being executed from (e.g. stack trampolines.)</span>
<span class="cm"> *</span>
<span class="cm"> * Note, this is called with pte lock held.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kt">void</span> <span class="nf">sh5_flush_cache_page</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">struct</span> <span class="n">flusher_data</span> <span class="o">*</span><span class="n">data</span> <span class="o">=</span> <span class="n">args</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">vm_area_struct</span> <span class="o">*</span><span class="n">vma</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">eaddr</span><span class="p">,</span> <span class="n">pfn</span><span class="p">;</span>

	<span class="n">vma</span> <span class="o">=</span> <span class="n">data</span><span class="o">-&gt;</span><span class="n">vma</span><span class="p">;</span>
	<span class="n">eaddr</span> <span class="o">=</span> <span class="n">data</span><span class="o">-&gt;</span><span class="n">addr1</span><span class="p">;</span>
	<span class="n">pfn</span> <span class="o">=</span> <span class="n">data</span><span class="o">-&gt;</span><span class="n">addr2</span><span class="p">;</span>

	<span class="n">sh64_dcache_purge_phy_page</span><span class="p">(</span><span class="n">pfn</span> <span class="o">&lt;&lt;</span> <span class="n">PAGE_SHIFT</span><span class="p">);</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">vma</span><span class="o">-&gt;</span><span class="n">vm_flags</span> <span class="o">&amp;</span> <span class="n">VM_EXEC</span><span class="p">)</span>
		<span class="n">sh64_icache_inv_user_page</span><span class="p">(</span><span class="n">vma</span><span class="p">,</span> <span class="n">eaddr</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kt">void</span> <span class="nf">sh5_flush_dcache_page</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">page</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">sh64_dcache_purge_phy_page</span><span class="p">(</span><span class="n">page_to_phys</span><span class="p">((</span><span class="k">struct</span> <span class="n">page</span> <span class="o">*</span><span class="p">)</span><span class="n">page</span><span class="p">));</span>
	<span class="n">wmb</span><span class="p">();</span>
<span class="p">}</span>

<span class="cm">/*</span>
<span class="cm"> * Flush the range [start,end] of kernel virtual address space from</span>
<span class="cm"> * the I-cache.  The corresponding range must be purged from the</span>
<span class="cm"> * D-cache also because the SH-5 doesn&#39;t have cache snooping between</span>
<span class="cm"> * the caches.  The addresses will be visible through the superpage</span>
<span class="cm"> * mapping, therefore it&#39;s guaranteed that there no cache entries for</span>
<span class="cm"> * the range in cache sets of the wrong colour.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kt">void</span> <span class="nf">sh5_flush_icache_range</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">struct</span> <span class="n">flusher_data</span> <span class="o">*</span><span class="n">data</span> <span class="o">=</span> <span class="n">args</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">;</span>

	<span class="n">start</span> <span class="o">=</span> <span class="n">data</span><span class="o">-&gt;</span><span class="n">addr1</span><span class="p">;</span>
	<span class="n">end</span> <span class="o">=</span> <span class="n">data</span><span class="o">-&gt;</span><span class="n">addr2</span><span class="p">;</span>

	<span class="n">__flush_purge_region</span><span class="p">((</span><span class="kt">void</span> <span class="o">*</span><span class="p">)</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">);</span>
	<span class="n">wmb</span><span class="p">();</span>
	<span class="n">sh64_icache_inv_kernel_range</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">);</span>
<span class="p">}</span>

<span class="cm">/*</span>
<span class="cm"> * For the address range [start,end), write back the data from the</span>
<span class="cm"> * D-cache and invalidate the corresponding region of the I-cache for the</span>
<span class="cm"> * current process.  Used to flush signal trampolines on the stack to</span>
<span class="cm"> * make them executable.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kt">void</span> <span class="nf">sh5_flush_cache_sigtramp</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">vaddr</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">end</span> <span class="o">=</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span><span class="p">)</span><span class="n">vaddr</span> <span class="o">+</span> <span class="n">L1_CACHE_BYTES</span><span class="p">;</span>

	<span class="n">__flush_wback_region</span><span class="p">(</span><span class="n">vaddr</span><span class="p">,</span> <span class="n">L1_CACHE_BYTES</span><span class="p">);</span>
	<span class="n">wmb</span><span class="p">();</span>
	<span class="n">sh64_icache_inv_current_user_range</span><span class="p">((</span><span class="kt">unsigned</span> <span class="kt">long</span><span class="p">)</span><span class="n">vaddr</span><span class="p">,</span> <span class="n">end</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="n">__init</span> <span class="nf">sh5_cache_init</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">local_flush_cache_all</span>		<span class="o">=</span> <span class="n">sh5_flush_cache_all</span><span class="p">;</span>
	<span class="n">local_flush_cache_mm</span>		<span class="o">=</span> <span class="n">sh5_flush_cache_mm</span><span class="p">;</span>
	<span class="n">local_flush_cache_dup_mm</span>	<span class="o">=</span> <span class="n">sh5_flush_cache_mm</span><span class="p">;</span>
	<span class="n">local_flush_cache_page</span>		<span class="o">=</span> <span class="n">sh5_flush_cache_page</span><span class="p">;</span>
	<span class="n">local_flush_cache_range</span>		<span class="o">=</span> <span class="n">sh5_flush_cache_range</span><span class="p">;</span>
	<span class="n">local_flush_dcache_page</span>		<span class="o">=</span> <span class="n">sh5_flush_dcache_page</span><span class="p">;</span>
	<span class="n">local_flush_icache_range</span>	<span class="o">=</span> <span class="n">sh5_flush_icache_range</span><span class="p">;</span>
	<span class="n">local_flush_cache_sigtramp</span>	<span class="o">=</span> <span class="n">sh5_flush_cache_sigtramp</span><span class="p">;</span>

	<span class="cm">/* Reserve a slot for dcache colouring in the DTLB */</span>
	<span class="n">dtlb_cache_slot</span>	<span class="o">=</span> <span class="n">sh64_get_wired_dtlb_entry</span><span class="p">();</span>

	<span class="n">sh4__flush_region_init</span><span class="p">();</span>
<span class="p">}</span>

</pre></div></td></tr>

</tbody>
</table>
</div>

</body>
<script>docas={repo:"joekychen/linux",depth:3}</script>
<script>document.write('<script src=' + ('__proto__' in {} ? 'http://cdnjs.cloudflare.com/ajax/libs/zepto/1.0rc1/zepto.min.js' : 'https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js')+'><\\/script>')</script>
<script src="http://baoshan.github.com/moment/min/moment.min.js"></script>
<script src="../../../javascript/docco.min.js"></script>
</html>
