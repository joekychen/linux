<!DOCTYPE html>
<html><head><title>joekychen/linux » arch › parisc › include › asm › atomic.h

</title>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta name="generator" content="Docco">
<link rel="stylesheet" media="all" href="../../../../stylesheets/docco.min.css" />


</head>
<body>
<div id="container">
<div id="background"></div>
<table cellpadding="0" cellspacing="0">
<thead><tr><th class="docs"><a id="home" href="../../../../index.html"></a><h1>atomic.h</h1></th><th class="code"></th></tr></thead>
<tbody>


<tr id="section-1"><td class="docs"><div class="pilwrap"><a class="pilcrow" href="#section-1">&#182;</a></div></td><td class="code"><div class="highlight"><pre><span class="cm">/* Copyright (C) 2000 Philipp Rumpf &lt;prumpf@tux.org&gt;</span>
<span class="cm"> * Copyright (C) 2006 Kyle McMartin &lt;kyle@parisc-linux.org&gt;</span>
<span class="cm"> */</span>

<span class="cp">#ifndef _ASM_PARISC_ATOMIC_H_</span>
<span class="cp">#define _ASM_PARISC_ATOMIC_H_</span>

<span class="cp">#include &lt;linux/types.h&gt;</span>
<span class="cp">#include &lt;asm/cmpxchg.h&gt;</span>

<span class="cm">/*</span>
<span class="cm"> * Atomic operations that C can&#39;t guarantee us.  Useful for</span>
<span class="cm"> * resource counting etc..</span>
<span class="cm"> *</span>
<span class="cm"> * And probably incredibly slow on parisc.  OTOH, we don&#39;t</span>
<span class="cm"> * have to write any serious assembly.   prumpf</span>
<span class="cm"> */</span>

<span class="cp">#ifdef CONFIG_SMP</span>
<span class="cp">#include &lt;asm/spinlock.h&gt;</span>
<span class="cp">#include &lt;asm/cache.h&gt;		</span><span class="cm">/* we use L1_CACHE_BYTES */</span><span class="cp"></span>

<span class="cm">/* Use an array of spinlocks for our atomic_ts.</span>
<span class="cm"> * Hash function to index into a different SPINLOCK.</span>
<span class="cm"> * Since &quot;a&quot; is usually an address, use one spinlock per cacheline.</span>
<span class="cm"> */</span>
<span class="cp">#  define ATOMIC_HASH_SIZE 4</span>
<span class="cp">#  define ATOMIC_HASH(a) (&amp;(__atomic_hash[ (((unsigned long) (a))/L1_CACHE_BYTES) &amp; (ATOMIC_HASH_SIZE-1) ]))</span>

<span class="k">extern</span> <span class="n">arch_spinlock_t</span> <span class="n">__atomic_hash</span><span class="p">[</span><span class="n">ATOMIC_HASH_SIZE</span><span class="p">]</span> <span class="n">__lock_aligned</span><span class="p">;</span>

<span class="cm">/* Can&#39;t use raw_spin_lock_irq because of #include problems, so</span>
<span class="cm"> * this is the substitute */</span>
<span class="cp">#define _atomic_spin_lock_irqsave(l,f) do {	\</span>
<span class="cp">	arch_spinlock_t *s = ATOMIC_HASH(l);		\</span>
<span class="cp">	local_irq_save(f);			\</span>
<span class="cp">	arch_spin_lock(s);			\</span>
<span class="cp">} while(0)</span>

<span class="cp">#define _atomic_spin_unlock_irqrestore(l,f) do {	\</span>
<span class="cp">	arch_spinlock_t *s = ATOMIC_HASH(l);			\</span>
<span class="cp">	arch_spin_unlock(s);				\</span>
<span class="cp">	local_irq_restore(f);				\</span>
<span class="cp">} while(0)</span>


<span class="cp">#else</span>
<span class="cp">#  define _atomic_spin_lock_irqsave(l,f) do { local_irq_save(f); } while (0)</span>
<span class="cp">#  define _atomic_spin_unlock_irqrestore(l,f) do { local_irq_restore(f); } while (0)</span>
<span class="cp">#endif</span>

<span class="cm">/*</span>
<span class="cm"> * Note that we need not lock read accesses - aligned word writes/reads</span>
<span class="cm"> * are atomic, so a reader never sees inconsistent values.</span>
<span class="cm"> */</span>

<span class="cm">/* It&#39;s possible to reduce all atomic operations to either</span>
<span class="cm"> * __atomic_add_return, atomic_set and atomic_read (the latter</span>
<span class="cm"> * is there only for consistency).</span>
<span class="cm"> */</span>

<span class="k">static</span> <span class="n">__inline__</span> <span class="kt">int</span> <span class="nf">__atomic_add_return</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="p">,</span> <span class="n">atomic_t</span> <span class="o">*</span><span class="n">v</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">int</span> <span class="n">ret</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">;</span>
	<span class="n">_atomic_spin_lock_irqsave</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>

	<span class="n">ret</span> <span class="o">=</span> <span class="p">(</span><span class="n">v</span><span class="o">-&gt;</span><span class="n">counter</span> <span class="o">+=</span> <span class="n">i</span><span class="p">);</span>

	<span class="n">_atomic_spin_unlock_irqrestore</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>
	<span class="k">return</span> <span class="n">ret</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">static</span> <span class="n">__inline__</span> <span class="kt">void</span> <span class="nf">atomic_set</span><span class="p">(</span><span class="n">atomic_t</span> <span class="o">*</span><span class="n">v</span><span class="p">,</span> <span class="kt">int</span> <span class="n">i</span><span class="p">)</span> 
<span class="p">{</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">;</span>
	<span class="n">_atomic_spin_lock_irqsave</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>

	<span class="n">v</span><span class="o">-&gt;</span><span class="n">counter</span> <span class="o">=</span> <span class="n">i</span><span class="p">;</span>

	<span class="n">_atomic_spin_unlock_irqrestore</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">static</span> <span class="n">__inline__</span> <span class="kt">int</span> <span class="nf">atomic_read</span><span class="p">(</span><span class="k">const</span> <span class="n">atomic_t</span> <span class="o">*</span><span class="n">v</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="k">volatile</span> <span class="kt">int</span> <span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">counter</span><span class="p">);</span>
<span class="p">}</span>

<span class="cm">/* exported interface */</span>
<span class="cp">#define atomic_cmpxchg(v, o, n) (cmpxchg(&amp;((v)-&gt;counter), (o), (n)))</span>
<span class="cp">#define atomic_xchg(v, new) (xchg(&amp;((v)-&gt;counter), new))</span>

<span class="cm">/**</span>
<span class="cm"> * __atomic_add_unless - add unless the number is a given value</span>
<span class="cm"> * @v: pointer of type atomic_t</span>
<span class="cm"> * @a: the amount to add to v...</span>
<span class="cm"> * @u: ...unless v is equal to u.</span>
<span class="cm"> *</span>
<span class="cm"> * Atomically adds @a to @v, so long as it was not @u.</span>
<span class="cm"> * Returns the old value of @v.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="n">__inline__</span> <span class="kt">int</span> <span class="nf">__atomic_add_unless</span><span class="p">(</span><span class="n">atomic_t</span> <span class="o">*</span><span class="n">v</span><span class="p">,</span> <span class="kt">int</span> <span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="n">u</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">int</span> <span class="n">c</span><span class="p">,</span> <span class="n">old</span><span class="p">;</span>
	<span class="n">c</span> <span class="o">=</span> <span class="n">atomic_read</span><span class="p">(</span><span class="n">v</span><span class="p">);</span>
	<span class="k">for</span> <span class="p">(;;)</span> <span class="p">{</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">unlikely</span><span class="p">(</span><span class="n">c</span> <span class="o">==</span> <span class="p">(</span><span class="n">u</span><span class="p">)))</span>
			<span class="k">break</span><span class="p">;</span>
		<span class="n">old</span> <span class="o">=</span> <span class="n">atomic_cmpxchg</span><span class="p">((</span><span class="n">v</span><span class="p">),</span> <span class="n">c</span><span class="p">,</span> <span class="n">c</span> <span class="o">+</span> <span class="p">(</span><span class="n">a</span><span class="p">));</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">likely</span><span class="p">(</span><span class="n">old</span> <span class="o">==</span> <span class="n">c</span><span class="p">))</span>
			<span class="k">break</span><span class="p">;</span>
		<span class="n">c</span> <span class="o">=</span> <span class="n">old</span><span class="p">;</span>
	<span class="p">}</span>
	<span class="k">return</span> <span class="n">c</span><span class="p">;</span>
<span class="p">}</span>


<span class="cp">#define atomic_add(i,v)	((void)(__atomic_add_return( (i),(v))))</span>
<span class="cp">#define atomic_sub(i,v)	((void)(__atomic_add_return(-(i),(v))))</span>
<span class="cp">#define atomic_inc(v)	((void)(__atomic_add_return(   1,(v))))</span>
<span class="cp">#define atomic_dec(v)	((void)(__atomic_add_return(  -1,(v))))</span>

<span class="cp">#define atomic_add_return(i,v)	(__atomic_add_return( (i),(v)))</span>
<span class="cp">#define atomic_sub_return(i,v)	(__atomic_add_return(-(i),(v)))</span>
<span class="cp">#define atomic_inc_return(v)	(__atomic_add_return(   1,(v)))</span>
<span class="cp">#define atomic_dec_return(v)	(__atomic_add_return(  -1,(v)))</span>

<span class="cp">#define atomic_add_negative(a, v)	(atomic_add_return((a), (v)) &lt; 0)</span>

<span class="cm">/*</span>
<span class="cm"> * atomic_inc_and_test - increment and test</span>
<span class="cm"> * @v: pointer of type atomic_t</span>
<span class="cm"> *</span>
<span class="cm"> * Atomically increments @v by 1</span>
<span class="cm"> * and returns true if the result is zero, or false for all</span>
<span class="cm"> * other cases.</span>
<span class="cm"> */</span>
<span class="cp">#define atomic_inc_and_test(v) (atomic_inc_return(v) == 0)</span>

<span class="cp">#define atomic_dec_and_test(v)	(atomic_dec_return(v) == 0)</span>

<span class="cp">#define atomic_sub_and_test(i,v)	(atomic_sub_return((i),(v)) == 0)</span>

<span class="cp">#define ATOMIC_INIT(i)	((atomic_t) { (i) })</span>

<span class="cp">#define smp_mb__before_atomic_dec()	smp_mb()</span>
<span class="cp">#define smp_mb__after_atomic_dec()	smp_mb()</span>
<span class="cp">#define smp_mb__before_atomic_inc()	smp_mb()</span>
<span class="cp">#define smp_mb__after_atomic_inc()	smp_mb()</span>

<span class="cp">#ifdef CONFIG_64BIT</span>

<span class="cp">#define ATOMIC64_INIT(i) ((atomic64_t) { (i) })</span>

<span class="k">static</span> <span class="n">__inline__</span> <span class="n">s64</span>
<span class="nf">__atomic64_add_return</span><span class="p">(</span><span class="n">s64</span> <span class="n">i</span><span class="p">,</span> <span class="n">atomic64_t</span> <span class="o">*</span><span class="n">v</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">s64</span> <span class="n">ret</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">;</span>
	<span class="n">_atomic_spin_lock_irqsave</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>

	<span class="n">ret</span> <span class="o">=</span> <span class="p">(</span><span class="n">v</span><span class="o">-&gt;</span><span class="n">counter</span> <span class="o">+=</span> <span class="n">i</span><span class="p">);</span>

	<span class="n">_atomic_spin_unlock_irqrestore</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>
	<span class="k">return</span> <span class="n">ret</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">static</span> <span class="n">__inline__</span> <span class="kt">void</span>
<span class="nf">atomic64_set</span><span class="p">(</span><span class="n">atomic64_t</span> <span class="o">*</span><span class="n">v</span><span class="p">,</span> <span class="n">s64</span> <span class="n">i</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">;</span>
	<span class="n">_atomic_spin_lock_irqsave</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>

	<span class="n">v</span><span class="o">-&gt;</span><span class="n">counter</span> <span class="o">=</span> <span class="n">i</span><span class="p">;</span>

	<span class="n">_atomic_spin_unlock_irqrestore</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">static</span> <span class="n">__inline__</span> <span class="n">s64</span>
<span class="nf">atomic64_read</span><span class="p">(</span><span class="k">const</span> <span class="n">atomic64_t</span> <span class="o">*</span><span class="n">v</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="k">volatile</span> <span class="kt">long</span> <span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">counter</span><span class="p">);</span>
<span class="p">}</span>

<span class="cp">#define atomic64_add(i,v)	((void)(__atomic64_add_return( ((s64)(i)),(v))))</span>
<span class="cp">#define atomic64_sub(i,v)	((void)(__atomic64_add_return(-((s64)(i)),(v))))</span>
<span class="cp">#define atomic64_inc(v)		((void)(__atomic64_add_return(   1,(v))))</span>
<span class="cp">#define atomic64_dec(v)		((void)(__atomic64_add_return(  -1,(v))))</span>

<span class="cp">#define atomic64_add_return(i,v)	(__atomic64_add_return( ((s64)(i)),(v)))</span>
<span class="cp">#define atomic64_sub_return(i,v)	(__atomic64_add_return(-((s64)(i)),(v)))</span>
<span class="cp">#define atomic64_inc_return(v)		(__atomic64_add_return(   1,(v)))</span>
<span class="cp">#define atomic64_dec_return(v)		(__atomic64_add_return(  -1,(v)))</span>

<span class="cp">#define atomic64_add_negative(a, v)	(atomic64_add_return((a), (v)) &lt; 0)</span>

<span class="cp">#define atomic64_inc_and_test(v) 	(atomic64_inc_return(v) == 0)</span>
<span class="cp">#define atomic64_dec_and_test(v)	(atomic64_dec_return(v) == 0)</span>
<span class="cp">#define atomic64_sub_and_test(i,v)	(atomic64_sub_return((i),(v)) == 0)</span>

<span class="cm">/* exported interface */</span>
<span class="cp">#define atomic64_cmpxchg(v, o, n) \</span>
<span class="cp">	((__typeof__((v)-&gt;counter))cmpxchg(&amp;((v)-&gt;counter), (o), (n)))</span>
<span class="cp">#define atomic64_xchg(v, new) (xchg(&amp;((v)-&gt;counter), new))</span>

<span class="cm">/**</span>
<span class="cm"> * atomic64_add_unless - add unless the number is a given value</span>
<span class="cm"> * @v: pointer of type atomic64_t</span>
<span class="cm"> * @a: the amount to add to v...</span>
<span class="cm"> * @u: ...unless v is equal to u.</span>
<span class="cm"> *</span>
<span class="cm"> * Atomically adds @a to @v, so long as it was not @u.</span>
<span class="cm"> * Returns the old value of @v.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="n">__inline__</span> <span class="kt">int</span> <span class="nf">atomic64_add_unless</span><span class="p">(</span><span class="n">atomic64_t</span> <span class="o">*</span><span class="n">v</span><span class="p">,</span> <span class="kt">long</span> <span class="n">a</span><span class="p">,</span> <span class="kt">long</span> <span class="n">u</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">long</span> <span class="n">c</span><span class="p">,</span> <span class="n">old</span><span class="p">;</span>
	<span class="n">c</span> <span class="o">=</span> <span class="n">atomic64_read</span><span class="p">(</span><span class="n">v</span><span class="p">);</span>
	<span class="k">for</span> <span class="p">(;;)</span> <span class="p">{</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">unlikely</span><span class="p">(</span><span class="n">c</span> <span class="o">==</span> <span class="p">(</span><span class="n">u</span><span class="p">)))</span>
			<span class="k">break</span><span class="p">;</span>
		<span class="n">old</span> <span class="o">=</span> <span class="n">atomic64_cmpxchg</span><span class="p">((</span><span class="n">v</span><span class="p">),</span> <span class="n">c</span><span class="p">,</span> <span class="n">c</span> <span class="o">+</span> <span class="p">(</span><span class="n">a</span><span class="p">));</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">likely</span><span class="p">(</span><span class="n">old</span> <span class="o">==</span> <span class="n">c</span><span class="p">))</span>
			<span class="k">break</span><span class="p">;</span>
		<span class="n">c</span> <span class="o">=</span> <span class="n">old</span><span class="p">;</span>
	<span class="p">}</span>
	<span class="k">return</span> <span class="n">c</span> <span class="o">!=</span> <span class="p">(</span><span class="n">u</span><span class="p">);</span>
<span class="p">}</span>

<span class="cp">#define atomic64_inc_not_zero(v) atomic64_add_unless((v), 1, 0)</span>

<span class="cp">#endif </span><span class="cm">/* !CONFIG_64BIT */</span><span class="cp"></span>


<span class="cp">#endif </span><span class="cm">/* _ASM_PARISC_ATOMIC_H_ */</span><span class="cp"></span>

</pre></div></td></tr>

</tbody>
</table>
</div>

</body>
<script>docas={repo:"joekychen/linux",depth:4}</script>
<script>document.write('<script src=' + ('__proto__' in {} ? 'http://cdnjs.cloudflare.com/ajax/libs/zepto/1.0rc1/zepto.min.js' : 'https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js')+'><\\/script>')</script>
<script src="http://baoshan.github.com/moment/min/moment.min.js"></script>
<script src="../../../../javascript/docco.min.js"></script>
</html>
