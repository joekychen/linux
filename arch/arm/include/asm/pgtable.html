<!DOCTYPE html>
<html><head><title>joekychen/linux » arch › arm › include › asm › pgtable.h

</title>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta name="generator" content="Docco">
<link rel="stylesheet" media="all" href="../../../../stylesheets/docco.min.css" />


</head>
<body>
<div id="container">
<div id="background"></div>
<table cellpadding="0" cellspacing="0">
<thead><tr><th class="docs"><a id="home" href="../../../../index.html"></a><h1>pgtable.h</h1></th><th class="code"></th></tr></thead>
<tbody>


<tr id="section-1"><td class="docs"><div class="pilwrap"><a class="pilcrow" href="#section-1">&#182;</a></div></td><td class="code"><div class="highlight"><pre><span class="cm">/*</span>
<span class="cm"> *  arch/arm/include/asm/pgtable.h</span>
<span class="cm"> *</span>
<span class="cm"> *  Copyright (C) 1995-2002 Russell King</span>
<span class="cm"> *</span>
<span class="cm"> * This program is free software; you can redistribute it and/or modify</span>
<span class="cm"> * it under the terms of the GNU General Public License version 2 as</span>
<span class="cm"> * published by the Free Software Foundation.</span>
<span class="cm"> */</span>
<span class="cp">#ifndef _ASMARM_PGTABLE_H</span>
<span class="cp">#define _ASMARM_PGTABLE_H</span>

<span class="cp">#include &lt;linux/const.h&gt;</span>
<span class="cp">#include &lt;asm/proc-fns.h&gt;</span>

<span class="cp">#ifndef CONFIG_MMU</span>

<span class="cp">#include &lt;asm-generic/4level-fixup.h&gt;</span>
<span class="cp">#include &quot;pgtable-nommu.h&quot;</span>

<span class="cp">#else</span>

<span class="cp">#include &lt;asm-generic/pgtable-nopud.h&gt;</span>
<span class="cp">#include &lt;asm/memory.h&gt;</span>
<span class="cp">#include &lt;asm/pgtable-hwdef.h&gt;</span>

<span class="cp">#ifdef CONFIG_ARM_LPAE</span>
<span class="cp">#include &lt;asm/pgtable-3level.h&gt;</span>
<span class="cp">#else</span>
<span class="cp">#include &lt;asm/pgtable-2level.h&gt;</span>
<span class="cp">#endif</span>

<span class="cm">/*</span>
<span class="cm"> * Just any arbitrary offset to the start of the vmalloc VM area: the</span>
<span class="cm"> * current 8MB value just means that there will be a 8MB &quot;hole&quot; after the</span>
<span class="cm"> * physical memory until the kernel virtual memory starts.  That means that</span>
<span class="cm"> * any out-of-bounds memory accesses will hopefully be caught.</span>
<span class="cm"> * The vmalloc() routines leaves a hole of 4kB between each vmalloced</span>
<span class="cm"> * area for the same reason. ;)</span>
<span class="cm"> */</span>
<span class="cp">#define VMALLOC_OFFSET		(8*1024*1024)</span>
<span class="cp">#define VMALLOC_START		(((unsigned long)high_memory + VMALLOC_OFFSET) &amp; ~(VMALLOC_OFFSET-1))</span>
<span class="cp">#define VMALLOC_END		0xff000000UL</span>

<span class="cp">#define LIBRARY_TEXT_START	0x0c000000</span>

<span class="cp">#ifndef __ASSEMBLY__</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">__pte_error</span><span class="p">(</span><span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">file</span><span class="p">,</span> <span class="kt">int</span> <span class="n">line</span><span class="p">,</span> <span class="n">pte_t</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">__pmd_error</span><span class="p">(</span><span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">file</span><span class="p">,</span> <span class="kt">int</span> <span class="n">line</span><span class="p">,</span> <span class="n">pmd_t</span><span class="p">);</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">__pgd_error</span><span class="p">(</span><span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">file</span><span class="p">,</span> <span class="kt">int</span> <span class="n">line</span><span class="p">,</span> <span class="n">pgd_t</span><span class="p">);</span>

<span class="cp">#define pte_ERROR(pte)		__pte_error(__FILE__, __LINE__, pte)</span>
<span class="cp">#define pmd_ERROR(pmd)		__pmd_error(__FILE__, __LINE__, pmd)</span>
<span class="cp">#define pgd_ERROR(pgd)		__pgd_error(__FILE__, __LINE__, pgd)</span>

<span class="cm">/*</span>
<span class="cm"> * This is the lowest virtual address we can permit any user space</span>
<span class="cm"> * mapping to be mapped at.  This is particularly important for</span>
<span class="cm"> * non-high vector CPUs.</span>
<span class="cm"> */</span>
<span class="cp">#define FIRST_USER_ADDRESS	PAGE_SIZE</span>

<span class="cm">/*</span>
<span class="cm"> * The pgprot_* and protection_map entries will be fixed up in runtime</span>
<span class="cm"> * to include the cachable and bufferable bits based on memory policy,</span>
<span class="cm"> * as well as any architecture dependent bits like global/ASID and SMP</span>
<span class="cm"> * shared mapping bits.</span>
<span class="cm"> */</span>
<span class="cp">#define _L_PTE_DEFAULT	L_PTE_PRESENT | L_PTE_YOUNG</span>

<span class="k">extern</span> <span class="n">pgprot_t</span>		<span class="n">pgprot_user</span><span class="p">;</span>
<span class="k">extern</span> <span class="n">pgprot_t</span>		<span class="n">pgprot_kernel</span><span class="p">;</span>

<span class="cp">#define _MOD_PROT(p, b)	__pgprot(pgprot_val(p) | (b))</span>

<span class="cp">#define PAGE_NONE		_MOD_PROT(pgprot_user, L_PTE_XN | L_PTE_RDONLY)</span>
<span class="cp">#define PAGE_SHARED		_MOD_PROT(pgprot_user, L_PTE_USER | L_PTE_XN)</span>
<span class="cp">#define PAGE_SHARED_EXEC	_MOD_PROT(pgprot_user, L_PTE_USER)</span>
<span class="cp">#define PAGE_COPY		_MOD_PROT(pgprot_user, L_PTE_USER | L_PTE_RDONLY | L_PTE_XN)</span>
<span class="cp">#define PAGE_COPY_EXEC		_MOD_PROT(pgprot_user, L_PTE_USER | L_PTE_RDONLY)</span>
<span class="cp">#define PAGE_READONLY		_MOD_PROT(pgprot_user, L_PTE_USER | L_PTE_RDONLY | L_PTE_XN)</span>
<span class="cp">#define PAGE_READONLY_EXEC	_MOD_PROT(pgprot_user, L_PTE_USER | L_PTE_RDONLY)</span>
<span class="cp">#define PAGE_KERNEL		_MOD_PROT(pgprot_kernel, L_PTE_XN)</span>
<span class="cp">#define PAGE_KERNEL_EXEC	pgprot_kernel</span>

<span class="cp">#define __PAGE_NONE		__pgprot(_L_PTE_DEFAULT | L_PTE_RDONLY | L_PTE_XN)</span>
<span class="cp">#define __PAGE_SHARED		__pgprot(_L_PTE_DEFAULT | L_PTE_USER | L_PTE_XN)</span>
<span class="cp">#define __PAGE_SHARED_EXEC	__pgprot(_L_PTE_DEFAULT | L_PTE_USER)</span>
<span class="cp">#define __PAGE_COPY		__pgprot(_L_PTE_DEFAULT | L_PTE_USER | L_PTE_RDONLY | L_PTE_XN)</span>
<span class="cp">#define __PAGE_COPY_EXEC	__pgprot(_L_PTE_DEFAULT | L_PTE_USER | L_PTE_RDONLY)</span>
<span class="cp">#define __PAGE_READONLY		__pgprot(_L_PTE_DEFAULT | L_PTE_USER | L_PTE_RDONLY | L_PTE_XN)</span>
<span class="cp">#define __PAGE_READONLY_EXEC	__pgprot(_L_PTE_DEFAULT | L_PTE_USER | L_PTE_RDONLY)</span>

<span class="cp">#define __pgprot_modify(prot,mask,bits)		\</span>
<span class="cp">	__pgprot((pgprot_val(prot) &amp; ~(mask)) | (bits))</span>

<span class="cp">#define pgprot_noncached(prot) \</span>
<span class="cp">	__pgprot_modify(prot, L_PTE_MT_MASK, L_PTE_MT_UNCACHED)</span>

<span class="cp">#define pgprot_writecombine(prot) \</span>
<span class="cp">	__pgprot_modify(prot, L_PTE_MT_MASK, L_PTE_MT_BUFFERABLE)</span>

<span class="cp">#define pgprot_stronglyordered(prot) \</span>
<span class="cp">	__pgprot_modify(prot, L_PTE_MT_MASK, L_PTE_MT_UNCACHED)</span>

<span class="cp">#ifdef CONFIG_ARM_DMA_MEM_BUFFERABLE</span>
<span class="cp">#define pgprot_dmacoherent(prot) \</span>
<span class="cp">	__pgprot_modify(prot, L_PTE_MT_MASK, L_PTE_MT_BUFFERABLE | L_PTE_XN)</span>
<span class="cp">#define __HAVE_PHYS_MEM_ACCESS_PROT</span>
<span class="k">struct</span> <span class="n">file</span><span class="p">;</span>
<span class="k">extern</span> <span class="n">pgprot_t</span> <span class="n">phys_mem_access_prot</span><span class="p">(</span><span class="k">struct</span> <span class="n">file</span> <span class="o">*</span><span class="n">file</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">pfn</span><span class="p">,</span>
				     <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">size</span><span class="p">,</span> <span class="n">pgprot_t</span> <span class="n">vma_prot</span><span class="p">);</span>
<span class="cp">#else</span>
<span class="cp">#define pgprot_dmacoherent(prot) \</span>
<span class="cp">	__pgprot_modify(prot, L_PTE_MT_MASK, L_PTE_MT_UNCACHED | L_PTE_XN)</span>
<span class="cp">#endif</span>

<span class="cp">#endif </span><span class="cm">/* __ASSEMBLY__ */</span><span class="cp"></span>

<span class="cm">/*</span>
<span class="cm"> * The table below defines the page protection levels that we insert into our</span>
<span class="cm"> * Linux page table version.  These get translated into the best that the</span>
<span class="cm"> * architecture can perform.  Note that on most ARM hardware:</span>
<span class="cm"> *  1) We cannot do execute protection</span>
<span class="cm"> *  2) If we could do execute protection, then read is implied</span>
<span class="cm"> *  3) write implies read permissions</span>
<span class="cm"> */</span>
<span class="cp">#define __P000  __PAGE_NONE</span>
<span class="cp">#define __P001  __PAGE_READONLY</span>
<span class="cp">#define __P010  __PAGE_COPY</span>
<span class="cp">#define __P011  __PAGE_COPY</span>
<span class="cp">#define __P100  __PAGE_READONLY_EXEC</span>
<span class="cp">#define __P101  __PAGE_READONLY_EXEC</span>
<span class="cp">#define __P110  __PAGE_COPY_EXEC</span>
<span class="cp">#define __P111  __PAGE_COPY_EXEC</span>

<span class="cp">#define __S000  __PAGE_NONE</span>
<span class="cp">#define __S001  __PAGE_READONLY</span>
<span class="cp">#define __S010  __PAGE_SHARED</span>
<span class="cp">#define __S011  __PAGE_SHARED</span>
<span class="cp">#define __S100  __PAGE_READONLY_EXEC</span>
<span class="cp">#define __S101  __PAGE_READONLY_EXEC</span>
<span class="cp">#define __S110  __PAGE_SHARED_EXEC</span>
<span class="cp">#define __S111  __PAGE_SHARED_EXEC</span>

<span class="cp">#ifndef __ASSEMBLY__</span>
<span class="cm">/*</span>
<span class="cm"> * ZERO_PAGE is a global shared page that is always zero: used</span>
<span class="cm"> * for zero-mapped memory areas etc..</span>
<span class="cm"> */</span>
<span class="k">extern</span> <span class="k">struct</span> <span class="n">page</span> <span class="o">*</span><span class="n">empty_zero_page</span><span class="p">;</span>
<span class="cp">#define ZERO_PAGE(vaddr)	(empty_zero_page)</span>


<span class="k">extern</span> <span class="n">pgd_t</span> <span class="n">swapper_pg_dir</span><span class="p">[</span><span class="n">PTRS_PER_PGD</span><span class="p">];</span>

<span class="cm">/* to find an entry in a page-table-directory */</span>
<span class="cp">#define pgd_index(addr)		((addr) &gt;&gt; PGDIR_SHIFT)</span>

<span class="cp">#define pgd_offset(mm, addr)	((mm)-&gt;pgd + pgd_index(addr))</span>

<span class="cm">/* to find an entry in a kernel page-table-directory */</span>
<span class="cp">#define pgd_offset_k(addr)	pgd_offset(&amp;init_mm, addr)</span>

<span class="cp">#define pmd_none(pmd)		(!pmd_val(pmd))</span>
<span class="cp">#define pmd_present(pmd)	(pmd_val(pmd))</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="n">pte_t</span> <span class="o">*</span><span class="nf">pmd_page_vaddr</span><span class="p">(</span><span class="n">pmd_t</span> <span class="n">pmd</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="n">__va</span><span class="p">(</span><span class="n">pmd_val</span><span class="p">(</span><span class="n">pmd</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">PHYS_MASK</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">s32</span><span class="p">)</span><span class="n">PAGE_MASK</span><span class="p">);</span>
<span class="p">}</span>

<span class="cp">#define pmd_page(pmd)		pfn_to_page(__phys_to_pfn(pmd_val(pmd) &amp; PHYS_MASK))</span>

<span class="cp">#ifndef CONFIG_HIGHPTE</span>
<span class="cp">#define __pte_map(pmd)		pmd_page_vaddr(*(pmd))</span>
<span class="cp">#define __pte_unmap(pte)	do { } while (0)</span>
<span class="cp">#else</span>
<span class="cp">#define __pte_map(pmd)		(pte_t *)kmap_atomic(pmd_page(*(pmd)))</span>
<span class="cp">#define __pte_unmap(pte)	kunmap_atomic(pte)</span>
<span class="cp">#endif</span>

<span class="cp">#define pte_index(addr)		(((addr) &gt;&gt; PAGE_SHIFT) &amp; (PTRS_PER_PTE - 1))</span>

<span class="cp">#define pte_offset_kernel(pmd,addr)	(pmd_page_vaddr(*(pmd)) + pte_index(addr))</span>

<span class="cp">#define pte_offset_map(pmd,addr)	(__pte_map(pmd) + pte_index(addr))</span>
<span class="cp">#define pte_unmap(pte)			__pte_unmap(pte)</span>

<span class="cp">#define pte_pfn(pte)		((pte_val(pte) &amp; PHYS_MASK) &gt;&gt; PAGE_SHIFT)</span>
<span class="cp">#define pfn_pte(pfn,prot)	__pte(__pfn_to_phys(pfn) | pgprot_val(prot))</span>

<span class="cp">#define pte_page(pte)		pfn_to_page(pte_pfn(pte))</span>
<span class="cp">#define mk_pte(page,prot)	pfn_pte(page_to_pfn(page), prot)</span>

<span class="cp">#define pte_clear(mm,addr,ptep)	set_pte_ext(ptep, __pte(0), 0)</span>

<span class="cp">#if __LINUX_ARM_ARCH__ &lt; 6</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">__sync_icache_dcache</span><span class="p">(</span><span class="n">pte_t</span> <span class="n">pteval</span><span class="p">)</span>
<span class="p">{</span>
<span class="p">}</span>
<span class="cp">#else</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">__sync_icache_dcache</span><span class="p">(</span><span class="n">pte_t</span> <span class="n">pteval</span><span class="p">);</span>
<span class="cp">#endif</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">set_pte_at</span><span class="p">(</span><span class="k">struct</span> <span class="n">mm_struct</span> <span class="o">*</span><span class="n">mm</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">addr</span><span class="p">,</span>
			      <span class="n">pte_t</span> <span class="o">*</span><span class="n">ptep</span><span class="p">,</span> <span class="n">pte_t</span> <span class="n">pteval</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">addr</span> <span class="o">&gt;=</span> <span class="n">TASK_SIZE</span><span class="p">)</span>
		<span class="n">set_pte_ext</span><span class="p">(</span><span class="n">ptep</span><span class="p">,</span> <span class="n">pteval</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
	<span class="k">else</span> <span class="p">{</span>
		<span class="n">__sync_icache_dcache</span><span class="p">(</span><span class="n">pteval</span><span class="p">);</span>
		<span class="n">set_pte_ext</span><span class="p">(</span><span class="n">ptep</span><span class="p">,</span> <span class="n">pteval</span><span class="p">,</span> <span class="n">PTE_EXT_NG</span><span class="p">);</span>
	<span class="p">}</span>
<span class="p">}</span>

<span class="cp">#define pte_none(pte)		(!pte_val(pte))</span>
<span class="cp">#define pte_present(pte)	(pte_val(pte) &amp; L_PTE_PRESENT)</span>
<span class="cp">#define pte_write(pte)		(!(pte_val(pte) &amp; L_PTE_RDONLY))</span>
<span class="cp">#define pte_dirty(pte)		(pte_val(pte) &amp; L_PTE_DIRTY)</span>
<span class="cp">#define pte_young(pte)		(pte_val(pte) &amp; L_PTE_YOUNG)</span>
<span class="cp">#define pte_exec(pte)		(!(pte_val(pte) &amp; L_PTE_XN))</span>
<span class="cp">#define pte_special(pte)	(0)</span>

<span class="cp">#define pte_present_user(pte) \</span>
<span class="cp">	((pte_val(pte) &amp; (L_PTE_PRESENT | L_PTE_USER)) == \</span>
<span class="cp">	 (L_PTE_PRESENT | L_PTE_USER))</span>

<span class="cp">#define PTE_BIT_FUNC(fn,op) \</span>
<span class="cp">static inline pte_t pte_##fn(pte_t pte) { pte_val(pte) op; return pte; }</span>

<span class="n">PTE_BIT_FUNC</span><span class="p">(</span><span class="n">wrprotect</span><span class="p">,</span> <span class="o">|=</span> <span class="n">L_PTE_RDONLY</span><span class="p">);</span>
<span class="n">PTE_BIT_FUNC</span><span class="p">(</span><span class="n">mkwrite</span><span class="p">,</span>   <span class="o">&amp;=</span> <span class="o">~</span><span class="n">L_PTE_RDONLY</span><span class="p">);</span>
<span class="n">PTE_BIT_FUNC</span><span class="p">(</span><span class="n">mkclean</span><span class="p">,</span>   <span class="o">&amp;=</span> <span class="o">~</span><span class="n">L_PTE_DIRTY</span><span class="p">);</span>
<span class="n">PTE_BIT_FUNC</span><span class="p">(</span><span class="n">mkdirty</span><span class="p">,</span>   <span class="o">|=</span> <span class="n">L_PTE_DIRTY</span><span class="p">);</span>
<span class="n">PTE_BIT_FUNC</span><span class="p">(</span><span class="n">mkold</span><span class="p">,</span>     <span class="o">&amp;=</span> <span class="o">~</span><span class="n">L_PTE_YOUNG</span><span class="p">);</span>
<span class="n">PTE_BIT_FUNC</span><span class="p">(</span><span class="n">mkyoung</span><span class="p">,</span>   <span class="o">|=</span> <span class="n">L_PTE_YOUNG</span><span class="p">);</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="n">pte_t</span> <span class="nf">pte_mkspecial</span><span class="p">(</span><span class="n">pte_t</span> <span class="n">pte</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="n">pte</span><span class="p">;</span> <span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="n">pte_t</span> <span class="nf">pte_modify</span><span class="p">(</span><span class="n">pte_t</span> <span class="n">pte</span><span class="p">,</span> <span class="n">pgprot_t</span> <span class="n">newprot</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">const</span> <span class="n">pteval_t</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">L_PTE_XN</span> <span class="o">|</span> <span class="n">L_PTE_RDONLY</span> <span class="o">|</span> <span class="n">L_PTE_USER</span><span class="p">;</span>
	<span class="n">pte_val</span><span class="p">(</span><span class="n">pte</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">pte_val</span><span class="p">(</span><span class="n">pte</span><span class="p">)</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">mask</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">pgprot_val</span><span class="p">(</span><span class="n">newprot</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">mask</span><span class="p">);</span>
	<span class="k">return</span> <span class="n">pte</span><span class="p">;</span>
<span class="p">}</span>

<span class="cm">/*</span>
<span class="cm"> * Encode and decode a swap entry.  Swap entries are stored in the Linux</span>
<span class="cm"> * page tables as follows:</span>
<span class="cm"> *</span>
<span class="cm"> *   3 3 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1</span>
<span class="cm"> *   1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0</span>
<span class="cm"> *   &lt;--------------- offset --------------------&gt; &lt;- type --&gt; 0 0 0</span>
<span class="cm"> *</span>
<span class="cm"> * This gives us up to 63 swap files and 32GB per swap file.  Note that</span>
<span class="cm"> * the offset field is always non-zero.</span>
<span class="cm"> */</span>
<span class="cp">#define __SWP_TYPE_SHIFT	3</span>
<span class="cp">#define __SWP_TYPE_BITS		6</span>
<span class="cp">#define __SWP_TYPE_MASK		((1 &lt;&lt; __SWP_TYPE_BITS) - 1)</span>
<span class="cp">#define __SWP_OFFSET_SHIFT	(__SWP_TYPE_BITS + __SWP_TYPE_SHIFT)</span>

<span class="cp">#define __swp_type(x)		(((x).val &gt;&gt; __SWP_TYPE_SHIFT) &amp; __SWP_TYPE_MASK)</span>
<span class="cp">#define __swp_offset(x)		((x).val &gt;&gt; __SWP_OFFSET_SHIFT)</span>
<span class="cp">#define __swp_entry(type,offset) ((swp_entry_t) { ((type) &lt;&lt; __SWP_TYPE_SHIFT) | ((offset) &lt;&lt; __SWP_OFFSET_SHIFT) })</span>

<span class="cp">#define __pte_to_swp_entry(pte)	((swp_entry_t) { pte_val(pte) })</span>
<span class="cp">#define __swp_entry_to_pte(swp)	((pte_t) { (swp).val })</span>

<span class="cm">/*</span>
<span class="cm"> * It is an error for the kernel to have more swap files than we can</span>
<span class="cm"> * encode in the PTEs.  This ensures that we know when MAX_SWAPFILES</span>
<span class="cm"> * is increased beyond what we presently support.</span>
<span class="cm"> */</span>
<span class="cp">#define MAX_SWAPFILES_CHECK() BUILD_BUG_ON(MAX_SWAPFILES_SHIFT &gt; __SWP_TYPE_BITS)</span>

<span class="cm">/*</span>
<span class="cm"> * Encode and decode a file entry.  File entries are stored in the Linux</span>
<span class="cm"> * page tables as follows:</span>
<span class="cm"> *</span>
<span class="cm"> *   3 3 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1</span>
<span class="cm"> *   1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0</span>
<span class="cm"> *   &lt;----------------------- offset ------------------------&gt; 1 0 0</span>
<span class="cm"> */</span>
<span class="cp">#define pte_file(pte)		(pte_val(pte) &amp; L_PTE_FILE)</span>
<span class="cp">#define pte_to_pgoff(x)		(pte_val(x) &gt;&gt; 3)</span>
<span class="cp">#define pgoff_to_pte(x)		__pte(((x) &lt;&lt; 3) | L_PTE_FILE)</span>

<span class="cp">#define PTE_FILE_MAX_BITS	29</span>

<span class="cm">/* Needs to be defined here and not in linux/mm.h, as it is arch dependent */</span>
<span class="cm">/* FIXME: this is not correct */</span>
<span class="cp">#define kern_addr_valid(addr)	(1)</span>

<span class="cp">#include &lt;asm-generic/pgtable.h&gt;</span>

<span class="cm">/*</span>
<span class="cm"> * We provide our own arch_get_unmapped_area to cope with VIPT caches.</span>
<span class="cm"> */</span>
<span class="cp">#define HAVE_ARCH_UNMAPPED_AREA</span>
<span class="cp">#define HAVE_ARCH_UNMAPPED_AREA_TOPDOWN</span>

<span class="cm">/*</span>
<span class="cm"> * remap a physical page `pfn&#39; of size `size&#39; with page protection `prot&#39;</span>
<span class="cm"> * into virtual address `from&#39;</span>
<span class="cm"> */</span>
<span class="cp">#define io_remap_pfn_range(vma,from,pfn,size,prot) \</span>
<span class="cp">		remap_pfn_range(vma, from, pfn, size, prot)</span>

<span class="cp">#define pgtable_cache_init() do { } while (0)</span>

<span class="cp">#endif </span><span class="cm">/* !__ASSEMBLY__ */</span><span class="cp"></span>

<span class="cp">#endif </span><span class="cm">/* CONFIG_MMU */</span><span class="cp"></span>

<span class="cp">#endif </span><span class="cm">/* _ASMARM_PGTABLE_H */</span><span class="cp"></span>

</pre></div></td></tr>

</tbody>
</table>
</div>

</body>
<script>docas={repo:"joekychen/linux",depth:4}</script>
<script>document.write('<script src=' + ('__proto__' in {} ? 'http://cdnjs.cloudflare.com/ajax/libs/zepto/1.0rc1/zepto.min.js' : 'https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js')+'><\\/script>')</script>
<script src="http://baoshan.github.com/moment/min/moment.min.js"></script>
<script src="../../../../javascript/docco.min.js"></script>
</html>
