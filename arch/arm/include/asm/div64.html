<!DOCTYPE html>
<html><head><title>joekychen/linux » arch › arm › include › asm › div64.h

</title>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta name="generator" content="Docco">
<link rel="stylesheet" media="all" href="../../../../stylesheets/docco.min.css" />


</head>
<body>
<div id="container">
<div id="background"></div>
<table cellpadding="0" cellspacing="0">
<thead><tr><th class="docs"><a id="home" href="../../../../index.html"></a><h1>div64.h</h1></th><th class="code"></th></tr></thead>
<tbody>


<tr id="section-1"><td class="docs"><div class="pilwrap"><a class="pilcrow" href="#section-1">&#182;</a></div></td><td class="code"><div class="highlight"><pre><span class="cp">#ifndef __ASM_ARM_DIV64</span>
<span class="cp">#define __ASM_ARM_DIV64</span>

<span class="cp">#include &lt;linux/types.h&gt;</span>
<span class="cp">#include &lt;asm/compiler.h&gt;</span>

<span class="cm">/*</span>
<span class="cm"> * The semantics of do_div() are:</span>
<span class="cm"> *</span>
<span class="cm"> * uint32_t do_div(uint64_t *n, uint32_t base)</span>
<span class="cm"> * {</span>
<span class="cm"> * 	uint32_t remainder = *n % base;</span>
<span class="cm"> * 	*n = *n / base;</span>
<span class="cm"> * 	return remainder;</span>
<span class="cm"> * }</span>
<span class="cm"> *</span>
<span class="cm"> * In other words, a 64-bit dividend with a 32-bit divisor producing</span>
<span class="cm"> * a 64-bit result and a 32-bit remainder.  To accomplish this optimally</span>
<span class="cm"> * we call a special __do_div64 helper with completely non standard</span>
<span class="cm"> * calling convention for arguments and results (beware).</span>
<span class="cm"> */</span>

<span class="cp">#ifdef __ARMEB__</span>
<span class="cp">#define __xh &quot;r0&quot;</span>
<span class="cp">#define __xl &quot;r1&quot;</span>
<span class="cp">#else</span>
<span class="cp">#define __xl &quot;r0&quot;</span>
<span class="cp">#define __xh &quot;r1&quot;</span>
<span class="cp">#endif</span>

<span class="cp">#define __do_div_asm(n, base)					\</span>
<span class="cp">({								\</span>
<span class="cp">	register unsigned int __base      asm(&quot;r4&quot;) = base;	\</span>
<span class="cp">	register unsigned long long __n   asm(&quot;r0&quot;) = n;	\</span>
<span class="cp">	register unsigned long long __res asm(&quot;r2&quot;);		\</span>
<span class="cp">	register unsigned int __rem       asm(__xh);		\</span>
<span class="cp">	asm(	__asmeq(&quot;%0&quot;, __xh)				\</span>
<span class="cp">		__asmeq(&quot;%1&quot;, &quot;r2&quot;)				\</span>
<span class="cp">		__asmeq(&quot;%2&quot;, &quot;r0&quot;)				\</span>
<span class="cp">		__asmeq(&quot;%3&quot;, &quot;r4&quot;)				\</span>
<span class="cp">		&quot;bl	__do_div64&quot;				\</span>
<span class="cp">		: &quot;=r&quot; (__rem), &quot;=r&quot; (__res)			\</span>
<span class="cp">		: &quot;r&quot; (__n), &quot;r&quot; (__base)			\</span>
<span class="cp">		: &quot;ip&quot;, &quot;lr&quot;, &quot;cc&quot;);				\</span>
<span class="cp">	n = __res;						\</span>
<span class="cp">	__rem;							\</span>
<span class="cp">})</span>

<span class="cp">#if __GNUC__ &lt; 4</span>

<span class="cm">/*</span>
<span class="cm"> * gcc versions earlier than 4.0 are simply too problematic for the</span>
<span class="cm"> * optimized implementation below. First there is gcc PR 15089 that</span>
<span class="cm"> * tend to trig on more complex constructs, spurious .global __udivsi3</span>
<span class="cm"> * are inserted even if none of those symbols are referenced in the</span>
<span class="cm"> * generated code, and those gcc versions are not able to do constant</span>
<span class="cm"> * propagation on long long values anyway.</span>
<span class="cm"> */</span>
<span class="cp">#define do_div(n, base) __do_div_asm(n, base)</span>

<span class="cp">#elif __GNUC__ &gt;= 4</span>

<span class="cp">#include &lt;asm/bug.h&gt;</span>

<span class="cm">/*</span>
<span class="cm"> * If the divisor happens to be constant, we determine the appropriate</span>
<span class="cm"> * inverse at compile time to turn the division into a few inline</span>
<span class="cm"> * multiplications instead which is much faster. And yet only if compiling</span>
<span class="cm"> * for ARMv4 or higher (we need umull/umlal) and if the gcc version is</span>
<span class="cm"> * sufficiently recent to perform proper long long constant propagation.</span>
<span class="cm"> * (It is unfortunate that gcc doesn&#39;t perform all this internally.)</span>
<span class="cm"> */</span>
<span class="cp">#define do_div(n, base)							\</span>
<span class="cp">({									\</span>
<span class="cp">	unsigned int __r, __b = (base);					\</span>
<span class="cp">	if (!__builtin_constant_p(__b) || __b == 0 ||			\</span>
<span class="cp">	    (__LINUX_ARM_ARCH__ &lt; 4 &amp;&amp; (__b &amp; (__b - 1)) != 0)) {	\</span>
<span class="cp">		</span><span class="cm">/* non-constant divisor (or zero): slow path */</span><span class="cp">		\</span>
<span class="cp">		__r = __do_div_asm(n, __b);				\</span>
<span class="cp">	} else if ((__b &amp; (__b - 1)) == 0) {				\</span>
<span class="cp">		</span><span class="cm">/* Trivial: __b is constant and a power of 2 */</span><span class="cp">		\</span>
<span class="cp">		</span><span class="cm">/* gcc does the right thing with this code.  */</span><span class="cp">		\</span>
<span class="cp">		__r = n;						\</span>
<span class="cp">		__r &amp;= (__b - 1);					\</span>
<span class="cp">		n /= __b;						\</span>
<span class="cp">	} else {							\</span>
<span class="cp">		</span><span class="cm">/* Multiply by inverse of __b: n/b = n*(p/b)/p       */</span><span class="cp">	\</span>
<span class="cp">		</span><span class="cm">/* We rely on the fact that most of this code gets   */</span><span class="cp">	\</span>
<span class="cp">		</span><span class="cm">/* optimized away at compile time due to constant    */</span><span class="cp">	\</span>
<span class="cp">		</span><span class="cm">/* propagation and only a couple inline assembly     */</span><span class="cp">	\</span>
<span class="cp">		</span><span class="cm">/* instructions should remain. Better avoid any      */</span><span class="cp">	\</span>
<span class="cp">		</span><span class="cm">/* code construct that might prevent that.           */</span><span class="cp">	\</span>
<span class="cp">		unsigned long long __res, __x, __t, __m, __n = n;	\</span>
<span class="cp">		unsigned int __c, __p, __z = 0;				\</span>
<span class="cp">		</span><span class="cm">/* preserve low part of n for reminder computation */</span><span class="cp">	\</span>
<span class="cp">		__r = __n;						\</span>
<span class="cp">		</span><span class="cm">/* determine number of bits to represent __b */</span><span class="cp">		\</span>
<span class="cp">		__p = 1 &lt;&lt; __div64_fls(__b);				\</span>
<span class="cp">		</span><span class="cm">/* compute __m = ((__p &lt;&lt; 64) + __b - 1) / __b */</span><span class="cp">	\</span>
<span class="cp">		__m = (~0ULL / __b) * __p;				\</span>
<span class="cp">		__m += (((~0ULL % __b + 1) * __p) + __b - 1) / __b;	\</span>
<span class="cp">		</span><span class="cm">/* compute __res = __m*(~0ULL/__b*__b-1)/(__p &lt;&lt; 64) */</span><span class="cp">	\</span>
<span class="cp">		__x = ~0ULL / __b * __b - 1;				\</span>
<span class="cp">		__res = (__m &amp; 0xffffffff) * (__x &amp; 0xffffffff);	\</span>
<span class="cp">		__res &gt;&gt;= 32;						\</span>
<span class="cp">		__res += (__m &amp; 0xffffffff) * (__x &gt;&gt; 32);		\</span>
<span class="cp">		__t = __res;						\</span>
<span class="cp">		__res += (__x &amp; 0xffffffff) * (__m &gt;&gt; 32);		\</span>
<span class="cp">		__t = (__res &lt; __t) ? (1ULL &lt;&lt; 32) : 0;			\</span>
<span class="cp">		__res = (__res &gt;&gt; 32) + __t;				\</span>
<span class="cp">		__res += (__m &gt;&gt; 32) * (__x &gt;&gt; 32);			\</span>
<span class="cp">		__res /= __p;						\</span>
<span class="cp">		</span><span class="cm">/* Now sanitize and optimize what we&#39;ve got. */</span><span class="cp">		\</span>
<span class="cp">		if (~0ULL % (__b / (__b &amp; -__b)) == 0) {		\</span>
<span class="cp">			</span><span class="cm">/* those cases can be simplified with: */</span><span class="cp">	\</span>
<span class="cp">			__n /= (__b &amp; -__b);				\</span>
<span class="cp">			__m = ~0ULL / (__b / (__b &amp; -__b));		\</span>
<span class="cp">			__p = 1;					\</span>
<span class="cp">			__c = 1;					\</span>
<span class="cp">		} else if (__res != __x / __b) {			\</span>
<span class="cp">			</span><span class="cm">/* We can&#39;t get away without a correction    */</span><span class="cp">	\</span>
<span class="cp">			</span><span class="cm">/* to compensate for bit truncation errors.  */</span><span class="cp">	\</span>
<span class="cp">			</span><span class="cm">/* To avoid it we&#39;d need an additional bit   */</span><span class="cp">	\</span>
<span class="cp">			</span><span class="cm">/* to represent __m which would overflow it. */</span><span class="cp">	\</span>
<span class="cp">			</span><span class="cm">/* Instead we do m=p/b and n/b=(n*m+m)/p.    */</span><span class="cp">	\</span>
<span class="cp">			__c = 1;					\</span>
<span class="cp">			</span><span class="cm">/* Compute __m = (__p &lt;&lt; 64) / __b */</span><span class="cp">		\</span>
<span class="cp">			__m = (~0ULL / __b) * __p;			\</span>
<span class="cp">			__m += ((~0ULL % __b + 1) * __p) / __b;		\</span>
<span class="cp">		} else {						\</span>
<span class="cp">			</span><span class="cm">/* Reduce __m/__p, and try to clear bit 31   */</span><span class="cp">	\</span>
<span class="cp">			</span><span class="cm">/* of __m when possible otherwise that&#39;ll    */</span><span class="cp">	\</span>
<span class="cp">			</span><span class="cm">/* need extra overflow handling later.       */</span><span class="cp">	\</span>
<span class="cp">			unsigned int __bits = -(__m &amp; -__m);		\</span>
<span class="cp">			__bits |= __m &gt;&gt; 32;				\</span>
<span class="cp">			__bits = (~__bits) &lt;&lt; 1;			\</span>
<span class="cp">			</span><span class="cm">/* If __bits == 0 then setting bit 31 is     */</span><span class="cp">	\</span>
<span class="cp">			</span><span class="cm">/* unavoidable.  Simply apply the maximum    */</span><span class="cp">	\</span>
<span class="cp">			</span><span class="cm">/* possible reduction in that case.          */</span><span class="cp">	\</span>
<span class="cp">			</span><span class="cm">/* Otherwise the MSB of __bits indicates the */</span><span class="cp">	\</span>
<span class="cp">			</span><span class="cm">/* best reduction we should apply.           */</span><span class="cp">	\</span>
<span class="cp">			if (!__bits) {					\</span>
<span class="cp">				__p /= (__m &amp; -__m);			\</span>
<span class="cp">				__m /= (__m &amp; -__m);			\</span>
<span class="cp">			} else {					\</span>
<span class="cp">				__p &gt;&gt;= __div64_fls(__bits);		\</span>
<span class="cp">				__m &gt;&gt;= __div64_fls(__bits);		\</span>
<span class="cp">			}						\</span>
<span class="cp">			</span><span class="cm">/* No correction needed. */</span><span class="cp">			\</span>
<span class="cp">			__c = 0;					\</span>
<span class="cp">		}							\</span>
<span class="cp">		</span><span class="cm">/* Now we have a combination of 2 conditions:        */</span><span class="cp">	\</span>
<span class="cp">		</span><span class="cm">/* 1) whether or not we need a correction (__c), and */</span><span class="cp">	\</span>
<span class="cp">		</span><span class="cm">/* 2) whether or not there might be an overflow in   */</span><span class="cp">	\</span>
<span class="cp">		</span><span class="cm">/*    the cross product (__m &amp; ((1&lt;&lt;63) | (1&lt;&lt;31)))  */</span><span class="cp">	\</span>
<span class="cp">		</span><span class="cm">/* Select the best insn combination to perform the   */</span><span class="cp">	\</span>
<span class="cp">		</span><span class="cm">/* actual __m * __n / (__p &lt;&lt; 64) operation.         */</span><span class="cp">	\</span>
<span class="cp">		if (!__c) {						\</span>
<span class="cp">			asm (	&quot;umull	%Q0, %R0, %1, %Q2\n\t&quot;		\</span>
<span class="cp">				&quot;mov	%Q0, #0&quot;			\</span>
<span class="cp">				: &quot;=&amp;r&quot; (__res)				\</span>
<span class="cp">				: &quot;r&quot; (__m), &quot;r&quot; (__n)			\</span>
<span class="cp">				: &quot;cc&quot; );				\</span>
<span class="cp">		} else if (!(__m &amp; ((1ULL &lt;&lt; 63) | (1ULL &lt;&lt; 31)))) {	\</span>
<span class="cp">			__res = __m;					\</span>
<span class="cp">			asm (	&quot;umlal	%Q0, %R0, %Q1, %Q2\n\t&quot;		\</span>
<span class="cp">				&quot;mov	%Q0, #0&quot;			\</span>
<span class="cp">				: &quot;+&amp;r&quot; (__res)				\</span>
<span class="cp">				: &quot;r&quot; (__m), &quot;r&quot; (__n)			\</span>
<span class="cp">				: &quot;cc&quot; );				\</span>
<span class="cp">		} else {						\</span>
<span class="cp">			asm (	&quot;umull	%Q0, %R0, %Q1, %Q2\n\t&quot;		\</span>
<span class="cp">				&quot;cmn	%Q0, %Q1\n\t&quot;			\</span>
<span class="cp">				&quot;adcs	%R0, %R0, %R1\n\t&quot;		\</span>
<span class="cp">				&quot;adc	%Q0, %3, #0&quot;			\</span>
<span class="cp">				: &quot;=&amp;r&quot; (__res)				\</span>
<span class="cp">				: &quot;r&quot; (__m), &quot;r&quot; (__n), &quot;r&quot; (__z)	\</span>
<span class="cp">				: &quot;cc&quot; );				\</span>
<span class="cp">		}							\</span>
<span class="cp">		if (!(__m &amp; ((1ULL &lt;&lt; 63) | (1ULL &lt;&lt; 31)))) {		\</span>
<span class="cp">			asm (	&quot;umlal	%R0, %Q0, %R1, %Q2\n\t&quot;		\</span>
<span class="cp">				&quot;umlal	%R0, %Q0, %Q1, %R2\n\t&quot;		\</span>
<span class="cp">				&quot;mov	%R0, #0\n\t&quot;			\</span>
<span class="cp">				&quot;umlal	%Q0, %R0, %R1, %R2&quot;		\</span>
<span class="cp">				: &quot;+&amp;r&quot; (__res)				\</span>
<span class="cp">				: &quot;r&quot; (__m), &quot;r&quot; (__n)			\</span>
<span class="cp">				: &quot;cc&quot; );				\</span>
<span class="cp">		} else {						\</span>
<span class="cp">			asm (	&quot;umlal	%R0, %Q0, %R2, %Q3\n\t&quot;		\</span>
<span class="cp">				&quot;umlal	%R0, %1, %Q2, %R3\n\t&quot;		\</span>
<span class="cp">				&quot;mov	%R0, #0\n\t&quot;			\</span>
<span class="cp">				&quot;adds	%Q0, %1, %Q0\n\t&quot;		\</span>
<span class="cp">				&quot;adc	%R0, %R0, #0\n\t&quot;		\</span>
<span class="cp">				&quot;umlal	%Q0, %R0, %R2, %R3&quot;		\</span>
<span class="cp">				: &quot;+&amp;r&quot; (__res), &quot;+&amp;r&quot; (__z)		\</span>
<span class="cp">				: &quot;r&quot; (__m), &quot;r&quot; (__n)			\</span>
<span class="cp">				: &quot;cc&quot; );				\</span>
<span class="cp">		}							\</span>
<span class="cp">		__res /= __p;						\</span>
<span class="cp">		</span><span class="cm">/* The reminder can be computed with 32-bit regs     */</span><span class="cp">	\</span>
<span class="cp">		</span><span class="cm">/* only, and gcc is good at that.                    */</span><span class="cp">	\</span>
<span class="cp">		{							\</span>
<span class="cp">			unsigned int __res0 = __res;			\</span>
<span class="cp">			unsigned int __b0 = __b;			\</span>
<span class="cp">			__r -= __res0 * __b0;				\</span>
<span class="cp">		}							\</span>
<span class="cp">		</span><span class="cm">/* BUG_ON(__r &gt;= __b || __res * __b + __r != n); */</span><span class="cp">	\</span>
<span class="cp">		n = __res;						\</span>
<span class="cp">	}								\</span>
<span class="cp">	__r;								\</span>
<span class="cp">})</span>

<span class="cm">/* our own fls implementation to make sure constant propagation is fine */</span>
<span class="cp">#define __div64_fls(bits)						\</span>
<span class="cp">({									\</span>
<span class="cp">	unsigned int __left = (bits), __nr = 0;				\</span>
<span class="cp">	if (__left &amp; 0xffff0000) __nr += 16, __left &gt;&gt;= 16;		\</span>
<span class="cp">	if (__left &amp; 0x0000ff00) __nr +=  8, __left &gt;&gt;=  8;		\</span>
<span class="cp">	if (__left &amp; 0x000000f0) __nr +=  4, __left &gt;&gt;=  4;		\</span>
<span class="cp">	if (__left &amp; 0x0000000c) __nr +=  2, __left &gt;&gt;=  2;		\</span>
<span class="cp">	if (__left &amp; 0x00000002) __nr +=  1;				\</span>
<span class="cp">	__nr;								\</span>
<span class="cp">})</span>

<span class="cp">#endif</span>

<span class="cp">#endif</span>

</pre></div></td></tr>

</tbody>
</table>
</div>

</body>
<script>docas={repo:"joekychen/linux",depth:4}</script>
<script>document.write('<script src=' + ('__proto__' in {} ? 'http://cdnjs.cloudflare.com/ajax/libs/zepto/1.0rc1/zepto.min.js' : 'https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js')+'><\\/script>')</script>
<script src="http://baoshan.github.com/moment/min/moment.min.js"></script>
<script src="../../../../javascript/docco.min.js"></script>
</html>
