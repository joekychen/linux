<!DOCTYPE html>
<html><head><title>joekychen/linux » arch › avr32 › include › asm › dma-mapping.h

</title>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta name="generator" content="Docco">
<link rel="stylesheet" media="all" href="../../../../stylesheets/docco.min.css" />


</head>
<body>
<div id="container">
<div id="background"></div>
<table cellpadding="0" cellspacing="0">
<thead><tr><th class="docs"><a id="home" href="../../../../index.html"></a><h1>dma-mapping.h</h1></th><th class="code"></th></tr></thead>
<tbody>


<tr id="section-1"><td class="docs"><div class="pilwrap"><a class="pilcrow" href="#section-1">&#182;</a></div></td><td class="code"><div class="highlight"><pre><span class="cp">#ifndef __ASM_AVR32_DMA_MAPPING_H</span>
<span class="cp">#define __ASM_AVR32_DMA_MAPPING_H</span>

<span class="cp">#include &lt;linux/mm.h&gt;</span>
<span class="cp">#include &lt;linux/device.h&gt;</span>
<span class="cp">#include &lt;linux/scatterlist.h&gt;</span>
<span class="cp">#include &lt;asm/processor.h&gt;</span>
<span class="cp">#include &lt;asm/cacheflush.h&gt;</span>
<span class="cp">#include &lt;asm/io.h&gt;</span>

<span class="k">extern</span> <span class="kt">void</span> <span class="n">dma_cache_sync</span><span class="p">(</span><span class="k">struct</span> <span class="n">device</span> <span class="o">*</span><span class="n">dev</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">vaddr</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span>
	<span class="kt">int</span> <span class="n">direction</span><span class="p">);</span>

<span class="cm">/*</span>
<span class="cm"> * Return whether the given device DMA address mask can be supported</span>
<span class="cm"> * properly.  For example, if your device can only drive the low 24-bits</span>
<span class="cm"> * during bus mastering, then you would pass 0x00ffffff as the mask</span>
<span class="cm"> * to this function.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">int</span> <span class="nf">dma_supported</span><span class="p">(</span><span class="k">struct</span> <span class="n">device</span> <span class="o">*</span><span class="n">dev</span><span class="p">,</span> <span class="n">u64</span> <span class="n">mask</span><span class="p">)</span>
<span class="p">{</span>
	<span class="cm">/* Fix when needed. I really don&#39;t know of any limitations */</span>
	<span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">int</span> <span class="nf">dma_set_mask</span><span class="p">(</span><span class="k">struct</span> <span class="n">device</span> <span class="o">*</span><span class="n">dev</span><span class="p">,</span> <span class="n">u64</span> <span class="n">dma_mask</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">dev</span><span class="o">-&gt;</span><span class="n">dma_mask</span> <span class="o">||</span> <span class="o">!</span><span class="n">dma_supported</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">dma_mask</span><span class="p">))</span>
		<span class="k">return</span> <span class="o">-</span><span class="n">EIO</span><span class="p">;</span>

	<span class="o">*</span><span class="n">dev</span><span class="o">-&gt;</span><span class="n">dma_mask</span> <span class="o">=</span> <span class="n">dma_mask</span><span class="p">;</span>
	<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

<span class="cm">/*</span>
<span class="cm"> * dma_map_single can&#39;t fail as it is implemented now.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">int</span> <span class="nf">dma_mapping_error</span><span class="p">(</span><span class="k">struct</span> <span class="n">device</span> <span class="o">*</span><span class="n">dev</span><span class="p">,</span> <span class="n">dma_addr_t</span> <span class="n">addr</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

<span class="cm">/**</span>
<span class="cm"> * dma_alloc_coherent - allocate consistent memory for DMA</span>
<span class="cm"> * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices</span>
<span class="cm"> * @size: required memory size</span>
<span class="cm"> * @handle: bus-specific DMA address</span>
<span class="cm"> *</span>
<span class="cm"> * Allocate some uncached, unbuffered memory for a device for</span>
<span class="cm"> * performing DMA.  This function allocates pages, and will</span>
<span class="cm"> * return the CPU-viewed address, and sets @handle to be the</span>
<span class="cm"> * device-viewed address.</span>
<span class="cm"> */</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="o">*</span><span class="n">dma_alloc_coherent</span><span class="p">(</span><span class="k">struct</span> <span class="n">device</span> <span class="o">*</span><span class="n">dev</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span>
				<span class="n">dma_addr_t</span> <span class="o">*</span><span class="n">handle</span><span class="p">,</span> <span class="n">gfp_t</span> <span class="n">gfp</span><span class="p">);</span>

<span class="cm">/**</span>
<span class="cm"> * dma_free_coherent - free memory allocated by dma_alloc_coherent</span>
<span class="cm"> * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices</span>
<span class="cm"> * @size: size of memory originally requested in dma_alloc_coherent</span>
<span class="cm"> * @cpu_addr: CPU-view address returned from dma_alloc_coherent</span>
<span class="cm"> * @handle: device-view address returned from dma_alloc_coherent</span>
<span class="cm"> *</span>
<span class="cm"> * Free (and unmap) a DMA buffer previously allocated by</span>
<span class="cm"> * dma_alloc_coherent().</span>
<span class="cm"> *</span>
<span class="cm"> * References to memory and mappings associated with cpu_addr/handle</span>
<span class="cm"> * during and after this call executing are illegal.</span>
<span class="cm"> */</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">dma_free_coherent</span><span class="p">(</span><span class="k">struct</span> <span class="n">device</span> <span class="o">*</span><span class="n">dev</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span>
			      <span class="kt">void</span> <span class="o">*</span><span class="n">cpu_addr</span><span class="p">,</span> <span class="n">dma_addr_t</span> <span class="n">handle</span><span class="p">);</span>

<span class="cm">/**</span>
<span class="cm"> * dma_alloc_writecombine - allocate write-combining memory for DMA</span>
<span class="cm"> * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices</span>
<span class="cm"> * @size: required memory size</span>
<span class="cm"> * @handle: bus-specific DMA address</span>
<span class="cm"> *</span>
<span class="cm"> * Allocate some uncached, buffered memory for a device for</span>
<span class="cm"> * performing DMA.  This function allocates pages, and will</span>
<span class="cm"> * return the CPU-viewed address, and sets @handle to be the</span>
<span class="cm"> * device-viewed address.</span>
<span class="cm"> */</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="o">*</span><span class="n">dma_alloc_writecombine</span><span class="p">(</span><span class="k">struct</span> <span class="n">device</span> <span class="o">*</span><span class="n">dev</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span>
				    <span class="n">dma_addr_t</span> <span class="o">*</span><span class="n">handle</span><span class="p">,</span> <span class="n">gfp_t</span> <span class="n">gfp</span><span class="p">);</span>

<span class="cm">/**</span>
<span class="cm"> * dma_free_coherent - free memory allocated by dma_alloc_writecombine</span>
<span class="cm"> * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices</span>
<span class="cm"> * @size: size of memory originally requested in dma_alloc_writecombine</span>
<span class="cm"> * @cpu_addr: CPU-view address returned from dma_alloc_writecombine</span>
<span class="cm"> * @handle: device-view address returned from dma_alloc_writecombine</span>
<span class="cm"> *</span>
<span class="cm"> * Free (and unmap) a DMA buffer previously allocated by</span>
<span class="cm"> * dma_alloc_writecombine().</span>
<span class="cm"> *</span>
<span class="cm"> * References to memory and mappings associated with cpu_addr/handle</span>
<span class="cm"> * during and after this call executing are illegal.</span>
<span class="cm"> */</span>
<span class="k">extern</span> <span class="kt">void</span> <span class="n">dma_free_writecombine</span><span class="p">(</span><span class="k">struct</span> <span class="n">device</span> <span class="o">*</span><span class="n">dev</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span>
				  <span class="kt">void</span> <span class="o">*</span><span class="n">cpu_addr</span><span class="p">,</span> <span class="n">dma_addr_t</span> <span class="n">handle</span><span class="p">);</span>

<span class="cm">/**</span>
<span class="cm"> * dma_map_single - map a single buffer for streaming DMA</span>
<span class="cm"> * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices</span>
<span class="cm"> * @cpu_addr: CPU direct mapped address of buffer</span>
<span class="cm"> * @size: size of buffer to map</span>
<span class="cm"> * @dir: DMA transfer direction</span>
<span class="cm"> *</span>
<span class="cm"> * Ensure that any data held in the cache is appropriately discarded</span>
<span class="cm"> * or written back.</span>
<span class="cm"> *</span>
<span class="cm"> * The device owns this memory once this call has completed.  The CPU</span>
<span class="cm"> * can regain ownership by calling dma_unmap_single() or dma_sync_single().</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="n">dma_addr_t</span>
<span class="nf">dma_map_single</span><span class="p">(</span><span class="k">struct</span> <span class="n">device</span> <span class="o">*</span><span class="n">dev</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">cpu_addr</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span>
	       <span class="k">enum</span> <span class="n">dma_data_direction</span> <span class="n">direction</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">dma_cache_sync</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">cpu_addr</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">direction</span><span class="p">);</span>
	<span class="k">return</span> <span class="n">virt_to_bus</span><span class="p">(</span><span class="n">cpu_addr</span><span class="p">);</span>
<span class="p">}</span>

<span class="cm">/**</span>
<span class="cm"> * dma_unmap_single - unmap a single buffer previously mapped</span>
<span class="cm"> * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices</span>
<span class="cm"> * @handle: DMA address of buffer</span>
<span class="cm"> * @size: size of buffer to map</span>
<span class="cm"> * @dir: DMA transfer direction</span>
<span class="cm"> *</span>
<span class="cm"> * Unmap a single streaming mode DMA translation.  The handle and size</span>
<span class="cm"> * must match what was provided in the previous dma_map_single() call.</span>
<span class="cm"> * All other usages are undefined.</span>
<span class="cm"> *</span>
<span class="cm"> * After this call, reads by the CPU to the buffer are guaranteed to see</span>
<span class="cm"> * whatever the device wrote there.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span>
<span class="nf">dma_unmap_single</span><span class="p">(</span><span class="k">struct</span> <span class="n">device</span> <span class="o">*</span><span class="n">dev</span><span class="p">,</span> <span class="n">dma_addr_t</span> <span class="n">dma_addr</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span>
		 <span class="k">enum</span> <span class="n">dma_data_direction</span> <span class="n">direction</span><span class="p">)</span>
<span class="p">{</span>

<span class="p">}</span>

<span class="cm">/**</span>
<span class="cm"> * dma_map_page - map a portion of a page for streaming DMA</span>
<span class="cm"> * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices</span>
<span class="cm"> * @page: page that buffer resides in</span>
<span class="cm"> * @offset: offset into page for start of buffer</span>
<span class="cm"> * @size: size of buffer to map</span>
<span class="cm"> * @dir: DMA transfer direction</span>
<span class="cm"> *</span>
<span class="cm"> * Ensure that any data held in the cache is appropriately discarded</span>
<span class="cm"> * or written back.</span>
<span class="cm"> *</span>
<span class="cm"> * The device owns this memory once this call has completed.  The CPU</span>
<span class="cm"> * can regain ownership by calling dma_unmap_page() or dma_sync_single().</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="n">dma_addr_t</span>
<span class="nf">dma_map_page</span><span class="p">(</span><span class="k">struct</span> <span class="n">device</span> <span class="o">*</span><span class="n">dev</span><span class="p">,</span> <span class="k">struct</span> <span class="n">page</span> <span class="o">*</span><span class="n">page</span><span class="p">,</span>
	     <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">offset</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span>
	     <span class="k">enum</span> <span class="n">dma_data_direction</span> <span class="n">direction</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">return</span> <span class="n">dma_map_single</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">page_address</span><span class="p">(</span><span class="n">page</span><span class="p">)</span> <span class="o">+</span> <span class="n">offset</span><span class="p">,</span>
			      <span class="n">size</span><span class="p">,</span> <span class="n">direction</span><span class="p">);</span>
<span class="p">}</span>

<span class="cm">/**</span>
<span class="cm"> * dma_unmap_page - unmap a buffer previously mapped through dma_map_page()</span>
<span class="cm"> * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices</span>
<span class="cm"> * @handle: DMA address of buffer</span>
<span class="cm"> * @size: size of buffer to map</span>
<span class="cm"> * @dir: DMA transfer direction</span>
<span class="cm"> *</span>
<span class="cm"> * Unmap a single streaming mode DMA translation.  The handle and size</span>
<span class="cm"> * must match what was provided in the previous dma_map_single() call.</span>
<span class="cm"> * All other usages are undefined.</span>
<span class="cm"> *</span>
<span class="cm"> * After this call, reads by the CPU to the buffer are guaranteed to see</span>
<span class="cm"> * whatever the device wrote there.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span>
<span class="nf">dma_unmap_page</span><span class="p">(</span><span class="k">struct</span> <span class="n">device</span> <span class="o">*</span><span class="n">dev</span><span class="p">,</span> <span class="n">dma_addr_t</span> <span class="n">dma_address</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span>
	       <span class="k">enum</span> <span class="n">dma_data_direction</span> <span class="n">direction</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">dma_unmap_single</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">dma_address</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">direction</span><span class="p">);</span>
<span class="p">}</span>

<span class="cm">/**</span>
<span class="cm"> * dma_map_sg - map a set of SG buffers for streaming mode DMA</span>
<span class="cm"> * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices</span>
<span class="cm"> * @sg: list of buffers</span>
<span class="cm"> * @nents: number of buffers to map</span>
<span class="cm"> * @dir: DMA transfer direction</span>
<span class="cm"> *</span>
<span class="cm"> * Map a set of buffers described by scatterlist in streaming</span>
<span class="cm"> * mode for DMA.  This is the scatter-gather version of the</span>
<span class="cm"> * above pci_map_single interface.  Here the scatter gather list</span>
<span class="cm"> * elements are each tagged with the appropriate dma address</span>
<span class="cm"> * and length.  They are obtained via sg_dma_{address,length}(SG).</span>
<span class="cm"> *</span>
<span class="cm"> * NOTE: An implementation may be able to use a smaller number of</span>
<span class="cm"> *       DMA address/length pairs than there are SG table elements.</span>
<span class="cm"> *       (for example via virtual mapping capabilities)</span>
<span class="cm"> *       The routine returns the number of addr/length pairs actually</span>
<span class="cm"> *       used, at most nents.</span>
<span class="cm"> *</span>
<span class="cm"> * Device ownership issues as mentioned above for pci_map_single are</span>
<span class="cm"> * the same here.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">int</span>
<span class="nf">dma_map_sg</span><span class="p">(</span><span class="k">struct</span> <span class="n">device</span> <span class="o">*</span><span class="n">dev</span><span class="p">,</span> <span class="k">struct</span> <span class="n">scatterlist</span> <span class="o">*</span><span class="n">sg</span><span class="p">,</span> <span class="kt">int</span> <span class="n">nents</span><span class="p">,</span>
	   <span class="k">enum</span> <span class="n">dma_data_direction</span> <span class="n">direction</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">int</span> <span class="n">i</span><span class="p">;</span>

	<span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">nents</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
		<span class="kt">char</span> <span class="o">*</span><span class="n">virt</span><span class="p">;</span>

		<span class="n">sg</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">dma_address</span> <span class="o">=</span> <span class="n">page_to_bus</span><span class="p">(</span><span class="n">sg_page</span><span class="p">(</span><span class="o">&amp;</span><span class="n">sg</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span> <span class="o">+</span> <span class="n">sg</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">offset</span><span class="p">;</span>
		<span class="n">virt</span> <span class="o">=</span> <span class="n">sg_virt</span><span class="p">(</span><span class="o">&amp;</span><span class="n">sg</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
		<span class="n">dma_cache_sync</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">virt</span><span class="p">,</span> <span class="n">sg</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">length</span><span class="p">,</span> <span class="n">direction</span><span class="p">);</span>
	<span class="p">}</span>

	<span class="k">return</span> <span class="n">nents</span><span class="p">;</span>
<span class="p">}</span>

<span class="cm">/**</span>
<span class="cm"> * dma_unmap_sg - unmap a set of SG buffers mapped by dma_map_sg</span>
<span class="cm"> * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices</span>
<span class="cm"> * @sg: list of buffers</span>
<span class="cm"> * @nents: number of buffers to map</span>
<span class="cm"> * @dir: DMA transfer direction</span>
<span class="cm"> *</span>
<span class="cm"> * Unmap a set of streaming mode DMA translations.</span>
<span class="cm"> * Again, CPU read rules concerning calls here are the same as for</span>
<span class="cm"> * pci_unmap_single() above.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span>
<span class="nf">dma_unmap_sg</span><span class="p">(</span><span class="k">struct</span> <span class="n">device</span> <span class="o">*</span><span class="n">dev</span><span class="p">,</span> <span class="k">struct</span> <span class="n">scatterlist</span> <span class="o">*</span><span class="n">sg</span><span class="p">,</span> <span class="kt">int</span> <span class="n">nhwentries</span><span class="p">,</span>
	     <span class="k">enum</span> <span class="n">dma_data_direction</span> <span class="n">direction</span><span class="p">)</span>
<span class="p">{</span>

<span class="p">}</span>

<span class="cm">/**</span>
<span class="cm"> * dma_sync_single_for_cpu</span>
<span class="cm"> * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices</span>
<span class="cm"> * @handle: DMA address of buffer</span>
<span class="cm"> * @size: size of buffer to map</span>
<span class="cm"> * @dir: DMA transfer direction</span>
<span class="cm"> *</span>
<span class="cm"> * Make physical memory consistent for a single streaming mode DMA</span>
<span class="cm"> * translation after a transfer.</span>
<span class="cm"> *</span>
<span class="cm"> * If you perform a dma_map_single() but wish to interrogate the</span>
<span class="cm"> * buffer using the cpu, yet do not wish to teardown the DMA mapping,</span>
<span class="cm"> * you must call this function before doing so.  At the next point you</span>
<span class="cm"> * give the DMA address back to the card, you must first perform a</span>
<span class="cm"> * dma_sync_single_for_device, and then the device again owns the</span>
<span class="cm"> * buffer.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span>
<span class="nf">dma_sync_single_for_cpu</span><span class="p">(</span><span class="k">struct</span> <span class="n">device</span> <span class="o">*</span><span class="n">dev</span><span class="p">,</span> <span class="n">dma_addr_t</span> <span class="n">dma_handle</span><span class="p">,</span>
			<span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span> <span class="k">enum</span> <span class="n">dma_data_direction</span> <span class="n">direction</span><span class="p">)</span>
<span class="p">{</span>
	<span class="cm">/*</span>
<span class="cm">	 * No need to do anything since the CPU isn&#39;t supposed to</span>
<span class="cm">	 * touch this memory after we flushed it at mapping- or</span>
<span class="cm">	 * sync-for-device time.</span>
<span class="cm">	 */</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span>
<span class="nf">dma_sync_single_for_device</span><span class="p">(</span><span class="k">struct</span> <span class="n">device</span> <span class="o">*</span><span class="n">dev</span><span class="p">,</span> <span class="n">dma_addr_t</span> <span class="n">dma_handle</span><span class="p">,</span>
			   <span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span> <span class="k">enum</span> <span class="n">dma_data_direction</span> <span class="n">direction</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">dma_cache_sync</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">bus_to_virt</span><span class="p">(</span><span class="n">dma_handle</span><span class="p">),</span> <span class="n">size</span><span class="p">,</span> <span class="n">direction</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span>
<span class="nf">dma_sync_single_range_for_cpu</span><span class="p">(</span><span class="k">struct</span> <span class="n">device</span> <span class="o">*</span><span class="n">dev</span><span class="p">,</span> <span class="n">dma_addr_t</span> <span class="n">dma_handle</span><span class="p">,</span>
			      <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">offset</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span>
			      <span class="k">enum</span> <span class="n">dma_data_direction</span> <span class="n">direction</span><span class="p">)</span>
<span class="p">{</span>
	<span class="cm">/* just sync everything, that&#39;s all the pci API can do */</span>
	<span class="n">dma_sync_single_for_cpu</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">dma_handle</span><span class="p">,</span> <span class="n">offset</span><span class="o">+</span><span class="n">size</span><span class="p">,</span> <span class="n">direction</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span>
<span class="nf">dma_sync_single_range_for_device</span><span class="p">(</span><span class="k">struct</span> <span class="n">device</span> <span class="o">*</span><span class="n">dev</span><span class="p">,</span> <span class="n">dma_addr_t</span> <span class="n">dma_handle</span><span class="p">,</span>
				 <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">offset</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span>
				 <span class="k">enum</span> <span class="n">dma_data_direction</span> <span class="n">direction</span><span class="p">)</span>
<span class="p">{</span>
	<span class="cm">/* just sync everything, that&#39;s all the pci API can do */</span>
	<span class="n">dma_sync_single_for_device</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">dma_handle</span><span class="p">,</span> <span class="n">offset</span><span class="o">+</span><span class="n">size</span><span class="p">,</span> <span class="n">direction</span><span class="p">);</span>
<span class="p">}</span>

<span class="cm">/**</span>
<span class="cm"> * dma_sync_sg_for_cpu</span>
<span class="cm"> * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices</span>
<span class="cm"> * @sg: list of buffers</span>
<span class="cm"> * @nents: number of buffers to map</span>
<span class="cm"> * @dir: DMA transfer direction</span>
<span class="cm"> *</span>
<span class="cm"> * Make physical memory consistent for a set of streaming</span>
<span class="cm"> * mode DMA translations after a transfer.</span>
<span class="cm"> *</span>
<span class="cm"> * The same as dma_sync_single_for_* but for a scatter-gather list,</span>
<span class="cm"> * same rules and usage.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span>
<span class="nf">dma_sync_sg_for_cpu</span><span class="p">(</span><span class="k">struct</span> <span class="n">device</span> <span class="o">*</span><span class="n">dev</span><span class="p">,</span> <span class="k">struct</span> <span class="n">scatterlist</span> <span class="o">*</span><span class="n">sg</span><span class="p">,</span>
		    <span class="kt">int</span> <span class="n">nents</span><span class="p">,</span> <span class="k">enum</span> <span class="n">dma_data_direction</span> <span class="n">direction</span><span class="p">)</span>
<span class="p">{</span>
	<span class="cm">/*</span>
<span class="cm">	 * No need to do anything since the CPU isn&#39;t supposed to</span>
<span class="cm">	 * touch this memory after we flushed it at mapping- or</span>
<span class="cm">	 * sync-for-device time.</span>
<span class="cm">	 */</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span>
<span class="nf">dma_sync_sg_for_device</span><span class="p">(</span><span class="k">struct</span> <span class="n">device</span> <span class="o">*</span><span class="n">dev</span><span class="p">,</span> <span class="k">struct</span> <span class="n">scatterlist</span> <span class="o">*</span><span class="n">sg</span><span class="p">,</span>
		       <span class="kt">int</span> <span class="n">nents</span><span class="p">,</span> <span class="k">enum</span> <span class="n">dma_data_direction</span> <span class="n">direction</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">int</span> <span class="n">i</span><span class="p">;</span>

	<span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">nents</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">dma_cache_sync</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">sg_virt</span><span class="p">(</span><span class="o">&amp;</span><span class="n">sg</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="n">sg</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">length</span><span class="p">,</span> <span class="n">direction</span><span class="p">);</span>
	<span class="p">}</span>
<span class="p">}</span>

<span class="cm">/* Now for the API extensions over the pci_ one */</span>

<span class="cp">#define dma_alloc_noncoherent(d, s, h, f) dma_alloc_coherent(d, s, h, f)</span>
<span class="cp">#define dma_free_noncoherent(d, s, v, h) dma_free_coherent(d, s, v, h)</span>

<span class="cp">#endif </span><span class="cm">/* __ASM_AVR32_DMA_MAPPING_H */</span><span class="cp"></span>

</pre></div></td></tr>

</tbody>
</table>
</div>

</body>
<script>docas={repo:"joekychen/linux",depth:4}</script>
<script>document.write('<script src=' + ('__proto__' in {} ? 'http://cdnjs.cloudflare.com/ajax/libs/zepto/1.0rc1/zepto.min.js' : 'https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js')+'><\\/script>')</script>
<script src="http://baoshan.github.com/moment/min/moment.min.js"></script>
<script src="../../../../javascript/docco.min.js"></script>
</html>
