f | rt.c | s | 46K | 1684 | Peter Zijlstra | a.p.zijlstra@chello.nl | 1338994346 |  | sched/rt: Fix lockdep annotation within find_lock_lowest_rq()  Roland Dreier reported spurious, hard to trigger lockdep warnings within the scheduler - without any real lockup.  This bit gives us the right clue:  > [89945.640512]  [<ffffffff8103fa1a>] double_lock_balance+0x5a/0x90 > [89945.640568]  [<ffffffff8104c546>] push_rt_task+0xc6/0x290  if you look at that code you'll find the double_lock_balance() in question is the one in find_lock_lowest_rq() [yay for inlining].  Now find_lock_lowest_rq() has a bug.. it fails to use double_unlock_balance() in one exit path, if this results in a retry in push_rt_task() we'll call double_lock_balance() again, at which point we'll run into said lockdep confusion.  Reported-by: Roland Dreier <roland@kernel.org> Acked-by: Steven Rostedt <rostedt@goodmis.org> Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl> Link: http://lkml.kernel.org/r/1337282386.4281.77.camel@twins Signed-off-by: Ingo Molnar <mingo@kernel.org>
f | fair.c | s | 130K | 4424 | Linus Torvalds | torvalds@linux-foundation.org | 1339192769 |  | Merge branch 'sched-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip  Pull scheduler fixes from Ingo Molnar.  * 'sched-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:   sched: Fix the relax_domain_level boot parameter   sched: Validate assumptions in sched_init_numa()   sched: Always initialize cpu-power   sched: Fix domain iteration   sched/rt: Fix lockdep annotation within find_lock_lowest_rq()   sched/numa: Load balance between remote nodes   sched/x86: Calculate booted cores after construction of sibling_mask
f | features.h | s | 1.9K | 60 | Peter Zijlstra | a.p.zijlstra@chello.nl | 1335437692 |  | sched: Fix more load-balancing fallout  Commits 367456c756a6 ("sched: Ditch per cgroup task lists for load-balancing") and 5d6523ebd ("sched: Fix load-balance wreckage") left some more wreckage.  By setting loop_max unconditionally to ->nr_running load-balancing could take a lot of time on very long runqueues (hackbench!). So keep the sysctl as max limit of the amount of tasks we'll iterate.  Furthermore, the min load filter for migration completely fails with cgroups since inequality in per-cpu state can easily lead to such small loads :/  Furthermore the change to add new tasks to the tail of the queue instead of the head seems to have some effect.. not quite sure I understand why.  Combined these fixes solve the huge hackbench regression reported by Tim when hackbench is ran in a cgroup.  Reported-by: Tim Chen <tim.c.chen@linux.intel.com> Acked-by: Tim Chen <tim.c.chen@linux.intel.com> Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl> Cc: Linus Torvalds <torvalds@linux-foundation.org> Cc: Andrew Morton <akpm@linux-foundation.org> Link: http://lkml.kernel.org/r/1335365763.28150.267.camel@twins [ got rid of the CONFIG_PREEMPT tuning and made small readability edits ] Signed-off-by: Ingo Molnar <mingo@kernel.org>
f | Makefile | g | 776B |  | Thomas Gleixner | tglx@linutronix.de | 1336215621 |  | init_task: Create generic init_task instance  All archs define init_task in the same way (except ia64, but there is no particular reason why ia64 cannot use the common version). Create a generic instance so all archs can be converted over.  The config switch is temporary and will be removed when all archs are converted over.  Signed-off-by: Thomas Gleixner <tglx@linutronix.de> Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org> Cc: Chen Liqin <liqin.chen@sunplusct.com> Cc: Chris Metcalf <cmetcalf@tilera.com> Cc: Chris Zankel <chris@zankel.net> Cc: David Howells <dhowells@redhat.com> Cc: David S. Miller <davem@davemloft.net> Cc: Geert Uytterhoeven <geert@linux-m68k.org> Cc: Guan Xuetao <gxt@mprc.pku.edu.cn> Cc: Haavard Skinnemoen <hskinnemoen@gmail.com> Cc: Hirokazu Takata <takata@linux-m32r.org> Cc: James E.J. Bottomley <jejb@parisc-linux.org> Cc: Jesper Nilsson <jesper.nilsson@axis.com> Cc: Jonas Bonn <jonas@southpole.se> Cc: Mark Salter <msalter@redhat.com> Cc: Martin Schwidefsky <schwidefsky@de.ibm.com> Cc: Heiko Carstens <heiko.carstens@de.ibm.com> Cc: Matt Turner <mattst88@gmail.com> Cc: Michal Simek <monstr@monstr.eu> Cc: Mike Frysinger <vapier@gentoo.org> Cc: Paul Mundt <lethal@linux-sh.org> Cc: Ralf Baechle <ralf@linux-mips.org> Cc: Richard Kuo <rkuo@codeaurora.org> Cc: Richard Weinberger <richard@nod.at> Cc: Russell King <linux@arm.linux.org.uk> Cc: Yoshinori Sato <ysato@users.sourceforge.jp> Link: http://lkml.kernel.org/r/20120503085034.092585287@linutronix.de
f | debug.c | s | 11K | 440 | Peter Zijlstra | a.p.zijlstra@chello.nl | 1337000728 |  | sched/debug: Fix printing large integers on 32-bit platforms  Some numbers like nr_running and nr_uninterruptible are fundamentally unsigned since its impossible to have a negative amount of tasks, yet we still print them as signed to easily recognise the underflow condition.  rq->nr_uninterruptible has 'special' accounting and can in fact very easily become negative on a per-cpu basis.  It was noted that since the P() macro assumes things are long long and the promotion of unsigned 'int/long' to long long on 32bit doesn't sign extend we print silly large numbers instead of the easier to read signed numbers.  Therefore extend the P() macro to not require the sign extention.  Reported-by: Diwakar Tundlam <dtundlam@nvidia.com> Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl> Link: http://lkml.kernel.org/n/tip-gk5tm8t2n4ix2vkpns42uqqp@git.kernel.org Signed-off-by: Ingo Molnar <mingo@kernel.org>
f | idle_task.c | s | 2.1K | 81 | Hiroshi Shimamoto | h-shimamoto@ct.jp.nec.com | 1336395858 |  | sched: Update documentation and comments  Change sched_*.c to sched/*.c in documentation and comments.  Signed-off-by: Hiroshi Shimamoto <h-shimamoto@ct.jp.nec.com> Cc: Peter Zijlstra <a.p.zijlstra@chello.nl> Link: http://lkml.kernel.org/r/4F795CAC.9080206@ct.jp.nec.com Signed-off-by: Ingo Molnar <mingo@kernel.org>
f | auto_group.h | s | 1.5K | 50 | Peter Zijlstra | a.p.zijlstra@chello.nl | 1321528822 |  | sched: Move all scheduler bits into kernel/sched/  There's too many sched*.[ch] files in kernel/, give them their own directory.  (No code changed, other than Makefile glue added.)  Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl> Signed-off-by: Ingo Molnar <mingo@elte.hu>
f | cpupri.h | s | 791B | 27 | Peter Zijlstra | a.p.zijlstra@chello.nl | 1321528822 |  | sched: Move all scheduler bits into kernel/sched/  There's too many sched*.[ch] files in kernel/, give them their own directory.  (No code changed, other than Makefile glue added.)  Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl> Signed-off-by: Ingo Molnar <mingo@elte.hu>
f | stats.c | s | 2.7K | 97 | Rakib Mullick | rakib.mullick@gmail.com | 1327667333 |  | sched: Remove sched_switch  Currently we don't utilize the sched_switch field anymore.  But, simply removing sched_switch field from the middle of the sched_stat output will break tools.  So, to stay compatible we hardcode it to zero and remove the field from the scheduler data structures.  Update the schedstat documentation accordingly.  Signed-off-by: Rakib Mullick <rakib.mullick@gmail.com> Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl> Link: http://lkml.kernel.org/r/1327422836.27181.5.camel@localhost.localdomain Signed-off-by: Ingo Molnar <mingo@elte.hu>
f | stats.h | s | 6.6K | 203 | Martin Schwidefsky | schwidefsky@de.ibm.com | 1324318995 |  | Merge branch 'sched/core' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip into cputime-tip  Conflicts: 	drivers/cpufreq/cpufreq_conservative.c 	drivers/cpufreq/cpufreq_ondemand.c 	drivers/macintosh/rack-meter.c 	fs/proc/stat.c 	fs/proc/uptime.c 	kernel/sched/core.c
f | clock.c | s | 8.0K | 293 | Peter Zijlstra | a.p.zijlstra@chello.nl | 1321528822 |  | sched: Move all scheduler bits into kernel/sched/  There's too many sched*.[ch] files in kernel/, give them their own directory.  (No code changed, other than Makefile glue added.)  Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl> Signed-off-by: Ingo Molnar <mingo@elte.hu>
f | stop_task.c | s | 2.2K | 85 | Peter Zijlstra | a.p.zijlstra@chello.nl | 1321528822 |  | sched: Move all scheduler bits into kernel/sched/  There's too many sched*.[ch] files in kernel/, give them their own directory.  (No code changed, other than Makefile glue added.)  Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl> Signed-off-by: Ingo Molnar <mingo@elte.hu>
f | sched.h | s | 29K | 960 | Peter Zijlstra | a.p.zijlstra@chello.nl | 1338994346 |  | sched: Fix domain iteration  Weird topologies can lead to asymmetric domain setups. This needs further consideration since these setups are typically non-minimal too.  For now, make it work by adding an extra mask selecting which CPUs are allowed to iterate up.  The topology that triggered it is the one from David Rientjes:  	10 20 20 30 	20 10 20 20 	20 20 10 20 	30 20 20 10  resulting in boxes that wouldn't even boot.  Reported-by: David Rientjes <rientjes@google.com> Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl> Link: http://lkml.kernel.org/n/tip-3p86l9cuaqnxz7uxsojmz5rm@git.kernel.org Signed-off-by: Ingo Molnar <mingo@kernel.org>
f | core.c | s | 199K | 7071 | Dimitri Sivanich | sivanich@sgi.com | 1338995261 |  | sched: Fix the relax_domain_level boot parameter  It does not get processed because sched_domain_level_max is 0 at the time that setup_relax_domain_level() is run.  Simply accept the value as it is, as we don't know the value of sched_domain_level_max until sched domain construction is completed.  Fix sched_relax_domain_level in cpuset.  The build_sched_domain() routine calls the set_domain_attribute() routine prior to setting the sd->level, however, the set_domain_attribute() routine relies on the sd->level to decide whether idle load balancing will be off/on.  Signed-off-by: Dimitri Sivanich <sivanich@sgi.com> Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl> Link: http://lkml.kernel.org/r/20120605184436.GA15668@sgi.com Signed-off-by: Ingo Molnar <mingo@kernel.org>
f | auto_group.c | s | 5.6K | 201 | Hiroshi Shimamoto | h-shimamoto@ct.jp.nec.com | 1330687429 |  | sched: Clean up parameter passing of proc_sched_autogroup_set_nice()  Pass nice as a value to proc_sched_autogroup_set_nice().  No side effect is expected, and the variable err will be overwritten with the return value.  Signed-off-by: Hiroshi Shimamoto <h-shimamoto@ct.jp.nec.com> Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl> Link: http://lkml.kernel.org/r/4F45FBB7.5090607@ct.jp.nec.com Signed-off-by: Ingo Molnar <mingo@elte.hu>
f | cpupri.c | s | 6.7K | 209 | Randy Dunlap | rdunlap@xenotime.net | 1327337094 |  | kernel-doc: fix kernel-doc warnings in sched  Fix new kernel-doc notation warnings:  Warning(include/linux/sched.h:2094): No description found for parameter 'p' Warning(include/linux/sched.h:2094): Excess function parameter 'tsk' description in 'is_idle_task' Warning(kernel/sched/cpupri.c:139): No description found for parameter 'newpri' Warning(kernel/sched/cpupri.c:139): Excess function parameter 'pri' description in 'cpupri_set' Warning(kernel/sched/cpupri.c:208): Excess function parameter 'bootmem' description in 'cpupri_init'  Signed-off-by: Randy Dunlap <rdunlap@xenotime.net> Cc:	Ingo Molnar <mingo@elte.hu> Cc:	Peter Zijlstra <peterz@infradead.org> Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
