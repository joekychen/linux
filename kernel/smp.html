<!DOCTYPE html>
<html><head><title>joekychen/linux » kernel › smp.c

</title>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta name="generator" content="Docco">
<link rel="stylesheet" media="all" href="../stylesheets/docco.min.css" />


</head>
<body>
<div id="container">
<div id="background"></div>
<table cellpadding="0" cellspacing="0">
<thead><tr><th class="docs"><a id="home" href="../index.html"></a><h1>smp.c</h1></th><th class="code"></th></tr></thead>
<tbody>


<tr id="section-1"><td class="docs"><div class="pilwrap"><a class="pilcrow" href="#section-1">&#182;</a></div></td><td class="code"><div class="highlight"><pre><span class="cm">/*</span>
<span class="cm"> * Generic helpers for smp ipi calls</span>
<span class="cm"> *</span>
<span class="cm"> * (C) Jens Axboe &lt;jens.axboe@oracle.com&gt; 2008</span>
<span class="cm"> */</span>
<span class="cp">#include &lt;linux/rcupdate.h&gt;</span>
<span class="cp">#include &lt;linux/rculist.h&gt;</span>
<span class="cp">#include &lt;linux/kernel.h&gt;</span>
<span class="cp">#include &lt;linux/export.h&gt;</span>
<span class="cp">#include &lt;linux/percpu.h&gt;</span>
<span class="cp">#include &lt;linux/init.h&gt;</span>
<span class="cp">#include &lt;linux/gfp.h&gt;</span>
<span class="cp">#include &lt;linux/smp.h&gt;</span>
<span class="cp">#include &lt;linux/cpu.h&gt;</span>

<span class="cp">#include &quot;smpboot.h&quot;</span>

<span class="cp">#ifdef CONFIG_USE_GENERIC_SMP_HELPERS</span>
<span class="k">static</span> <span class="k">struct</span> <span class="p">{</span>
	<span class="k">struct</span> <span class="n">list_head</span>	<span class="n">queue</span><span class="p">;</span>
	<span class="n">raw_spinlock_t</span>		<span class="n">lock</span><span class="p">;</span>
<span class="p">}</span> <span class="n">call_function</span> <span class="n">__cacheline_aligned_in_smp</span> <span class="o">=</span>
	<span class="p">{</span>
		<span class="p">.</span><span class="n">queue</span>		<span class="o">=</span> <span class="n">LIST_HEAD_INIT</span><span class="p">(</span><span class="n">call_function</span><span class="p">.</span><span class="n">queue</span><span class="p">),</span>
		<span class="p">.</span><span class="n">lock</span>		<span class="o">=</span> <span class="n">__RAW_SPIN_LOCK_UNLOCKED</span><span class="p">(</span><span class="n">call_function</span><span class="p">.</span><span class="n">lock</span><span class="p">),</span>
	<span class="p">};</span>

<span class="k">enum</span> <span class="p">{</span>
	<span class="n">CSD_FLAG_LOCK</span>		<span class="o">=</span> <span class="mh">0x01</span><span class="p">,</span>
<span class="p">};</span>

<span class="k">struct</span> <span class="n">call_function_data</span> <span class="p">{</span>
	<span class="k">struct</span> <span class="n">call_single_data</span>	<span class="n">csd</span><span class="p">;</span>
	<span class="n">atomic_t</span>		<span class="n">refs</span><span class="p">;</span>
	<span class="n">cpumask_var_t</span>		<span class="n">cpumask</span><span class="p">;</span>
<span class="p">};</span>

<span class="k">static</span> <span class="n">DEFINE_PER_CPU_SHARED_ALIGNED</span><span class="p">(</span><span class="k">struct</span> <span class="n">call_function_data</span><span class="p">,</span> <span class="n">cfd_data</span><span class="p">);</span>

<span class="k">struct</span> <span class="n">call_single_queue</span> <span class="p">{</span>
	<span class="k">struct</span> <span class="n">list_head</span>	<span class="n">list</span><span class="p">;</span>
	<span class="n">raw_spinlock_t</span>		<span class="n">lock</span><span class="p">;</span>
<span class="p">};</span>

<span class="k">static</span> <span class="n">DEFINE_PER_CPU_SHARED_ALIGNED</span><span class="p">(</span><span class="k">struct</span> <span class="n">call_single_queue</span><span class="p">,</span> <span class="n">call_single_queue</span><span class="p">);</span>

<span class="k">static</span> <span class="kt">int</span>
<span class="nf">hotplug_cfd</span><span class="p">(</span><span class="k">struct</span> <span class="n">notifier_block</span> <span class="o">*</span><span class="n">nfb</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">action</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">hcpu</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">long</span> <span class="n">cpu</span> <span class="o">=</span> <span class="p">(</span><span class="kt">long</span><span class="p">)</span><span class="n">hcpu</span><span class="p">;</span>
	<span class="k">struct</span> <span class="n">call_function_data</span> <span class="o">*</span><span class="n">cfd</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">per_cpu</span><span class="p">(</span><span class="n">cfd_data</span><span class="p">,</span> <span class="n">cpu</span><span class="p">);</span>

	<span class="k">switch</span> <span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="p">{</span>
	<span class="k">case</span> <span class="n">CPU_UP_PREPARE</span>:
	<span class="k">case</span> <span class="n">CPU_UP_PREPARE_FROZEN</span>:
		<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">zalloc_cpumask_var_node</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cfd</span><span class="o">-&gt;</span><span class="n">cpumask</span><span class="p">,</span> <span class="n">GFP_KERNEL</span><span class="p">,</span>
				<span class="n">cpu_to_node</span><span class="p">(</span><span class="n">cpu</span><span class="p">)))</span>
			<span class="k">return</span> <span class="n">notifier_from_errno</span><span class="p">(</span><span class="o">-</span><span class="n">ENOMEM</span><span class="p">);</span>
		<span class="k">break</span><span class="p">;</span>

<span class="cp">#ifdef CONFIG_HOTPLUG_CPU</span>
	<span class="k">case</span> <span class="n">CPU_UP_CANCELED</span>:
	<span class="k">case</span> <span class="n">CPU_UP_CANCELED_FROZEN</span>:

	<span class="k">case</span> <span class="n">CPU_DEAD</span>:
	<span class="k">case</span> <span class="n">CPU_DEAD_FROZEN</span>:
		<span class="n">free_cpumask_var</span><span class="p">(</span><span class="n">cfd</span><span class="o">-&gt;</span><span class="n">cpumask</span><span class="p">);</span>
		<span class="k">break</span><span class="p">;</span>
<span class="cp">#endif</span>
	<span class="p">};</span>

	<span class="k">return</span> <span class="n">NOTIFY_OK</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">static</span> <span class="k">struct</span> <span class="n">notifier_block</span> <span class="n">__cpuinitdata</span> <span class="n">hotplug_cfd_notifier</span> <span class="o">=</span> <span class="p">{</span>
	<span class="p">.</span><span class="n">notifier_call</span>		<span class="o">=</span> <span class="n">hotplug_cfd</span><span class="p">,</span>
<span class="p">};</span>

<span class="kt">void</span> <span class="n">__init</span> <span class="nf">call_function_init</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">void</span> <span class="o">*</span><span class="n">cpu</span> <span class="o">=</span> <span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="p">)(</span><span class="kt">long</span><span class="p">)</span><span class="n">smp_processor_id</span><span class="p">();</span>
	<span class="kt">int</span> <span class="n">i</span><span class="p">;</span>

	<span class="n">for_each_possible_cpu</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
		<span class="k">struct</span> <span class="n">call_single_queue</span> <span class="o">*</span><span class="n">q</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">per_cpu</span><span class="p">(</span><span class="n">call_single_queue</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>

		<span class="n">raw_spin_lock_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">q</span><span class="o">-&gt;</span><span class="n">lock</span><span class="p">);</span>
		<span class="n">INIT_LIST_HEAD</span><span class="p">(</span><span class="o">&amp;</span><span class="n">q</span><span class="o">-&gt;</span><span class="n">list</span><span class="p">);</span>
	<span class="p">}</span>

	<span class="n">hotplug_cfd</span><span class="p">(</span><span class="o">&amp;</span><span class="n">hotplug_cfd_notifier</span><span class="p">,</span> <span class="n">CPU_UP_PREPARE</span><span class="p">,</span> <span class="n">cpu</span><span class="p">);</span>
	<span class="n">register_cpu_notifier</span><span class="p">(</span><span class="o">&amp;</span><span class="n">hotplug_cfd_notifier</span><span class="p">);</span>
<span class="p">}</span>

<span class="cm">/*</span>
<span class="cm"> * csd_lock/csd_unlock used to serialize access to per-cpu csd resources</span>
<span class="cm"> *</span>
<span class="cm"> * For non-synchronous ipi calls the csd can still be in use by the</span>
<span class="cm"> * previous function call. For multi-cpu calls its even more interesting</span>
<span class="cm"> * as we&#39;ll have to ensure no other cpu is observing our csd.</span>
<span class="cm"> */</span>
<span class="k">static</span> <span class="kt">void</span> <span class="nf">csd_lock_wait</span><span class="p">(</span><span class="k">struct</span> <span class="n">call_single_data</span> <span class="o">*</span><span class="n">data</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">while</span> <span class="p">(</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">flags</span> <span class="o">&amp;</span> <span class="n">CSD_FLAG_LOCK</span><span class="p">)</span>
		<span class="n">cpu_relax</span><span class="p">();</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kt">void</span> <span class="nf">csd_lock</span><span class="p">(</span><span class="k">struct</span> <span class="n">call_single_data</span> <span class="o">*</span><span class="n">data</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">csd_lock_wait</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>
	<span class="n">data</span><span class="o">-&gt;</span><span class="n">flags</span> <span class="o">=</span> <span class="n">CSD_FLAG_LOCK</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * prevent CPU from reordering the above assignment</span>
<span class="cm">	 * to -&gt;flags with any subsequent assignments to other</span>
<span class="cm">	 * fields of the specified call_single_data structure:</span>
<span class="cm">	 */</span>
	<span class="n">smp_mb</span><span class="p">();</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kt">void</span> <span class="nf">csd_unlock</span><span class="p">(</span><span class="k">struct</span> <span class="n">call_single_data</span> <span class="o">*</span><span class="n">data</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">WARN_ON</span><span class="p">(</span><span class="o">!</span><span class="p">(</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">flags</span> <span class="o">&amp;</span> <span class="n">CSD_FLAG_LOCK</span><span class="p">));</span>

	<span class="cm">/*</span>
<span class="cm">	 * ensure we&#39;re all done before releasing data:</span>
<span class="cm">	 */</span>
	<span class="n">smp_mb</span><span class="p">();</span>

	<span class="n">data</span><span class="o">-&gt;</span><span class="n">flags</span> <span class="o">&amp;=</span> <span class="o">~</span><span class="n">CSD_FLAG_LOCK</span><span class="p">;</span>
<span class="p">}</span>

<span class="cm">/*</span>
<span class="cm"> * Insert a previously allocated call_single_data element</span>
<span class="cm"> * for execution on the given CPU. data must already have</span>
<span class="cm"> * -&gt;func, -&gt;info, and -&gt;flags set.</span>
<span class="cm"> */</span>
<span class="k">static</span>
<span class="kt">void</span> <span class="nf">generic_exec_single</span><span class="p">(</span><span class="kt">int</span> <span class="n">cpu</span><span class="p">,</span> <span class="k">struct</span> <span class="n">call_single_data</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="kt">int</span> <span class="n">wait</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">struct</span> <span class="n">call_single_queue</span> <span class="o">*</span><span class="n">dst</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">per_cpu</span><span class="p">(</span><span class="n">call_single_queue</span><span class="p">,</span> <span class="n">cpu</span><span class="p">);</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">;</span>
	<span class="kt">int</span> <span class="n">ipi</span><span class="p">;</span>

	<span class="n">raw_spin_lock_irqsave</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dst</span><span class="o">-&gt;</span><span class="n">lock</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>
	<span class="n">ipi</span> <span class="o">=</span> <span class="n">list_empty</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dst</span><span class="o">-&gt;</span><span class="n">list</span><span class="p">);</span>
	<span class="n">list_add_tail</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">list</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">dst</span><span class="o">-&gt;</span><span class="n">list</span><span class="p">);</span>
	<span class="n">raw_spin_unlock_irqrestore</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dst</span><span class="o">-&gt;</span><span class="n">lock</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>

	<span class="cm">/*</span>
<span class="cm">	 * The list addition should be visible before sending the IPI</span>
<span class="cm">	 * handler locks the list to pull the entry off it because of</span>
<span class="cm">	 * normal cache coherency rules implied by spinlocks.</span>
<span class="cm">	 *</span>
<span class="cm">	 * If IPIs can go out of order to the cache coherency protocol</span>
<span class="cm">	 * in an architecture, sufficient synchronisation should be added</span>
<span class="cm">	 * to arch code to make it appear to obey cache coherency WRT</span>
<span class="cm">	 * locking and barrier primitives. Generic code isn&#39;t really</span>
<span class="cm">	 * equipped to do the right thing...</span>
<span class="cm">	 */</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">ipi</span><span class="p">)</span>
		<span class="n">arch_send_call_function_single_ipi</span><span class="p">(</span><span class="n">cpu</span><span class="p">);</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">wait</span><span class="p">)</span>
		<span class="n">csd_lock_wait</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>
<span class="p">}</span>

<span class="cm">/*</span>
<span class="cm"> * Invoked by arch to handle an IPI for call function. Must be called with</span>
<span class="cm"> * interrupts disabled.</span>
<span class="cm"> */</span>
<span class="kt">void</span> <span class="nf">generic_smp_call_function_interrupt</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">struct</span> <span class="n">call_function_data</span> <span class="o">*</span><span class="n">data</span><span class="p">;</span>
	<span class="kt">int</span> <span class="n">cpu</span> <span class="o">=</span> <span class="n">smp_processor_id</span><span class="p">();</span>

	<span class="cm">/*</span>
<span class="cm">	 * Shouldn&#39;t receive this interrupt on a cpu that is not yet online.</span>
<span class="cm">	 */</span>
	<span class="n">WARN_ON_ONCE</span><span class="p">(</span><span class="o">!</span><span class="n">cpu_online</span><span class="p">(</span><span class="n">cpu</span><span class="p">));</span>

	<span class="cm">/*</span>
<span class="cm">	 * Ensure entry is visible on call_function_queue after we have</span>
<span class="cm">	 * entered the IPI. See comment in smp_call_function_many.</span>
<span class="cm">	 * If we don&#39;t have this, then we may miss an entry on the list</span>
<span class="cm">	 * and never get another IPI to process it.</span>
<span class="cm">	 */</span>
	<span class="n">smp_mb</span><span class="p">();</span>

	<span class="cm">/*</span>
<span class="cm">	 * It&#39;s ok to use list_for_each_rcu() here even though we may</span>
<span class="cm">	 * delete &#39;pos&#39;, since list_del_rcu() doesn&#39;t clear -&gt;next</span>
<span class="cm">	 */</span>
	<span class="n">list_for_each_entry_rcu</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">call_function</span><span class="p">.</span><span class="n">queue</span><span class="p">,</span> <span class="n">csd</span><span class="p">.</span><span class="n">list</span><span class="p">)</span> <span class="p">{</span>
		<span class="kt">int</span> <span class="n">refs</span><span class="p">;</span>
		<span class="n">smp_call_func_t</span> <span class="n">func</span><span class="p">;</span>

		<span class="cm">/*</span>
<span class="cm">		 * Since we walk the list without any locks, we might</span>
<span class="cm">		 * see an entry that was completed, removed from the</span>
<span class="cm">		 * list and is in the process of being reused.</span>
<span class="cm">		 *</span>
<span class="cm">		 * We must check that the cpu is in the cpumask before</span>
<span class="cm">		 * checking the refs, and both must be set before</span>
<span class="cm">		 * executing the callback on this cpu.</span>
<span class="cm">		 */</span>

		<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">cpumask_test_cpu</span><span class="p">(</span><span class="n">cpu</span><span class="p">,</span> <span class="n">data</span><span class="o">-&gt;</span><span class="n">cpumask</span><span class="p">))</span>
			<span class="k">continue</span><span class="p">;</span>

		<span class="n">smp_rmb</span><span class="p">();</span>

		<span class="k">if</span> <span class="p">(</span><span class="n">atomic_read</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">refs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
			<span class="k">continue</span><span class="p">;</span>

		<span class="n">func</span> <span class="o">=</span> <span class="n">data</span><span class="o">-&gt;</span><span class="n">csd</span><span class="p">.</span><span class="n">func</span><span class="p">;</span>		<span class="cm">/* save for later warn */</span>
		<span class="n">func</span><span class="p">(</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">csd</span><span class="p">.</span><span class="n">info</span><span class="p">);</span>

		<span class="cm">/*</span>
<span class="cm">		 * If the cpu mask is not still set then func enabled</span>
<span class="cm">		 * interrupts (BUG), and this cpu took another smp call</span>
<span class="cm">		 * function interrupt and executed func(info) twice</span>
<span class="cm">		 * on this cpu.  That nested execution decremented refs.</span>
<span class="cm">		 */</span>
		<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">cpumask_test_and_clear_cpu</span><span class="p">(</span><span class="n">cpu</span><span class="p">,</span> <span class="n">data</span><span class="o">-&gt;</span><span class="n">cpumask</span><span class="p">))</span> <span class="p">{</span>
			<span class="n">WARN</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s">&quot;%pf enabled interrupts and double executed</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">func</span><span class="p">);</span>
			<span class="k">continue</span><span class="p">;</span>
		<span class="p">}</span>

		<span class="n">refs</span> <span class="o">=</span> <span class="n">atomic_dec_return</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">refs</span><span class="p">);</span>
		<span class="n">WARN_ON</span><span class="p">(</span><span class="n">refs</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">);</span>

		<span class="k">if</span> <span class="p">(</span><span class="n">refs</span><span class="p">)</span>
			<span class="k">continue</span><span class="p">;</span>

		<span class="n">WARN_ON</span><span class="p">(</span><span class="o">!</span><span class="n">cpumask_empty</span><span class="p">(</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">cpumask</span><span class="p">));</span>

		<span class="n">raw_spin_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">call_function</span><span class="p">.</span><span class="n">lock</span><span class="p">);</span>
		<span class="n">list_del_rcu</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">csd</span><span class="p">.</span><span class="n">list</span><span class="p">);</span>
		<span class="n">raw_spin_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">call_function</span><span class="p">.</span><span class="n">lock</span><span class="p">);</span>

		<span class="n">csd_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">csd</span><span class="p">);</span>
	<span class="p">}</span>

<span class="p">}</span>

<span class="cm">/*</span>
<span class="cm"> * Invoked by arch to handle an IPI for call function single. Must be</span>
<span class="cm"> * called from the arch with interrupts disabled.</span>
<span class="cm"> */</span>
<span class="kt">void</span> <span class="nf">generic_smp_call_function_single_interrupt</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">struct</span> <span class="n">call_single_queue</span> <span class="o">*</span><span class="n">q</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">__get_cpu_var</span><span class="p">(</span><span class="n">call_single_queue</span><span class="p">);</span>
	<span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">data_flags</span><span class="p">;</span>
	<span class="n">LIST_HEAD</span><span class="p">(</span><span class="n">list</span><span class="p">);</span>

	<span class="cm">/*</span>
<span class="cm">	 * Shouldn&#39;t receive this interrupt on a cpu that is not yet online.</span>
<span class="cm">	 */</span>
	<span class="n">WARN_ON_ONCE</span><span class="p">(</span><span class="o">!</span><span class="n">cpu_online</span><span class="p">(</span><span class="n">smp_processor_id</span><span class="p">()));</span>

	<span class="n">raw_spin_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">q</span><span class="o">-&gt;</span><span class="n">lock</span><span class="p">);</span>
	<span class="n">list_replace_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">q</span><span class="o">-&gt;</span><span class="n">list</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">list</span><span class="p">);</span>
	<span class="n">raw_spin_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">q</span><span class="o">-&gt;</span><span class="n">lock</span><span class="p">);</span>

	<span class="k">while</span> <span class="p">(</span><span class="o">!</span><span class="n">list_empty</span><span class="p">(</span><span class="o">&amp;</span><span class="n">list</span><span class="p">))</span> <span class="p">{</span>
		<span class="k">struct</span> <span class="n">call_single_data</span> <span class="o">*</span><span class="n">data</span><span class="p">;</span>

		<span class="n">data</span> <span class="o">=</span> <span class="n">list_entry</span><span class="p">(</span><span class="n">list</span><span class="p">.</span><span class="n">next</span><span class="p">,</span> <span class="k">struct</span> <span class="n">call_single_data</span><span class="p">,</span> <span class="n">list</span><span class="p">);</span>
		<span class="n">list_del</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">list</span><span class="p">);</span>

		<span class="cm">/*</span>
<span class="cm">		 * &#39;data&#39; can be invalid after this call if flags == 0</span>
<span class="cm">		 * (when called through generic_exec_single()),</span>
<span class="cm">		 * so save them away before making the call:</span>
<span class="cm">		 */</span>
		<span class="n">data_flags</span> <span class="o">=</span> <span class="n">data</span><span class="o">-&gt;</span><span class="n">flags</span><span class="p">;</span>

		<span class="n">data</span><span class="o">-&gt;</span><span class="n">func</span><span class="p">(</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">info</span><span class="p">);</span>

		<span class="cm">/*</span>
<span class="cm">		 * Unlocked CSDs are valid through generic_exec_single():</span>
<span class="cm">		 */</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">data_flags</span> <span class="o">&amp;</span> <span class="n">CSD_FLAG_LOCK</span><span class="p">)</span>
			<span class="n">csd_unlock</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>
	<span class="p">}</span>
<span class="p">}</span>

<span class="k">static</span> <span class="n">DEFINE_PER_CPU_SHARED_ALIGNED</span><span class="p">(</span><span class="k">struct</span> <span class="n">call_single_data</span><span class="p">,</span> <span class="n">csd_data</span><span class="p">);</span>

<span class="cm">/*</span>
<span class="cm"> * smp_call_function_single - Run a function on a specific CPU</span>
<span class="cm"> * @func: The function to run. This must be fast and non-blocking.</span>
<span class="cm"> * @info: An arbitrary pointer to pass to the function.</span>
<span class="cm"> * @wait: If true, wait until function has completed on other CPUs.</span>
<span class="cm"> *</span>
<span class="cm"> * Returns 0 on success, else a negative status code.</span>
<span class="cm"> */</span>
<span class="kt">int</span> <span class="nf">smp_call_function_single</span><span class="p">(</span><span class="kt">int</span> <span class="n">cpu</span><span class="p">,</span> <span class="n">smp_call_func_t</span> <span class="n">func</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">info</span><span class="p">,</span>
			     <span class="kt">int</span> <span class="n">wait</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">struct</span> <span class="n">call_single_data</span> <span class="n">d</span> <span class="o">=</span> <span class="p">{</span>
		<span class="p">.</span><span class="n">flags</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
	<span class="p">};</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">;</span>
	<span class="kt">int</span> <span class="n">this_cpu</span><span class="p">;</span>
	<span class="kt">int</span> <span class="n">err</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

	<span class="cm">/*</span>
<span class="cm">	 * prevent preemption and reschedule on another processor,</span>
<span class="cm">	 * as well as CPU removal</span>
<span class="cm">	 */</span>
	<span class="n">this_cpu</span> <span class="o">=</span> <span class="n">get_cpu</span><span class="p">();</span>

	<span class="cm">/*</span>
<span class="cm">	 * Can deadlock when called with interrupts disabled.</span>
<span class="cm">	 * We allow cpu&#39;s that are not yet online though, as no one else can</span>
<span class="cm">	 * send smp call function interrupt to this cpu and as such deadlocks</span>
<span class="cm">	 * can&#39;t happen.</span>
<span class="cm">	 */</span>
	<span class="n">WARN_ON_ONCE</span><span class="p">(</span><span class="n">cpu_online</span><span class="p">(</span><span class="n">this_cpu</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="n">irqs_disabled</span><span class="p">()</span>
		     <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">oops_in_progress</span><span class="p">);</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">cpu</span> <span class="o">==</span> <span class="n">this_cpu</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">local_irq_save</span><span class="p">(</span><span class="n">flags</span><span class="p">);</span>
		<span class="n">func</span><span class="p">(</span><span class="n">info</span><span class="p">);</span>
		<span class="n">local_irq_restore</span><span class="p">(</span><span class="n">flags</span><span class="p">);</span>
	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
		<span class="k">if</span> <span class="p">((</span><span class="kt">unsigned</span><span class="p">)</span><span class="n">cpu</span> <span class="o">&lt;</span> <span class="n">nr_cpu_ids</span> <span class="o">&amp;&amp;</span> <span class="n">cpu_online</span><span class="p">(</span><span class="n">cpu</span><span class="p">))</span> <span class="p">{</span>
			<span class="k">struct</span> <span class="n">call_single_data</span> <span class="o">*</span><span class="n">data</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">d</span><span class="p">;</span>

			<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">wait</span><span class="p">)</span>
				<span class="n">data</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">__get_cpu_var</span><span class="p">(</span><span class="n">csd_data</span><span class="p">);</span>

			<span class="n">csd_lock</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>

			<span class="n">data</span><span class="o">-&gt;</span><span class="n">func</span> <span class="o">=</span> <span class="n">func</span><span class="p">;</span>
			<span class="n">data</span><span class="o">-&gt;</span><span class="n">info</span> <span class="o">=</span> <span class="n">info</span><span class="p">;</span>
			<span class="n">generic_exec_single</span><span class="p">(</span><span class="n">cpu</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">wait</span><span class="p">);</span>
		<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
			<span class="n">err</span> <span class="o">=</span> <span class="o">-</span><span class="n">ENXIO</span><span class="p">;</span>	<span class="cm">/* CPU not online */</span>
		<span class="p">}</span>
	<span class="p">}</span>

	<span class="n">put_cpu</span><span class="p">();</span>

	<span class="k">return</span> <span class="n">err</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">EXPORT_SYMBOL</span><span class="p">(</span><span class="n">smp_call_function_single</span><span class="p">);</span>

<span class="cm">/*</span>
<span class="cm"> * smp_call_function_any - Run a function on any of the given cpus</span>
<span class="cm"> * @mask: The mask of cpus it can run on.</span>
<span class="cm"> * @func: The function to run. This must be fast and non-blocking.</span>
<span class="cm"> * @info: An arbitrary pointer to pass to the function.</span>
<span class="cm"> * @wait: If true, wait until function has completed.</span>
<span class="cm"> *</span>
<span class="cm"> * Returns 0 on success, else a negative status code (if no cpus were online).</span>
<span class="cm"> * Note that @wait will be implicitly turned on in case of allocation failures,</span>
<span class="cm"> * since we fall back to on-stack allocation.</span>
<span class="cm"> *</span>
<span class="cm"> * Selection preference:</span>
<span class="cm"> *	1) current cpu if in @mask</span>
<span class="cm"> *	2) any cpu of current node if in @mask</span>
<span class="cm"> *	3) any other online cpu in @mask</span>
<span class="cm"> */</span>
<span class="kt">int</span> <span class="nf">smp_call_function_any</span><span class="p">(</span><span class="k">const</span> <span class="k">struct</span> <span class="n">cpumask</span> <span class="o">*</span><span class="n">mask</span><span class="p">,</span>
			  <span class="n">smp_call_func_t</span> <span class="n">func</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">info</span><span class="p">,</span> <span class="kt">int</span> <span class="n">wait</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">cpu</span><span class="p">;</span>
	<span class="k">const</span> <span class="k">struct</span> <span class="n">cpumask</span> <span class="o">*</span><span class="n">nodemask</span><span class="p">;</span>
	<span class="kt">int</span> <span class="n">ret</span><span class="p">;</span>

	<span class="cm">/* Try for same CPU (cheapest) */</span>
	<span class="n">cpu</span> <span class="o">=</span> <span class="n">get_cpu</span><span class="p">();</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">cpumask_test_cpu</span><span class="p">(</span><span class="n">cpu</span><span class="p">,</span> <span class="n">mask</span><span class="p">))</span>
		<span class="k">goto</span> <span class="n">call</span><span class="p">;</span>

	<span class="cm">/* Try for same node. */</span>
	<span class="n">nodemask</span> <span class="o">=</span> <span class="n">cpumask_of_node</span><span class="p">(</span><span class="n">cpu_to_node</span><span class="p">(</span><span class="n">cpu</span><span class="p">));</span>
	<span class="k">for</span> <span class="p">(</span><span class="n">cpu</span> <span class="o">=</span> <span class="n">cpumask_first_and</span><span class="p">(</span><span class="n">nodemask</span><span class="p">,</span> <span class="n">mask</span><span class="p">);</span> <span class="n">cpu</span> <span class="o">&lt;</span> <span class="n">nr_cpu_ids</span><span class="p">;</span>
	     <span class="n">cpu</span> <span class="o">=</span> <span class="n">cpumask_next_and</span><span class="p">(</span><span class="n">cpu</span><span class="p">,</span> <span class="n">nodemask</span><span class="p">,</span> <span class="n">mask</span><span class="p">))</span> <span class="p">{</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">cpu_online</span><span class="p">(</span><span class="n">cpu</span><span class="p">))</span>
			<span class="k">goto</span> <span class="n">call</span><span class="p">;</span>
	<span class="p">}</span>

	<span class="cm">/* Any online will do: smp_call_function_single handles nr_cpu_ids. */</span>
	<span class="n">cpu</span> <span class="o">=</span> <span class="n">cpumask_any_and</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">cpu_online_mask</span><span class="p">);</span>
<span class="nl">call:</span>
	<span class="n">ret</span> <span class="o">=</span> <span class="n">smp_call_function_single</span><span class="p">(</span><span class="n">cpu</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">info</span><span class="p">,</span> <span class="n">wait</span><span class="p">);</span>
	<span class="n">put_cpu</span><span class="p">();</span>
	<span class="k">return</span> <span class="n">ret</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">EXPORT_SYMBOL_GPL</span><span class="p">(</span><span class="n">smp_call_function_any</span><span class="p">);</span>

<span class="cm">/**</span>
<span class="cm"> * __smp_call_function_single(): Run a function on a specific CPU</span>
<span class="cm"> * @cpu: The CPU to run on.</span>
<span class="cm"> * @data: Pre-allocated and setup data structure</span>
<span class="cm"> * @wait: If true, wait until function has completed on specified CPU.</span>
<span class="cm"> *</span>
<span class="cm"> * Like smp_call_function_single(), but allow caller to pass in a</span>
<span class="cm"> * pre-allocated data structure. Useful for embedding @data inside</span>
<span class="cm"> * other structures, for instance.</span>
<span class="cm"> */</span>
<span class="kt">void</span> <span class="nf">__smp_call_function_single</span><span class="p">(</span><span class="kt">int</span> <span class="n">cpu</span><span class="p">,</span> <span class="k">struct</span> <span class="n">call_single_data</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span>
				<span class="kt">int</span> <span class="n">wait</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">this_cpu</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">;</span>

	<span class="n">this_cpu</span> <span class="o">=</span> <span class="n">get_cpu</span><span class="p">();</span>
	<span class="cm">/*</span>
<span class="cm">	 * Can deadlock when called with interrupts disabled.</span>
<span class="cm">	 * We allow cpu&#39;s that are not yet online though, as no one else can</span>
<span class="cm">	 * send smp call function interrupt to this cpu and as such deadlocks</span>
<span class="cm">	 * can&#39;t happen.</span>
<span class="cm">	 */</span>
	<span class="n">WARN_ON_ONCE</span><span class="p">(</span><span class="n">cpu_online</span><span class="p">(</span><span class="n">smp_processor_id</span><span class="p">())</span> <span class="o">&amp;&amp;</span> <span class="n">wait</span> <span class="o">&amp;&amp;</span> <span class="n">irqs_disabled</span><span class="p">()</span>
		     <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">oops_in_progress</span><span class="p">);</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">cpu</span> <span class="o">==</span> <span class="n">this_cpu</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">local_irq_save</span><span class="p">(</span><span class="n">flags</span><span class="p">);</span>
		<span class="n">data</span><span class="o">-&gt;</span><span class="n">func</span><span class="p">(</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">info</span><span class="p">);</span>
		<span class="n">local_irq_restore</span><span class="p">(</span><span class="n">flags</span><span class="p">);</span>
	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
		<span class="n">csd_lock</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>
		<span class="n">generic_exec_single</span><span class="p">(</span><span class="n">cpu</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">wait</span><span class="p">);</span>
	<span class="p">}</span>
	<span class="n">put_cpu</span><span class="p">();</span>
<span class="p">}</span>

<span class="cm">/**</span>
<span class="cm"> * smp_call_function_many(): Run a function on a set of other CPUs.</span>
<span class="cm"> * @mask: The set of cpus to run on (only runs on online subset).</span>
<span class="cm"> * @func: The function to run. This must be fast and non-blocking.</span>
<span class="cm"> * @info: An arbitrary pointer to pass to the function.</span>
<span class="cm"> * @wait: If true, wait (atomically) until function has completed</span>
<span class="cm"> *        on other CPUs.</span>
<span class="cm"> *</span>
<span class="cm"> * If @wait is true, then returns once @func has returned.</span>
<span class="cm"> *</span>
<span class="cm"> * You must not call this function with disabled interrupts or from a</span>
<span class="cm"> * hardware interrupt handler or from a bottom half handler. Preemption</span>
<span class="cm"> * must be disabled when calling this function.</span>
<span class="cm"> */</span>
<span class="kt">void</span> <span class="nf">smp_call_function_many</span><span class="p">(</span><span class="k">const</span> <span class="k">struct</span> <span class="n">cpumask</span> <span class="o">*</span><span class="n">mask</span><span class="p">,</span>
			    <span class="n">smp_call_func_t</span> <span class="n">func</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">info</span><span class="p">,</span> <span class="n">bool</span> <span class="n">wait</span><span class="p">)</span>
<span class="p">{</span>
	<span class="k">struct</span> <span class="n">call_function_data</span> <span class="o">*</span><span class="n">data</span><span class="p">;</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">;</span>
	<span class="kt">int</span> <span class="n">refs</span><span class="p">,</span> <span class="n">cpu</span><span class="p">,</span> <span class="n">next_cpu</span><span class="p">,</span> <span class="n">this_cpu</span> <span class="o">=</span> <span class="n">smp_processor_id</span><span class="p">();</span>

	<span class="cm">/*</span>
<span class="cm">	 * Can deadlock when called with interrupts disabled.</span>
<span class="cm">	 * We allow cpu&#39;s that are not yet online though, as no one else can</span>
<span class="cm">	 * send smp call function interrupt to this cpu and as such deadlocks</span>
<span class="cm">	 * can&#39;t happen.</span>
<span class="cm">	 */</span>
	<span class="n">WARN_ON_ONCE</span><span class="p">(</span><span class="n">cpu_online</span><span class="p">(</span><span class="n">this_cpu</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="n">irqs_disabled</span><span class="p">()</span>
		     <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">oops_in_progress</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">early_boot_irqs_disabled</span><span class="p">);</span>

	<span class="cm">/* Try to fastpath.  So, what&#39;s a CPU they want? Ignoring this one. */</span>
	<span class="n">cpu</span> <span class="o">=</span> <span class="n">cpumask_first_and</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">cpu_online_mask</span><span class="p">);</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">cpu</span> <span class="o">==</span> <span class="n">this_cpu</span><span class="p">)</span>
		<span class="n">cpu</span> <span class="o">=</span> <span class="n">cpumask_next_and</span><span class="p">(</span><span class="n">cpu</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">cpu_online_mask</span><span class="p">);</span>

	<span class="cm">/* No online cpus?  We&#39;re done. */</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">cpu</span> <span class="o">&gt;=</span> <span class="n">nr_cpu_ids</span><span class="p">)</span>
		<span class="k">return</span><span class="p">;</span>

	<span class="cm">/* Do we have another CPU which isn&#39;t us? */</span>
	<span class="n">next_cpu</span> <span class="o">=</span> <span class="n">cpumask_next_and</span><span class="p">(</span><span class="n">cpu</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">cpu_online_mask</span><span class="p">);</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">next_cpu</span> <span class="o">==</span> <span class="n">this_cpu</span><span class="p">)</span>
		<span class="n">next_cpu</span> <span class="o">=</span> <span class="n">cpumask_next_and</span><span class="p">(</span><span class="n">next_cpu</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">cpu_online_mask</span><span class="p">);</span>

	<span class="cm">/* Fastpath: do that cpu by itself. */</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">next_cpu</span> <span class="o">&gt;=</span> <span class="n">nr_cpu_ids</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">smp_call_function_single</span><span class="p">(</span><span class="n">cpu</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">info</span><span class="p">,</span> <span class="n">wait</span><span class="p">);</span>
		<span class="k">return</span><span class="p">;</span>
	<span class="p">}</span>

	<span class="n">data</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">__get_cpu_var</span><span class="p">(</span><span class="n">cfd_data</span><span class="p">);</span>
	<span class="n">csd_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">csd</span><span class="p">);</span>

	<span class="cm">/* This BUG_ON verifies our reuse assertions and can be removed */</span>
	<span class="n">BUG_ON</span><span class="p">(</span><span class="n">atomic_read</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">refs</span><span class="p">)</span> <span class="o">||</span> <span class="o">!</span><span class="n">cpumask_empty</span><span class="p">(</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">cpumask</span><span class="p">));</span>

	<span class="cm">/*</span>
<span class="cm">	 * The global call function queue list add and delete are protected</span>
<span class="cm">	 * by a lock, but the list is traversed without any lock, relying</span>
<span class="cm">	 * on the rcu list add and delete to allow safe concurrent traversal.</span>
<span class="cm">	 * We reuse the call function data without waiting for any grace</span>
<span class="cm">	 * period after some other cpu removes it from the global queue.</span>
<span class="cm">	 * This means a cpu might find our data block as it is being</span>
<span class="cm">	 * filled out.</span>
<span class="cm">	 *</span>
<span class="cm">	 * We hold off the interrupt handler on the other cpu by</span>
<span class="cm">	 * ordering our writes to the cpu mask vs our setting of the</span>
<span class="cm">	 * refs counter.  We assert only the cpu owning the data block</span>
<span class="cm">	 * will set a bit in cpumask, and each bit will only be cleared</span>
<span class="cm">	 * by the subject cpu.  Each cpu must first find its bit is</span>
<span class="cm">	 * set and then check that refs is set indicating the element is</span>
<span class="cm">	 * ready to be processed, otherwise it must skip the entry.</span>
<span class="cm">	 *</span>
<span class="cm">	 * On the previous iteration refs was set to 0 by another cpu.</span>
<span class="cm">	 * To avoid the use of transitivity, set the counter to 0 here</span>
<span class="cm">	 * so the wmb will pair with the rmb in the interrupt handler.</span>
<span class="cm">	 */</span>
	<span class="n">atomic_set</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">refs</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>	<span class="cm">/* convert 3rd to 1st party write */</span>

	<span class="n">data</span><span class="o">-&gt;</span><span class="n">csd</span><span class="p">.</span><span class="n">func</span> <span class="o">=</span> <span class="n">func</span><span class="p">;</span>
	<span class="n">data</span><span class="o">-&gt;</span><span class="n">csd</span><span class="p">.</span><span class="n">info</span> <span class="o">=</span> <span class="n">info</span><span class="p">;</span>

	<span class="cm">/* Ensure 0 refs is visible before mask.  Also orders func and info */</span>
	<span class="n">smp_wmb</span><span class="p">();</span>

	<span class="cm">/* We rely on the &quot;and&quot; being processed before the store */</span>
	<span class="n">cpumask_and</span><span class="p">(</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">cpumask</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">cpu_online_mask</span><span class="p">);</span>
	<span class="n">cpumask_clear_cpu</span><span class="p">(</span><span class="n">this_cpu</span><span class="p">,</span> <span class="n">data</span><span class="o">-&gt;</span><span class="n">cpumask</span><span class="p">);</span>
	<span class="n">refs</span> <span class="o">=</span> <span class="n">cpumask_weight</span><span class="p">(</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">cpumask</span><span class="p">);</span>

	<span class="cm">/* Some callers race with other cpus changing the passed mask */</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">unlikely</span><span class="p">(</span><span class="o">!</span><span class="n">refs</span><span class="p">))</span> <span class="p">{</span>
		<span class="n">csd_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">csd</span><span class="p">);</span>
		<span class="k">return</span><span class="p">;</span>
	<span class="p">}</span>

	<span class="n">raw_spin_lock_irqsave</span><span class="p">(</span><span class="o">&amp;</span><span class="n">call_function</span><span class="p">.</span><span class="n">lock</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>
	<span class="cm">/*</span>
<span class="cm">	 * Place entry at the _HEAD_ of the list, so that any cpu still</span>
<span class="cm">	 * observing the entry in generic_smp_call_function_interrupt()</span>
<span class="cm">	 * will not miss any other list entries:</span>
<span class="cm">	 */</span>
	<span class="n">list_add_rcu</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">csd</span><span class="p">.</span><span class="n">list</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">call_function</span><span class="p">.</span><span class="n">queue</span><span class="p">);</span>
	<span class="cm">/*</span>
<span class="cm">	 * We rely on the wmb() in list_add_rcu to complete our writes</span>
<span class="cm">	 * to the cpumask before this write to refs, which indicates</span>
<span class="cm">	 * data is on the list and is ready to be processed.</span>
<span class="cm">	 */</span>
	<span class="n">atomic_set</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">refs</span><span class="p">,</span> <span class="n">refs</span><span class="p">);</span>
	<span class="n">raw_spin_unlock_irqrestore</span><span class="p">(</span><span class="o">&amp;</span><span class="n">call_function</span><span class="p">.</span><span class="n">lock</span><span class="p">,</span> <span class="n">flags</span><span class="p">);</span>

	<span class="cm">/*</span>
<span class="cm">	 * Make the list addition visible before sending the ipi.</span>
<span class="cm">	 * (IPIs must obey or appear to obey normal Linux cache</span>
<span class="cm">	 * coherency rules -- see comment in generic_exec_single).</span>
<span class="cm">	 */</span>
	<span class="n">smp_mb</span><span class="p">();</span>

	<span class="cm">/* Send a message to all CPUs in the map */</span>
	<span class="n">arch_send_call_function_ipi_mask</span><span class="p">(</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">cpumask</span><span class="p">);</span>

	<span class="cm">/* Optionally wait for the CPUs to complete */</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">wait</span><span class="p">)</span>
		<span class="n">csd_lock_wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">csd</span><span class="p">);</span>
<span class="p">}</span>
<span class="n">EXPORT_SYMBOL</span><span class="p">(</span><span class="n">smp_call_function_many</span><span class="p">);</span>

<span class="cm">/**</span>
<span class="cm"> * smp_call_function(): Run a function on all other CPUs.</span>
<span class="cm"> * @func: The function to run. This must be fast and non-blocking.</span>
<span class="cm"> * @info: An arbitrary pointer to pass to the function.</span>
<span class="cm"> * @wait: If true, wait (atomically) until function has completed</span>
<span class="cm"> *        on other CPUs.</span>
<span class="cm"> *</span>
<span class="cm"> * Returns 0.</span>
<span class="cm"> *</span>
<span class="cm"> * If @wait is true, then returns once @func has returned; otherwise</span>
<span class="cm"> * it returns just before the target cpu calls @func.</span>
<span class="cm"> *</span>
<span class="cm"> * You must not call this function with disabled interrupts or from a</span>
<span class="cm"> * hardware interrupt handler or from a bottom half handler.</span>
<span class="cm"> */</span>
<span class="kt">int</span> <span class="nf">smp_call_function</span><span class="p">(</span><span class="n">smp_call_func_t</span> <span class="n">func</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">info</span><span class="p">,</span> <span class="kt">int</span> <span class="n">wait</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">preempt_disable</span><span class="p">();</span>
	<span class="n">smp_call_function_many</span><span class="p">(</span><span class="n">cpu_online_mask</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">info</span><span class="p">,</span> <span class="n">wait</span><span class="p">);</span>
	<span class="n">preempt_enable</span><span class="p">();</span>

	<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">EXPORT_SYMBOL</span><span class="p">(</span><span class="n">smp_call_function</span><span class="p">);</span>

<span class="kt">void</span> <span class="nf">ipi_call_lock</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">raw_spin_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">call_function</span><span class="p">.</span><span class="n">lock</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="nf">ipi_call_unlock</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">raw_spin_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">call_function</span><span class="p">.</span><span class="n">lock</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="nf">ipi_call_lock_irq</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">raw_spin_lock_irq</span><span class="p">(</span><span class="o">&amp;</span><span class="n">call_function</span><span class="p">.</span><span class="n">lock</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="nf">ipi_call_unlock_irq</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">raw_spin_unlock_irq</span><span class="p">(</span><span class="o">&amp;</span><span class="n">call_function</span><span class="p">.</span><span class="n">lock</span><span class="p">);</span>
<span class="p">}</span>
<span class="cp">#endif </span><span class="cm">/* USE_GENERIC_SMP_HELPERS */</span><span class="cp"></span>

<span class="cm">/* Setup configured maximum number of CPUs to activate */</span>
<span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">setup_max_cpus</span> <span class="o">=</span> <span class="n">NR_CPUS</span><span class="p">;</span>
<span class="n">EXPORT_SYMBOL</span><span class="p">(</span><span class="n">setup_max_cpus</span><span class="p">);</span>


<span class="cm">/*</span>
<span class="cm"> * Setup routine for controlling SMP activation</span>
<span class="cm"> *</span>
<span class="cm"> * Command-line option of &quot;nosmp&quot; or &quot;maxcpus=0&quot; will disable SMP</span>
<span class="cm"> * activation entirely (the MPS table probe still happens, though).</span>
<span class="cm"> *</span>
<span class="cm"> * Command-line option of &quot;maxcpus=&lt;NUM&gt;&quot;, where &lt;NUM&gt; is an integer</span>
<span class="cm"> * greater than 0, limits the maximum number of CPUs activated in</span>
<span class="cm"> * SMP mode to &lt;NUM&gt;.</span>
<span class="cm"> */</span>

<span class="kt">void</span> <span class="n">__weak</span> <span class="nf">arch_disable_smp_support</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span> <span class="p">{</span> <span class="p">}</span>

<span class="k">static</span> <span class="kt">int</span> <span class="n">__init</span> <span class="nf">nosmp</span><span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="n">str</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">setup_max_cpus</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="n">arch_disable_smp_support</span><span class="p">();</span>

	<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">early_param</span><span class="p">(</span><span class="s">&quot;nosmp&quot;</span><span class="p">,</span> <span class="n">nosmp</span><span class="p">);</span>

<span class="cm">/* this is hard limit */</span>
<span class="k">static</span> <span class="kt">int</span> <span class="n">__init</span> <span class="nf">nrcpus</span><span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="n">str</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">int</span> <span class="n">nr_cpus</span><span class="p">;</span>

	<span class="n">get_option</span><span class="p">(</span><span class="o">&amp;</span><span class="n">str</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">nr_cpus</span><span class="p">);</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">nr_cpus</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">nr_cpus</span> <span class="o">&lt;</span> <span class="n">nr_cpu_ids</span><span class="p">)</span>
		<span class="n">nr_cpu_ids</span> <span class="o">=</span> <span class="n">nr_cpus</span><span class="p">;</span>

	<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">early_param</span><span class="p">(</span><span class="s">&quot;nr_cpus&quot;</span><span class="p">,</span> <span class="n">nrcpus</span><span class="p">);</span>

<span class="k">static</span> <span class="kt">int</span> <span class="n">__init</span> <span class="nf">maxcpus</span><span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="n">str</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">get_option</span><span class="p">(</span><span class="o">&amp;</span><span class="n">str</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">setup_max_cpus</span><span class="p">);</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">setup_max_cpus</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
		<span class="n">arch_disable_smp_support</span><span class="p">();</span>

	<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">early_param</span><span class="p">(</span><span class="s">&quot;maxcpus&quot;</span><span class="p">,</span> <span class="n">maxcpus</span><span class="p">);</span>

<span class="cm">/* Setup number of possible processor ids */</span>
<span class="kt">int</span> <span class="n">nr_cpu_ids</span> <span class="n">__read_mostly</span> <span class="o">=</span> <span class="n">NR_CPUS</span><span class="p">;</span>
<span class="n">EXPORT_SYMBOL</span><span class="p">(</span><span class="n">nr_cpu_ids</span><span class="p">);</span>

<span class="cm">/* An arch may set nr_cpu_ids earlier if needed, so this would be redundant */</span>
<span class="kt">void</span> <span class="n">__init</span> <span class="nf">setup_nr_cpu_ids</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">nr_cpu_ids</span> <span class="o">=</span> <span class="n">find_last_bit</span><span class="p">(</span><span class="n">cpumask_bits</span><span class="p">(</span><span class="n">cpu_possible_mask</span><span class="p">),</span><span class="n">NR_CPUS</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>

<span class="cm">/* Called by boot processor to activate the rest. */</span>
<span class="kt">void</span> <span class="n">__init</span> <span class="nf">smp_init</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">cpu</span><span class="p">;</span>

	<span class="n">idle_threads_init</span><span class="p">();</span>

	<span class="cm">/* FIXME: This should be done in userspace --RR */</span>
	<span class="n">for_each_present_cpu</span><span class="p">(</span><span class="n">cpu</span><span class="p">)</span> <span class="p">{</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">num_online_cpus</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="n">setup_max_cpus</span><span class="p">)</span>
			<span class="k">break</span><span class="p">;</span>
		<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">cpu_online</span><span class="p">(</span><span class="n">cpu</span><span class="p">))</span>
			<span class="n">cpu_up</span><span class="p">(</span><span class="n">cpu</span><span class="p">);</span>
	<span class="p">}</span>

	<span class="cm">/* Any cleanup work */</span>
	<span class="n">printk</span><span class="p">(</span><span class="n">KERN_INFO</span> <span class="s">&quot;Brought up %ld CPUs</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="p">(</span><span class="kt">long</span><span class="p">)</span><span class="n">num_online_cpus</span><span class="p">());</span>
	<span class="n">smp_cpus_done</span><span class="p">(</span><span class="n">setup_max_cpus</span><span class="p">);</span>
<span class="p">}</span>

<span class="cm">/*</span>
<span class="cm"> * Call a function on all processors.  May be used during early boot while</span>
<span class="cm"> * early_boot_irqs_disabled is set.  Use local_irq_save/restore() instead</span>
<span class="cm"> * of local_irq_disable/enable().</span>
<span class="cm"> */</span>
<span class="kt">int</span> <span class="nf">on_each_cpu</span><span class="p">(</span><span class="kt">void</span> <span class="p">(</span><span class="o">*</span><span class="n">func</span><span class="p">)</span> <span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">info</span><span class="p">),</span> <span class="kt">void</span> <span class="o">*</span><span class="n">info</span><span class="p">,</span> <span class="kt">int</span> <span class="n">wait</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">flags</span><span class="p">;</span>
	<span class="kt">int</span> <span class="n">ret</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

	<span class="n">preempt_disable</span><span class="p">();</span>
	<span class="n">ret</span> <span class="o">=</span> <span class="n">smp_call_function</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">info</span><span class="p">,</span> <span class="n">wait</span><span class="p">);</span>
	<span class="n">local_irq_save</span><span class="p">(</span><span class="n">flags</span><span class="p">);</span>
	<span class="n">func</span><span class="p">(</span><span class="n">info</span><span class="p">);</span>
	<span class="n">local_irq_restore</span><span class="p">(</span><span class="n">flags</span><span class="p">);</span>
	<span class="n">preempt_enable</span><span class="p">();</span>
	<span class="k">return</span> <span class="n">ret</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">EXPORT_SYMBOL</span><span class="p">(</span><span class="n">on_each_cpu</span><span class="p">);</span>

<span class="cm">/**</span>
<span class="cm"> * on_each_cpu_mask(): Run a function on processors specified by</span>
<span class="cm"> * cpumask, which may include the local processor.</span>
<span class="cm"> * @mask: The set of cpus to run on (only runs on online subset).</span>
<span class="cm"> * @func: The function to run. This must be fast and non-blocking.</span>
<span class="cm"> * @info: An arbitrary pointer to pass to the function.</span>
<span class="cm"> * @wait: If true, wait (atomically) until function has completed</span>
<span class="cm"> *        on other CPUs.</span>
<span class="cm"> *</span>
<span class="cm"> * If @wait is true, then returns once @func has returned.</span>
<span class="cm"> *</span>
<span class="cm"> * You must not call this function with disabled interrupts or</span>
<span class="cm"> * from a hardware interrupt handler or from a bottom half handler.</span>
<span class="cm"> */</span>
<span class="kt">void</span> <span class="nf">on_each_cpu_mask</span><span class="p">(</span><span class="k">const</span> <span class="k">struct</span> <span class="n">cpumask</span> <span class="o">*</span><span class="n">mask</span><span class="p">,</span> <span class="n">smp_call_func_t</span> <span class="n">func</span><span class="p">,</span>
			<span class="kt">void</span> <span class="o">*</span><span class="n">info</span><span class="p">,</span> <span class="n">bool</span> <span class="n">wait</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">int</span> <span class="n">cpu</span> <span class="o">=</span> <span class="n">get_cpu</span><span class="p">();</span>

	<span class="n">smp_call_function_many</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">info</span><span class="p">,</span> <span class="n">wait</span><span class="p">);</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">cpumask_test_cpu</span><span class="p">(</span><span class="n">cpu</span><span class="p">,</span> <span class="n">mask</span><span class="p">))</span> <span class="p">{</span>
		<span class="n">local_irq_disable</span><span class="p">();</span>
		<span class="n">func</span><span class="p">(</span><span class="n">info</span><span class="p">);</span>
		<span class="n">local_irq_enable</span><span class="p">();</span>
	<span class="p">}</span>
	<span class="n">put_cpu</span><span class="p">();</span>
<span class="p">}</span>
<span class="n">EXPORT_SYMBOL</span><span class="p">(</span><span class="n">on_each_cpu_mask</span><span class="p">);</span>

<span class="cm">/*</span>
<span class="cm"> * on_each_cpu_cond(): Call a function on each processor for which</span>
<span class="cm"> * the supplied function cond_func returns true, optionally waiting</span>
<span class="cm"> * for all the required CPUs to finish. This may include the local</span>
<span class="cm"> * processor.</span>
<span class="cm"> * @cond_func:	A callback function that is passed a cpu id and</span>
<span class="cm"> *		the the info parameter. The function is called</span>
<span class="cm"> *		with preemption disabled. The function should</span>
<span class="cm"> *		return a blooean value indicating whether to IPI</span>
<span class="cm"> *		the specified CPU.</span>
<span class="cm"> * @func:	The function to run on all applicable CPUs.</span>
<span class="cm"> *		This must be fast and non-blocking.</span>
<span class="cm"> * @info:	An arbitrary pointer to pass to both functions.</span>
<span class="cm"> * @wait:	If true, wait (atomically) until function has</span>
<span class="cm"> *		completed on other CPUs.</span>
<span class="cm"> * @gfp_flags:	GFP flags to use when allocating the cpumask</span>
<span class="cm"> *		used internally by the function.</span>
<span class="cm"> *</span>
<span class="cm"> * The function might sleep if the GFP flags indicates a non</span>
<span class="cm"> * atomic allocation is allowed.</span>
<span class="cm"> *</span>
<span class="cm"> * Preemption is disabled to protect against CPUs going offline but not online.</span>
<span class="cm"> * CPUs going online during the call will not be seen or sent an IPI.</span>
<span class="cm"> *</span>
<span class="cm"> * You must not call this function with disabled interrupts or</span>
<span class="cm"> * from a hardware interrupt handler or from a bottom half handler.</span>
<span class="cm"> */</span>
<span class="kt">void</span> <span class="nf">on_each_cpu_cond</span><span class="p">(</span><span class="n">bool</span> <span class="p">(</span><span class="o">*</span><span class="n">cond_func</span><span class="p">)(</span><span class="kt">int</span> <span class="n">cpu</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">info</span><span class="p">),</span>
			<span class="n">smp_call_func_t</span> <span class="n">func</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">info</span><span class="p">,</span> <span class="n">bool</span> <span class="n">wait</span><span class="p">,</span>
			<span class="n">gfp_t</span> <span class="n">gfp_flags</span><span class="p">)</span>
<span class="p">{</span>
	<span class="n">cpumask_var_t</span> <span class="n">cpus</span><span class="p">;</span>
	<span class="kt">int</span> <span class="n">cpu</span><span class="p">,</span> <span class="n">ret</span><span class="p">;</span>

	<span class="n">might_sleep_if</span><span class="p">(</span><span class="n">gfp_flags</span> <span class="o">&amp;</span> <span class="n">__GFP_WAIT</span><span class="p">);</span>

	<span class="k">if</span> <span class="p">(</span><span class="n">likely</span><span class="p">(</span><span class="n">zalloc_cpumask_var</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cpus</span><span class="p">,</span> <span class="p">(</span><span class="n">gfp_flags</span><span class="o">|</span><span class="n">__GFP_NOWARN</span><span class="p">))))</span> <span class="p">{</span>
		<span class="n">preempt_disable</span><span class="p">();</span>
		<span class="n">for_each_online_cpu</span><span class="p">(</span><span class="n">cpu</span><span class="p">)</span>
			<span class="k">if</span> <span class="p">(</span><span class="n">cond_func</span><span class="p">(</span><span class="n">cpu</span><span class="p">,</span> <span class="n">info</span><span class="p">))</span>
				<span class="n">cpumask_set_cpu</span><span class="p">(</span><span class="n">cpu</span><span class="p">,</span> <span class="n">cpus</span><span class="p">);</span>
		<span class="n">on_each_cpu_mask</span><span class="p">(</span><span class="n">cpus</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">info</span><span class="p">,</span> <span class="n">wait</span><span class="p">);</span>
		<span class="n">preempt_enable</span><span class="p">();</span>
		<span class="n">free_cpumask_var</span><span class="p">(</span><span class="n">cpus</span><span class="p">);</span>
	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
		<span class="cm">/*</span>
<span class="cm">		 * No free cpumask, bother. No matter, we&#39;ll</span>
<span class="cm">		 * just have to IPI them one by one.</span>
<span class="cm">		 */</span>
		<span class="n">preempt_disable</span><span class="p">();</span>
		<span class="n">for_each_online_cpu</span><span class="p">(</span><span class="n">cpu</span><span class="p">)</span>
			<span class="k">if</span> <span class="p">(</span><span class="n">cond_func</span><span class="p">(</span><span class="n">cpu</span><span class="p">,</span> <span class="n">info</span><span class="p">))</span> <span class="p">{</span>
				<span class="n">ret</span> <span class="o">=</span> <span class="n">smp_call_function_single</span><span class="p">(</span><span class="n">cpu</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span>
								<span class="n">info</span><span class="p">,</span> <span class="n">wait</span><span class="p">);</span>
				<span class="n">WARN_ON_ONCE</span><span class="p">(</span><span class="o">!</span><span class="n">ret</span><span class="p">);</span>
			<span class="p">}</span>
		<span class="n">preempt_enable</span><span class="p">();</span>
	<span class="p">}</span>
<span class="p">}</span>
<span class="n">EXPORT_SYMBOL</span><span class="p">(</span><span class="n">on_each_cpu_cond</span><span class="p">);</span>

<span class="k">static</span> <span class="kt">void</span> <span class="nf">do_nothing</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">unused</span><span class="p">)</span>
<span class="p">{</span>
<span class="p">}</span>

<span class="cm">/**</span>
<span class="cm"> * kick_all_cpus_sync - Force all cpus out of idle</span>
<span class="cm"> *</span>
<span class="cm"> * Used to synchronize the update of pm_idle function pointer. It&#39;s</span>
<span class="cm"> * called after the pointer is updated and returns after the dummy</span>
<span class="cm"> * callback function has been executed on all cpus. The execution of</span>
<span class="cm"> * the function can only happen on the remote cpus after they have</span>
<span class="cm"> * left the idle function which had been called via pm_idle function</span>
<span class="cm"> * pointer. So it&#39;s guaranteed that nothing uses the previous pointer</span>
<span class="cm"> * anymore.</span>
<span class="cm"> */</span>
<span class="kt">void</span> <span class="nf">kick_all_cpus_sync</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
	<span class="cm">/* Make sure the change is visible before we kick the cpus */</span>
	<span class="n">smp_mb</span><span class="p">();</span>
	<span class="n">smp_call_function</span><span class="p">(</span><span class="n">do_nothing</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
<span class="p">}</span>
<span class="n">EXPORT_SYMBOL_GPL</span><span class="p">(</span><span class="n">kick_all_cpus_sync</span><span class="p">);</span>

</pre></div></td></tr>

</tbody>
</table>
</div>

</body>
<script>docas={repo:"joekychen/linux",depth:1}</script>
<script>document.write('<script src=' + ('__proto__' in {} ? 'http://cdnjs.cloudflare.com/ajax/libs/zepto/1.0rc1/zepto.min.js' : 'https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js')+'><\\/script>')</script>
<script src="http://baoshan.github.com/moment/min/moment.min.js"></script>
<script src="../javascript/docco.min.js"></script>
</html>
