d | linux |  | 15 items |  | David Ahern | dsahern@gmail.com | 1339424401 |  | perf tools: Fix endianity swapping for adds_features bitmask  Based on Jiri's latest attempt: https://lkml.org/lkml/2012/5/16/61  Basically, adds_features should be byte swapped assuming unsigned longs are either 8-bytes (u64) or 4-bytes (u32).      Fixes 32-bit ppc dumping 64-bit x86 feature data:      ========      captured on: Sun May 20 19:23:23 2012      hostname : nxos-vdc-dev3      os release : 3.4.0-rc7+      perf version : 3.4.rc4.137.g978da3      arch : x86_64      nrcpus online : 16      nrcpus avail : 16      cpudesc : Intel(R) Xeon(R) CPU E5540 @ 2.53GHz      cpuid : GenuineIntel,6,26,5      total memory : 24680324 kB     ...  Verified 64-bit x86 can still dump feature data for 32-bit ppc.  Signed-off-by: David Ahern <dsahern@gmail.com> Reviewed-by: Jiri Olsa <jolsa@redhat.com> Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com> Cc: Frederic Weisbecker <fweisbec@gmail.com> Cc: Paul Mackerras <paulus@samba.org> Cc: Peter Zijlstra <peterz@infradead.org> Link: http://lkml.kernel.org/r/4FBBB539.5010805@gmail.com Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
d | asm |  | 12 items |  | Linus Torvalds | torvalds@linux-foundation.org | 1332264555 |  | Merge branch 'perf-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip  Pull perf events changes for v3.4 from Ingo Molnar:   - New "hardware based branch profiling" feature both on the kernel and    the tooling side, on CPUs that support it.  (modern x86 Intel CPUs    with the 'LBR' hardware feature currently.)     This new feature is basically a sophisticated 'magnifying glass' for    branch execution - something that is pretty difficult to extract from    regular, function histogram centric profiles.     The simplest mode is activated via 'perf record -b', and the result    looks like this in perf report:  	$ perf record -b any_call,u -e cycles:u branchy  	$ perf report -b --sort=symbol 	    52.34%  [.] main                   [.] f1 	    24.04%  [.] f1                     [.] f3 	    23.60%  [.] f1                     [.] f2 	     0.01%  [k] _IO_new_file_xsputn    [k] _IO_file_overflow 	     0.01%  [k] _IO_vfprintf_internal  [k] _IO_new_file_xsputn 	     0.01%  [k] _IO_vfprintf_internal  [k] strchrnul 	     0.01%  [k] __printf               [k] _IO_vfprintf_internal 	     0.01%  [k] main                   [k] __printf     This output shows from/to branch columns and shows the highest    percentage (from,to) jump combinations - i.e.  the most likely taken    branches in the system.  "branches" can also include function calls    and any other synchronous and asynchronous transitions of the    instruction pointer that are not 'next instruction' - such as system    calls, traps, interrupts, etc.     This feature comes with (hopefully intuitive) flat ascii and TUI    support in perf report.   - Various 'perf annotate' visual improvements for us assembly junkies.    It will now recognize function calls in the TUI and by hitting enter    you can follow the call (recursively) and back, amongst other    improvements.   - Multiple threads/processes recording support in perf record, perf    stat, perf top - which is activated via a comma-list of PIDs:  	perf top -p 21483,21485 	perf stat -p 21483,21485 -ddd 	perf record -p 21483,21485   - Support for per UID views, via the --uid paramter to perf top, perf    report, etc.  For example 'perf top --uid mingo' will only show the    tasks that I am running, excluding other users, root, etc.   - Jump label restructurings and improvements - this includes the    factoring out of the (hopefully much clearer) include/linux/static_key.h    generic facility:  	struct static_key key = STATIC_KEY_INIT_FALSE;  	...  	if (static_key_false(&key)) 	        do unlikely code 	else 	        do likely code  	... 	static_key_slow_inc(); 	... 	static_key_slow_inc(); 	...     The static_key_false() branch will be generated into the code with as    little impact to the likely code path as possible.  the    static_key_slow_*() APIs flip the branch via live kernel code patching.     This facility can now be used more widely within the kernel to    micro-optimize hot branches whose likelihood matches the static-key    usage and fast/slow cost patterns.   - SW function tracer improvements: perf support and filtering support.   - Various hardenings of the perf.data ABI, to make older perf.data's    smoother on newer tool versions, to make new features integrate more    smoothly, to support cross-endian recording/analyzing workflows    better, etc.   - Restructuring of the kprobes code, the splitting out of 'optprobes',    and a corner case bugfix.   - Allow the tracing of kernel console output (printk).   - Improvements/fixes to user-space RDPMC support, allowing user-space    self-profiling code to extract PMU counts without performing any    system calls, while playing nice with the kernel side.   - 'perf bench' improvements   - ... and lots of internal restructurings, cleanups and fixes that made    these features possible.  And, as usual this list is incomplete as    there were also lots of other improvements  * 'perf-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (120 commits)   perf report: Fix annotate double quit issue in branch view mode   perf report: Remove duplicate annotate choice in branch view mode   perf/x86: Prettify pmu config literals   perf report: Enable TUI in branch view mode   perf report: Auto-detect branch stack sampling mode   perf record: Add HEADER_BRANCH_STACK tag   perf record: Provide default branch stack sampling mode option   perf tools: Make perf able to read files from older ABIs   perf tools: Fix ABI compatibility bug in print_event_desc()   perf tools: Enable reading of perf.data files from different ABI rev   perf: Add ABI reference sizes   perf report: Add support for taken branch sampling   perf record: Add support for sampling taken branch   perf tools: Add code to support PERF_SAMPLE_BRANCH_STACK   x86/kprobes: Split out optprobe related code to kprobes-opt.c   x86/kprobes: Fix a bug which can modify kernel code permanently   x86/kprobes: Fix instruction recovery on optimized path   perf: Add callback to flush branch_stack on context switch   perf: Disable PERF_SAMPLE_BRANCH_* when not supported   perf/x86: Add LBR software filter support for Intel CPUs   ...
f | dwarf-regs.h | s | 138B | 6 | Ian Munsie | imunsie@au.ibm.com | 1271908111 |  | perf: Move arch specific code into separate arch directory  The perf userspace tool included some architecture specific code to map registers from the DWARF register number into the names used by the regs and stack access API.  This moves the architecture specific code out into a separate arch/x86 directory along with the infrastructure required to use it.  Signed-off-by: Ian Munsie <imunsie@au.ibm.com> Acked-by: Masami Hiramatsu <mhiramat@redhat.com> Signed-off-by: Paul Mackerras <paulus@samba.org>
